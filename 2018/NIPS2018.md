1. **Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning** --*Ofir Marom &middot; Benjamin Rosman*
 > Object-oriented representations in reinforcement learning have shown promise in transfer learning, with previous research introducing a propositional object-oriented framework that has provably efficient learning bounds with respect to sample complexity. However, this framework has limitations in terms of the classes of tasks it can efficiently learn. In this paper we introduce a novel deictic object-oriented framework that has provably efficient learning bounds and can solve a broader range of tasks. Additionally, we show that this framework is capable of zero-shot transfer of transition dynamics across tasks and demonstrate this empirically for the Taxi and Sokoban domains.
2. **The Price of Fair PCA: One Extra dimension** --*Samira Samadi &middot; Uthaipon Tantipongpipat &middot; Jamie Morgenstern &middot; Mohit Singh &middot; Santosh Vempala*
 >  In this paper, we investigate the possibility that standard dimensionality reduction techniques might inadvertently produce data representations which do not maintain similar fidelity for two different populations. We show on several real-world datasets, PCA has higher reconstruction error on population $A$ than $B$ (for example, women versus men or lower versus higher-educated individuals). This can happen even when the dataset has similar number of samples from $A$ and $B$. This motivates our study of dimensionality reduction techniques with similar fidelity for $A$ as $B$. We give a polynomial-time algorithm for finding a projection which is nearly-optimal with respect to this measure, and evaluate it on several datasets.
3. **Transfer of Deep Reactive Policies for MDP Planning** --*Aniket Bajpai &middot; Sankalp Garg &middot; Mausam*
 > Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist.  Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning.  
4. **Sequential Data Classification for Resource-constrained Devices** --*Prateek Jain &middot; Harsha Vardhan Simhadri &middot; Don Dennis &middot;  *
 > We study the problem of fast and efficient classification of sequential data (such as time-series) on tiny devices, which is critical for various IoT related applications like audio keyword detection or gesture detection. Deploying sequential data classification modules on tiny devices is challenging as predictions over sliding windows of data need to be invoked continuously at a high frequency. Each of these predictors themselves are expensive as they evaluate large models over long windows of data. In this paper, we address this challenge by exploiting the following two observations about classification tasks arising in typical IoT related applications: (a) the "signature" of a particular class (e.g. an audio keyword) typically occupies a small fraction of the overall data, and (b) class signatures tend to discernible early-on in the data.  We propose a method that exploits these observations by using a multiple instance learning formulation along with an early prediction technique to learn a model that can achieve better accuracy compared to baseline models, while reducing the computation by a large fraction. For instance, on an audio keyword detection benchmark  our model improves standard LSTM model's accuracy by up to 1.5\% while decreasing the computation cost by more than 60\%. This enables us to deploy such models for continuous real-time prediction on a small device such as Raspberry Pi0, a task that the baseline LSTM could not achieve. Finally, we also provide an analysis of our multiple instance learning algorithm in a simple setting and show that the proposed algorithm can efficiently converge to the global optima, one of the first such result in this domain.
5. **Sparse PCA from Sparse Linear Regression** --*Madalina Persu &middot; Guy Bresler &middot; Sam Park*
 > Sparse Principal Component Analysis (SPCA) and Sparse Linear Regression (SLR) are two problems that have a wide range of applications and have attracted a tremendous amount of attention in the last two decades as canonical examples of statistical problems in high dimension. A variety of algorithms have been proposed for both SPCA and SLR, but their literature has been disjoint for the most part. We have a fairly good understanding of conditions and regimes under which these algorithms succeed. But is there be a deeper connection between computational structure of SPCA and SLR? In this paper we show how to efficiently transform a blackbox solver for SLR into an algorithm for SPCA. Assuming the SLR solver satisfies prediction error guarantees achieved by existing efficient algorithms such as those based on the Lasso, we show that the SPCA algorithm derived from it achieves state of the art performance, matching guarantees for testing and for support recovery under the single spiked covariance model as obtained by the current best polynomial-time algorithms. Our reduction not only highlights the inherent similarity between the two problems, but also, from a practical standpoint, it allows one to obtain a collection of algorithms for SPCA directly from known algorithms for SLR. Experiments on simulated data show that these algorithms perform well.
