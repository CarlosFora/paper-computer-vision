335. **Size-Noise Tradeoffs in Generative Networks** --*Bolton Bailey &middot; Matus Telgarsky*
 > Generative networks can modify their noise distributions to look like other noise distributions. Firstly, we demonstrate a construction that allows ReLU networks to increase the dimensionality of their noise distribution by implementing a ``space-filling'' function based on iterated tent maps. We show this construction is optimal by analyzing the number of affine pieces in functions computed by multivariate ReLU networks. We also develop a toolkit of techniques for function approximation with neural networks, including a Taylor series approximation and a binary search gadget for computing function inverses. This toolkit provides efficient ways (using $\polylog(1/\epsilon)$ nodes) for networks to pass between univariate normal and uniform distributions. 
336. **Learning to Teach with Dynamic Loss Functions** --*Lijun Wu &middot; Fei Tian &middot; Yingce Xia &middot; Yang Fan &middot; Tao Qin &middot; Lai Jian-Huang &middot; Tieyan Liu*
 > Teaching is critical to human society: it is with teaching that prospective students are educated and human civilization can be inherited and advanced. A good teacher not only provides his/her students with qualified teaching materials (e.g., textbooks), but also sets up appropriate learning objectives (e.g., course projects and exams) considering different situations of a student. When it comes to artificial intelligence, treating machine learning models as students, the loss functions that are optimized act as perfect counterparts of the learning objective set by the teacher. In this work, we explore the possibility of imitating human teaching behaviors by dynamically and automatically outputting appropriate loss functions to train machine learning models. Different from typical learning settings in which the loss function of a machine learning model is predefined and fixed, in our framework, the loss function of a machine learning model (we call it student) is defined by another machine learning model (we call it teacher). The ultimate goal of teacher model is cultivating the student to have better performance measured on development dataset. Towards that end, similar to human teaching, the teacher, a parametric model, dynamically outputs different loss functions that will be used and optimized by its student model at different training stages. We develop an efficient learning method for the teacher model that makes gradient based optimization possible, exempt of the ineffective solutions such as policy optimization. We name our method as ``learning to teach with dynamic loss functions'' (L2T-DLF for short). Extensive experiments on real world tasks including image classification and neural machine translation demonstrate that our method significantly improves the quality of various student models. 
337. **Turbo Learning for Captionbot and Drawingbot** --*Qiuyuan Huang &middot; Pengchuan Zhang &middot; Lei Zhang &middot; Dapeng Wu*
 > We study in this paper the problems of both image captioning and text-to-image generation, and present a novel turbo learning approach to jointly training an image-to-text generator (a.k.a. captionbot) and a text-to-image generator (a.k.a. drawingbot). The key idea behind the joint training is that image-to-text generation and text-to-image generation as dual problems can form a closed loop to provide informative feedback to each other. Based on such feedback, we introduce a new loss metric by comparing the original input with the output produced by the closed loop. In addition to the old loss metrics used in captionbot and drawingbot, this extra loss metric makes the jointly trained captionbot and drawingbot better than the separately trained captionbot and drawingbot. Furthermore, the turbo-learning approach enables semi-supervised learning since the closed loop can provide peudo-labels for unlabeled samples. Experimental results on the COCO dataset demonstrate that the proposed turbo learning can significantly improve the performance of both captionbot and drawingbot by a large margin.
338. **Learning Latent Subspaces in Variational Autoencoders** --*Jack Klys &middot; Jake Snell &middot; Richard Zemel*
 > We present a method for training variational autoencoders on labelled datasets which encode information corresponding to the labels in explicitly predetermined subspaces of the latent space. We motivate our model from both an information theoretic perspective as well as a adversarial game perspective. By separating labelled information into a less complicated space we allow the model to more easily disentangle representations. This provides a form of semi-supervised learning of attributes. Since these subspaces can be chosen a priori, setting them to be low-dimensional provides a form of dimensionality reduction. We demonstrate the utility of our model on attribute manipulation tasks with several image datasets.
339. **L4: Practical loss-based stepsize adaptation for deep learning** --*Michal Rolinek &middot; Georg Martius*
 > We propose a stepsize adaptation scheme for stochastic gradient descent. It operates directly with the loss function and rescales the gradient in order to make fixed predicted progress on the loss. We demonstrate its capabilities by conclusively improving the performance of Adam and Momentum optimizers. The enhanced optimizers with default hyperparameters  consistently outperform their constant stepsize counterparts, even the best ones,  without a measurable increase in computational cost. The performance is validated on multiple architectures including dense nets, CNNs, ResNets, and the recurrent Differential Neural Computer on classical datasets MNIST, fashion MNIST, CIFAR10 and others.
340. **Rich gets richer, Poor gets zero: On Sparse Alternatives to Softmax** --*Anirban Laha &middot; Saneem Chemmengath &middot; Priyanka Agrawal &middot; Mitesh Khapra &middot; Karthik Sankaranarayanan &middot; Harish Ramaswamy*
 > Several probability mapping functions have been proposed and employed in literature such as softmax, sum-normalization, spherical softmax, and sparsemax, but there is very little understanding in terms how they relate with each other. Further, none of the above formulations offer an explicit control over the degree of sparsity. To address this, we develop a unified framework that encompasses all these formulations as special cases. This framework ensures simple closed-form solutions and existence of sub-gradients suitable for learning via backpropagation. Within this framework, we propose two novel sparse formulations, sparseflex and sparsehourglass, that seek to provide a control over the degree of desired sparsity. We further develop novel convex loss functions that help induce the behavior of aforementioned formulations in the multilabel classification setting. We demonstrate empirically that the proposed formulations achieve better accuracy scores on standard NLP tasks while at the same time enhancing interpretability.
341. **Graph Convolutional Policy Network for Goal-Directed Molecular Graph Generation** --*Jiaxuan You &middot; Bowen Liu &middot; Zhitao Ying &middot; Vijay Pande &middot; Jure Leskovec*
 > Generating novel graph structures that optimize given objectives while obeying some given underlying rules is fundamental for chemistry, biology and social science research. This is especially important in the task of molecular graph generation, whose goal is to discover novel molecules with desired properties such as drug-likeness and synthetic accessibility, while obeying physical laws such as chemical valency. However, designing models that finds molecules that optimize desired properties while incorporating highly complex and non-differentiable rules remains to be a challenging task. Here we propose Graph Convolutional Policy Network (GCPN), a general graph convolutional network based model for goal-directed graph generation through reinforcement learning. The model is trained to optimize domain-specific rewards and adversarial loss through policy gradient, and acts in an environment that incorporates domain-specific rules. Experimental results show that GCPN can achieve 61% improvement on chemical property optimization over state-of-the-art baselines while resembling known molecules, and achieve 184% improvement on the constrained property optimization task.
342. **The Limits of Post-Selection Generalization** --*Jonathan Ullman &middot; Adam Smith &middot; Kobbi Nissim &middot; Uri Stemmer &middot; Thomas Steinke*
 > While statistics and machine learning offers numerous methods for ensuring generalization, these methods often fail in the presence of <em>post selection</em>---the common practice in which the choice of analysis depends on previous interactions with the same dataset.  A recent line of work has introduced powerful, general purpose algorithms that ensure a property called <em>post hoc generalization</em> (Cummings et al., COLT'16), which says that no person when given the output of the algorithm should be able to find any statistic for which the data differs significantly from the population it came from.
343. **Visualizing the Loss Landscape of Neural Nets** --*Hao Li &middot; Zheng Xu &middot; Gavin Taylor &middot; Christoph Studer &middot; Tom Goldstein*
 > Neural network training relies on our ability to find "good" minimizers of highly non-convex loss functions. It is well known that certain network architecture designs (e.g., skip connections) produce loss functions that train easier, and well-chosen training parameters (batch size, learning rate, optimizer) produce minimizers that generalize better. However, the reasons for these differences, and their effect on the underlying loss landscape, is not well understood. In this paper, we explore the structure of neural loss functions, and the effect of loss landscapes on generalization, using a range of visualization methods. First, we introduce a simple "filter normalization" method that helps us visualize loss function curvature, and make meaningful side-by-side comparisons between loss functions. Then, using a variety of visualizations, we explore how network architecture affects the loss landscape, and how training parameters affect the shape of minimizers.
344. **Bayesian Distributed Stochastic Gradient Descent** --*Michael Teng &middot; Frank Wood*
 > We introduce Bayesian distributed stochastic gradient descent (BDSGD), a high-throughput algorithm for training deep neural networks on parallel clusters. This algorithm uses amortized inference in a deep generative model to perform joint posterior predictive inference of mini-batch gradient computation times in a compute cluster specific manner. Specifically, our algorithm mitigates the straggler effect in synchronous, gradient-based optimization by choosing an optimal cutoff beyond which mini-batch gradient messages from slow workers are ignored. In our experiments, we show that eagerly discarding the mini-batch gradient computations of stragglers not only increases throughput but actually increases the overall rate of convergence as a function of wall-clock time by virtue of eliminating idleness.  The principal novel contribution and finding of this work goes beyond this by demonstrating that using the predicted run-times from a generative model of cluster worker performance improves substantially over the static-cutoff prior art, leading to reduced deep neural net training times on large computer clusters.
345. **Efficient Formal Safety Analysis of Neural Networks** --*Shiqi Wang &middot; Kexin Pei &middot; Justin Whitehouse &middot; Junfeng Yang &middot; Suman Jana*
 > Neural networks are increasingly deployed in real-world safety-critical domains such as autonomous driving, aircraft collision avoidance, and malware detection. However, these networks have been shown to often mispredict on inputs with minor adversarial or even accidental perturbations. Consequences of such errors can be disastrous and even potentially fatal as shown by the recent Tesla autopilot crash. Thus, there is an urgent need for formal analysis systems that can rigorously check neural networks for violations of different safety properties such as robustness against adversarial perturbations within a certain L-norm of a given image. An effective safety analysis system for a neural network must be able to either ensure that a safety property is satisfied by the network or find a counterexample, i.e., an input for which the network will violate the property. Unfortunately, most existing techniques for performing such analysis struggle to scale beyond very small networks and the ones that can scale to larger networks suffer from high false positives and cannot produce concrete counterexamples in case of a property violation. In this paper, we present a new efficient approach for rigorously checking different safety properties of neural networks that significantly outperforms existing approaches by multiple orders of magnitude. Our approach can check different safety properties and find concrete counterexamples for networks that are 10x larger than the ones supported by existing analysis techniques. We believe that our approach to estimating tight output bounds of a network for a given input range can also help improve the explainability of neural networks and guide the training process of more robust neural networks.
346. **A no-regret generalization of hierarchical softmax to extreme multi-label classification** --*Marek Wydmuch &middot; Kalina Jasinska &middot; Mikhail Kuznetsov &middot; Róbert Busa-Fekete &middot; Krzysztof Dembczynski*
 > Extreme multi-label classification (XMLC) is the problem of tagging an instance with a small subset of relevant labels chosen from an extremely large pool of possible labels. Large label spaces can be efficiently handled by organizing labels as a tree, like in the hierarchical softmax (HSM) approach. In this paper, we investigate Probabilistic Label Trees (PLTs) that have been recently devised for tackling XMLC problems. We show that PLT is a no-regret multi-label generalization of HSM when precision@k is used as a model evaluation metric. Critically, we prove that pick-one-label heuristic---a reduction technique from multi-label to multi-class that is routinely used along with HSM---is not consistent in general. We also show that our implementation of PLTs, referred to as XT, obtains significantly better results than HSM with the pick-one-label heuristic and XML-CNN, a deep network specifically designed for XMLC problems. Moreover, XT is competitive to many state-of-the-art approaches in terms of statistical performance, model size and prediction time which makes it amenable to deploy in an online system. 
347. **Distributed Learning without Distress: Privacy-Preserving Empirical Risk Minimization** --*Bargav Jayaraman &middot; Lingxiao Wang &middot; David Evans &middot; Quanquan Gu*
 > We consider the scenario where several independent data owners wish to collaboratively learn a model over their sensitive data sets, without exposing their private data. Our approach combines differential privacy with secure multi-party computation to achieve private distributed machine learning. In particular, we explore two popular methods of differential privacy, output perturbation and gradient perturbation, and advance the state-of-the-art for both methods in the distributed learning setting. In our output perturbation method, the parties combine their local models within a secure computation and then add the required differential privacy noise within the secure computation before revealing the model. In our gradient perturbation method, the data owners collaboratively train a global model via an iterative learning algorithm.  At each iteration, the parties aggregate their local gradients within a secure computation, adding sufficient noise to ensure privacy before the gradient updates are revealed. In both cases, we show that the noise can be reduced in the multi-party setting by adding the noise inside the secure computation after aggregation, asymptotically improving upon the best previous results. Thorough experiments on real world data sets corroborate our theory.
348. **Sequential Test for the Lowest Mean: From Thompson to Murphy Sampling** --*Emilie Kaufmann &middot; Wouter Koolen &middot; Aurelien Garivier*
 > Learning the minimum/maximum mean among a finite set of distributions is a fundamental sub-problem in planning, game tree search and reinforcement learning. We formalize this learning task as the problem of sequentially testing how the minimum mean among a finite set of distributions compares to a given threshold. We develop refined non-asymptotic lower bounds, which show that optimality mandates very different sampling behavior for a low vs high true minimum. We show that Thompson Sampling and the intuitive Lower Confidence Bounds policy each nail only one of these cases. We develop a novel approach that we call Murphy Sampling. Even though it entertains exclusively low true minima, we prove that MS is optimal for both possibilities. We then design advanced self-normalized deviation inequalities, fueling more aggressive stopping rules. We complement our theoretical guarantees by experiments showing that MS works best in practice.
349. **Deep Structured Prediction via Nonlinear Output Transformations** --*Colin Graber &middot; Ofer Meshi &middot; Alexander Schwing*
 > Deep structured models are widely used for tasks like semantic segmentation, where explicit correlations between variables provide important prior information which generally helps to reduce the data needs of deep nets. However, current deep structured models are restricted by oftentimes very local neighborhood structure, which cannot be increased for computational complexity reasons, and by the fact that the output configuration, or a representation thereof, cannot be transformed further. Very recent approaches which address those issues include graphical model inference inside deep nets so as to permit subsequent non-linear output space transformations. However, optimization of those formulations is challenging and not well understood. Here, we develop a novel model which generalizes existing approaches, such as structured prediction energy networks, and discuss a formulation which maintains applicability of existing inference techniques.
350. **Navigating with Graph Representations for Fast and Scalable Decoding of Neural Language Models** --*Minjia Zhang &middot; Wenhan Wang &middot;   &middot; Jianfeng Gao &middot; Yuxiong He*
 > Neural language models (NLMs) have recently gained a renewed interest by achieving state-of-the-art performance across many natural language processing (NLP) tasks. However, NLMs are very computationally demanding largely due to the computational cost of the softmax function over a large vocabulary. We observe that, in decoding of many NLP tasks, only the probabilities of the top-K hypotheses need to be calculated preciously and K is often much smaller than the vocabulary size. This paper proposes a novel softmax approximation algorithm, called Fast Graph Decoder (FGD), which quickly identifies, for a given context, a set of K words that are most likely to occur according to a NLM.  We demonstrate that FGD reduces the decoding time by an order of magnitude while attaining close to the full softmax baseline accuracy on neural machine translation and language modeling tasks. We also prove the theoretical guarantee on the softmax approximation quality.
351. **Algebraic tests of general Gaussian latent tree models** --*Dennis Leung &middot; Mathias Drton*
 > We consider general Gaussian latent tree models in which the observed variables are not restricted to be leaves of the tree. Extending related recent work, we give a full semi-algebraic description of the set of covariance matrices of any such model.  In other words, we find polynomial constraints that characterize when a matrix is the covariance matrix of a distribution in a given latent tree model. However, leveraging these constraints to test a given such model is often complicated by the number of constraints being large and by singularities of individual polynomials, which may invalidate standard approximations to relevant probability distributions. Illustrating with the star tree, we propose a new testing methodology that circumvents singularity issues by trading off some statistical estimation efficiency and handles cases with many constraints through recent advances on Gaussian approximation for maxima of sums of high-dimensional random vectors. Our test avoids the need to maximize the possibly multimodal likelihood function of such models and is applicable to models with larger number of variables.  These points are illustrated in numerical experiments.
352. **Exponentially Weighted Imitation Learning for Batched Historical Data** --*Qing Wang &middot; Jiechao Xiong &middot; Lei Han &middot; peng sun &middot; Han Liu &middot; Tong Zhang*
 > We consider deep policy learning with only batched historical trajectories. The main challenge of this problem is that the learner no longer has a simulator or ``environment oracle'' as in most reinforcement learning settings. To solve this problem, we propose a novel exponentially weighted imitation learning strategy that is applicable to problems with complex nonlinear function approximation and works well with hybrid (discrete and continuous) action space. The method does not rely on the knowledge of the behavior policy, thus can be used to learn from data generated by an unknown policy. Under mild conditions, our algorithm, though surprisingly simple, has a policy improvement guarantee and outperforms most competing methods empirically. Thorough numerical results are also provided to demonstrate the efficacy of the proposed methodology.
353. **Privacy Amplification by Subsampling: Tight Analyses via Couplings and Divergences** --*Borja Balle &middot; Gilles Barthe &middot; Marco Gaboardi*
 > Differential privacy comes equipped with multiple analytical tools for the design of private data analyses. One important tool is the so called “privacy amplification by subsampling” principle, which ensures that a differentially private mechanism run on a random subsample of a population provides higher privacy guarantees than when run on the entire population. Several instances of this principle have been studied for different random subsampling methods, each with an ad-hoc analysis.
354. **Multi-domain Causal Structure Learning in Linear Systems** --*AmirEmad Ghassami &middot; Kun Zhang &middot; Negar Kiyavash*
 > We study causal structure learning in linear systems with observational data given in multiple domains, across which the causal coefficients, and/or the distribution of the exogenous noises may vary. Unlike previous work, we do not assume any invariance of the causal process among the domains. The main tool used in our approach is the principle that in a causally sufficient system, P(cause) and P(effect | cause), as well as their included parameters, change independently across domains. We first present our main approach to finding causal relations from multi-domain observational information, and then propose efficient tests for causal structure learning based on the introduced idea. For the case of two variables, the proposed tests are generally capable of identifying causal direction from fewer than ten domains.
356. **SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient** --*Aaron Mishkin &middot; Frederik Kunstner &middot; Didrik Nielsen &middot; Mohammad Emtiyaz Khan &middot; Mark Schmidt*
 > We focus on the task of uncertainty estimation in deep learning models, where it is computationally challenging to even form a Gaussian approximation to the posterior. Because of this, many existing Gaussian approximations only use a diagonal covariance matrix even though such matrices are known to give poor uncertainty estimates. We propose a new stochastic, low-rank, approximate natural-gradient (SLANG) method for variational inference, which allows us to efficiently fit a non-diagonal approximation. The method estimates a ``diagonal plus low-rank'' structure based solely on back-propagated gradients of the network log-likelihood. This requires strictly less gradient computation than methods that require the gradient of the whole variational objective. Empirical evaluations on standard benchmarks confirm that SLANG obtains reasonable posterior approximations which give comparable accuracy to the state-of-the-art.
357. **LF-Net: Learning Local Features from Images** --*Yuki Ono &middot; Eduard Trulls &middot; Pascal Fua &middot; Kwang Moo Yi*
 > We present a novel strategy to learn a local feature pipeline from collections of images with deep networks, without the need for human supervision. To do so we frame the learning problem with a two-branch network. We posit that training both branches with a standard Siamese architecture is not feasible, as solving the correspondence problem jointly with feature learning is too challenging, and does not converge well enough to train from scratch. Instead, we propose to break differentiability on one branch and use ground-truth geometry to remove the burden of solving the correspondence problem while training, while keeping the other fully-differentiable. In order to train this setup with gradient-based methods, we optimize for the differentiable branch while using the parameters from the previous training step for the other, and demonstrate that both converge to a single, optimal solution. Our method can be trained with only the relative camera pose and depth information---furthermore, we show that this ground truth does not need to be perfect and can be easily obtained with off-the-shelf Structure-from-Motion solutions. Our models outperform the state of the art on sparse feature matching on  both indoor and outdoor datasets, while running at 60+ fps for QVGA images.
358. **Learning towards Minimum Hyperspherical Energy** --*Weiyang Liu &middot; Rongmei Lin &middot; Zhen Liu &middot; Lixin Liu &middot; Zhiding Yu &middot; Bo Dai &middot; Le Song*
 > Neural networks are a powerful class of nonlinear functions that can be trained end-to-end on various applications. While the over-parametrization nature in many neural networks renders the ability to fit complex functions and the strong representation power to handle challenging tasks, it also leads to highly correlated neurons that can hurt the generalization ability and incur unnecessary computation cost. As a result, how to regularize the network to avoid undesired representation redundancy becomes an important issue. To this end, we draw inspiration from a well-known problem in physics -- Thomson problem, where one seeks to find a state that distributes N electrons on a unit sphere as even as possible with minimum potential energy. In light of this intuition, we reduce the redundancy regularization problem to generic energy minimization, and propose a minimum hyperspherical energy (MHE) objective as generic regularization for neural networks. We also propose a few novel variants of MHE, and provide some insights from a theoretical point of view. Finally, we apply networks with MHE regularization to several challenging tasks. Extensive experiments demonstrate the effectiveness of our method, by showing the superior performance with MHE regularization.
359. **Deep Neural Networks with Box Convolutions** --*Egor Burkov &middot; Victor Lempitsky*
 > Box filters computed using integral images have been part of the computer vision toolset for a long time. Here, we show that a convolutional layer that computes box filter responses in a sliding manner can be used within deep architectures, whereas the dimensions and the offsets of the sliding boxes in such a layer can be learned as part of an end-to-end loss minimization. Crucially, the training process can make the size of the boxes in such a layer arbitrarily large without incurring extra computational cost and without the need to increase the number of learnable parameters. Due to its ability to integrate information over large boxes, the new layer facilitates long-range propagation of information and leads to the efficient increase of the receptive fields of downstream units in the network. By incorporating the new layer into existing architectures for semantic segmentation, we are able to achieve both the increase in segmentation accuracy as well as the decrease in the computational cost and the number of learnable parameters.
360. **Sharp Bounds for Generalized Uniformity Testing** --*Ilias Diakonikolas &middot; Daniel M. Kane &middot; Alistair Stewart*
 > We study the problem of generalized uniformity testing of a discrete probability distribution: Given samples from a probability distribution p over an unknown size discrete domain Ω, we want to distinguish, with probability at least 2/3, between the case that p is uniform on some subset of Ω versus ε-far, in total variation distance, from any such uniform distribution. We establish tight bounds on the sample complexity of generalized uniformity testing. In more detail, we present a computationally efficient tester whose sample complexity is optimal, within constant factors, and a matching worst-case information-theoretic lower bound. Specifically, we show that the sample complexity of generalized uniformity testing is Θ(1/(ε^(4/3) ||p||<em>3) + 1/(ε^2 ||p||</em>2 )).
361. **The Cluster Description Problem - Complexity Results, Formulations and Approximations** --*Ian Davidson &middot; S Ravi*
 > Consider the situation where you are given an existing $k$-way clustering $\pi$. A challenge for explainable AI is to find a compact and distinct explanations of each cluster which in this paper is using instance-level descriptors/tags from a common dictionary. Since the descriptors/tags were not given to the clustering method, this is not a semi-supervised learning situation.  We show that the \emph{feasibility} problem of just testing whether any distinct description (not the most compact) exists is generally intractable for just two clusters. This means that unless \textbf{P} = \cnp,  there cannot exist an efficient algorithm for the cluster description problem. Hence, we explore ILP formulations for smaller problems and a relaxed but restricted setting that leads to a polynomial time algorithm for larger problems.  We explore several extension to the basic setting such as the ability to ignore some instances and composition constraints on the descriptions of the clusters.  We show our formulation's usefulness on Twitter data where the communities were found using social connectivity (i.e. \texttt{follower} relation) but the explanation of the communities is based on behavioral properties of the nodes (i.e. hashtag usage) not available to the clustering method.
362. **Transfer of Value Functions via Variational Methods** --*Andrea Tirinzoni &middot; Rafael Rodriguez &middot; Marcello Restelli*
 > We consider the problem of transferring value functions in reinforcement learning. We propose an approach that uses the given source tasks to learn a prior distribution over optimal value functions and provide an efficient variational approximation of the corresponding posterior in a new target task. We show our approach to be general, in the sense that it can be combined with complex parametric function approximators and distribution models, while providing two practical algorithms based on Gaussians and Gaussian mixtures. We theoretically analyze them by deriving a finite-sample analysis and provide a comprehensive empirical evaluation in four different domains.
363. **ResNet with one-neuron hidden layers is a Universal Approximator** --*Hongzhou Lin &middot; Stefanie Jegelka*
 > We demonstrate that a very deep ResNet with stacked modules with one neuron per hidden layer and ReLU activation functions can uniformly approximate any Lebesgue integrable function in d dimensions, i.e. \ell_1(\R^d). Because of the identity mapping inherent to ResNets, our network has alternating layers of dimension one and d. This stands in sharp contrast to fully connected networks, which are not universal approximators if their width is the input dimension d. Hence, our result implies an increase in representational power for narrow deep networks by the ResNet architecture.
364. **Deep State Space Models for Unconditional Word Generation** --*Florian Schmidt &middot; Thomas Hofmann*
 > Autoregressive feedback is considered a necessity for successful unconditional text generation using stochastic sequence models. However, such feedback is known to introduce systematic biases into the training and it obscures a principle of generation: committing to global information and forgetting local nuances. We show that a non-autoregressive deep state space model with a clear separation of global and local uncertainty can be build from only two ingredients: An independent noise source and a deterministic transition function. Recent advances on flow-based variational inference allow training an evidence lower-bound without resorting to annealing, auxiliary losses or similar measures. The result is a highly interpretable generative model on par with a comparable auto-regressive model on the task of word generation.
365. **Predict Responsibly: Improving Fairness and Accuracy by Learning to Defer** --*David Madras &middot; Toni Pitassi &middot; Richard Zemel*
 > In many machine learning applications, there are multiple decision-makers involved, both automated and human. The interaction between these agents often goes unaddressed in algorithmic development. In this work, we explore a simple version of this interaction with a two-stage framework containing an automated model and an external decision-maker. The model can choose to say PASS, and pass the decision downstream, as explored in rejection learning. We extend this concept by proposing learning to defer, which generalizes rejection learning by considering the effect of other agents in the decision-making process. We propose a learning algorithm which accounts for potential biases held by external decision-makers in a system. Experiments demonstrate that learning to defer cam make systems not only more accurate but also less biased. Even when working with inconsistent or biased users, we show that deferring models still greatly improve the accuracy and/or fairness of the entire system.
366. **Online convex optimization for cumulative constraints** --*Jianjun Yuan &middot; Andrew Lamperski*
 >   We propose the algorithms for online convex   optimization which lead to cumulative squared constraint violations   of the form   $\sum\limits_{t=1}^T\big([g(x_t)]_+\big)^2=O(T^{1-\beta})$, where   $\beta\in(0,1)$   .  Previous literature has   focused on long-term constraints of the form   $\sum\limits_{t=1}^Tg(x_t)$. There, strictly feasible solutions   can cancel out the effects of violated constraints.   In contrast, the new form heavily penalizes large constraint   violations and cancellation effects cannot occur.    Furthermore, useful bounds on the single step constraint violation   $[g(x_t)]_+$ are derived.   For convex objectives, our regret bounds generalize   existing bounds, and for strongly convex objectives we give improved   regret bounds.   In numerical experiments, we show that our algorithm closely follows   the constraint boundary leading to low cumulative violation. 
367. **Recurrent Transformer Networks for Semantic Correspondence** --*Seungryong Kim &middot; Stephen Lin &middot; SANG RYUL JEON &middot; Dongbo Min &middot; Kwanghoon Sohn *
 > We present recurrent transformer networks (RTNs) for obtaining dense correspondences between semantically similar images. Our networks accomplish this through an iterative process of estimating spatial transformations between the input images and using these transformations to generate aligned convolutional activations. By directly estimating the transformations between an image pair, rather than employing spatial transformer networks to independently normalize each individual image, we show that greater accuracy can be achieved. This process is conducted in a recursive manner to refine both the transformation estimates and the feature representations. In addition, a technique is presented for weakly-supervised training of RTNs that is based on a proposed classification loss. With RTNs, state-of-the-art performance is attained on several benchmarks for semantic correspondence.
368. **Information Constraints on Auto-Encoding Variational Bayes** --*Romain Lopez &middot; Michael Jordan &middot; Jeffrey Regier &middot; Nir Yosef*
 > Parameterizing the approximate posterior of a generative model with neural networks has become a common theme in recent machine learning research. While providing appealing flexibility, this approach makes it difficult to impose or assess structural constraints such as conditional independence. We propose a framework for learning representations that relies on Auto-Encoding Variational Bayes and whose search space is constrained via kernel-based measures of independence.  In particular, our method employs the $d$-variable Hilbert-Schmidt Independence Criterion (dHSIC) to enforce independence between the latent representations and arbitrary nuisance factors. We show how to apply this method to a range of problems, including the problems of learning invariant representations and the learning of interpretable representations. We also present a full-fledged application to single-cell RNA sequencing (scRNA-seq). In this setting the biological signal in mixed in complex ways with sequencing errors and sampling effects.  We show that our method out-performs the state-of-the-art in this domain.
369. **Poison Frogs! Targeted Clean-Label PoisoningAttacks on Neural Networks** --*Ali Shafahi &middot; W. Ronny Huang &middot; Mahyar Najibi &middot; Octavian Suciu &middot; Christoph Studer &middot; Tudor Dumitras &middot; Tom Goldstein*
 > Data poisoning an attack on machine learning models wherein the attacker adds examples to the training set to manipulate the behavior of the model at test time. This paper explores poisoning attacks on neural nets. The proposed attacks use ``clean-labels''; they don't require the attacker to have any control over the labeling of training data.  They are also targeted; they control the behavior of the classifier on a specific test instance without degrading overall classifier performance. For example, an attacker could add a seemingly innocuous image (that is properly labeled) to a training set for a face recognition engine, and control the identity of a chosen person at test time. Because the attacker does not need to control the labeling function, poisons could be entered into the training set simply by putting them online and waiting for them to be scraped by a data collection bot.
370. **MacNet: Transferring Knowledge from Machine Comprehension to Sequence-to-Sequence Models** --*Boyuan Pan &middot; Yazheng Yang &middot; Hao Li &middot; Zhou Zhao &middot; Yueting Zhuang &middot; Deng Cai &middot; Xiaofei He*
 > Machine Comprehension (MC) is one of the core problems in natural language processing, requiring both understanding of natural language and knowledge about the world. Rapid progress has been made since the release of several benchmark datasets, and recently the state-of-the-art models even surpass human performance on the well-known SQuAD evaluation. In this paper, we transfer knowledge learned from machine comprehension to the sequence-to-sequence tasks to deepen the understanding of the text. We propose MacNet: a novel encoder-decoder supplementary architecture to the widely used attention-based sequence-to-sequence models. Experiments on neural machine translation (NMT) and abstractive text summarization show that our proposed framework can significantly improve the performance of the baseline models, and our method for the abstractive text summarization achieves the state-of-the-art results on the Gigaword dataset.
371. **Variational Learning on Aggregate Outputs with Gaussian Processes** --*Ho Chung Law &middot; Dino Sejdinovic &middot; Ewan Cameron &middot; Tim  Lucas &middot; Seth Flaxman &middot; Katherine  Battle &middot; Kenji Fukumizu*
 > While a typical supervised learning framework assumes that the inputs and the outputs are measured at the same levels of granularity, many applications, including global mapping of disease, only have access to outputs at a much coarser level than that of the inputs. Aggregation of outputs makes generalization to new inputs much more difficult. We consider an approach to this problem based on variational learning with a model of output aggregation and Gaussian processes, where aggregation leads to intractability of the standard evidence lower bounds. We propose new bounds and tractable approximations, leading to improved prediction accuracy and scalability to large datasets, while explicitly taking uncertainty into account. We develop a framework which extends to several types of likelihoods, including the Poisson model for aggregated count data. We apply our framework to a challenging and important problem, the fine-scale spatial modelling of malaria incidence, with over 1 million observations.
372. **Graphical Generative Adversarial Networks** --*Chongxuan LI &middot; Max Welling &middot; Jun Zhu &middot; Bo Zhang*
 > We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model structured data. Graphical-GAN conjoins the power of Bayesian networks on compactly representing the dependency structures among random variables and that of generative adversarial networks on learning expressive dependency functions. We introduce a structured recognition model to infer the posterior distribution of latent variables given observations. We generalize the Expectation Propagation (EP) algorithm to learn the generative model and recognition model jointly. Finally, we present two important instances of Graphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn the discrete and temporal structures on visual datasets, respectively.
373. **Learning to Infer Graphics Programs from Hand-Drawn Images** --*Kevin Ellis &middot; Daniel Ritchie &middot; Armando Solar-Lezama &middot; Josh Tenenbaum*
 > We introduce a model that learns to convert simple hand drawings   into graphics programs written in a subset of \LaTeX.~The model   combines techniques from deep learning and program synthesis.  We   learn a convolutional neural network that proposes plausible drawing   primitives that explain an image. These drawing primitives are a   specification (spec) of what the graphics program needs to draw.  We   learn a model that uses program synthesis techniques to recover a   graphics program from that spec. These programs have constructs like   variable bindings, iterative loops, or simple kinds of   conditionals. With a graphics program in hand, we can correct errors   made by the deep network and extrapolate drawings.
374. **Evolutionary Stochastic Gradient Descent for Optimization of Deep Neural Networks** --*Xiaodong Cui &middot; Wei Zhang &middot; Zoltan Tuske &middot; Michael Picheny*
 > We propose a population-based Evolutionary Stochastic Gradient Descent (ESGD) framework for optimizing deep neural networks. ESGD combines SGD and gradient-free evolutionary algorithms as complementary algorithms in one framework in which the optimization alternates between the SGD step and evolution step to improve the average fitness of the population. With a back-off strategy in the SGD step and an elitist strategy in the evolution step, it guarantees that the best fitness in the population will never degrade. In addition, various SGD-based optimizers with distinct hyper-parameters are considered in the SGD step as competing species in a coevolution setting such that their complementarity is also taken into account. The effectiveness of ESGD is demonstrated across multiple applications including speech recognition, image recognition and language modeling using networks with a variety of deep architectures.
375. **Stochastic fairness in clustering** --*David Harris &middot; Shi Li &middot; Aravind Srinivasan &middot; Khoa Trinh &middot; Thomas Pensyl*
 > Fairness is an increasing concern in machine learning, and in algorithms in general.  We consider a stochastic notion of fairness in clustering, and develop provably-good (approximation) algorithms for a number of these notions. We also complement some of these with impossibility results. 
376. **Dimensionally Tight Bounds for Second-Order Hamiltonian Monte Carlo** --*Oren Mangoubi &middot; Nisheeth Vishnoi*
 > Hamiltonian Monte Carlo (HMC) is a widely deployed method to sample from high-dimensional  distributions in  Statistics and Machine learning. HMC is known to run very efficiently in practice and its popular second-order ``leapfrog" implementation has long been conjectured to run in $d^{1/4}$ steps. Here we  show that this conjecture is true when sampling from strongly log-concave target distributions that satisfy a weak third-order regularity property associated with the input data. Our regularity condition is weaker than the Lipschitz Hessian property and allows us to show faster running time bounds for a  much larger class of distributions than would be possible with the usual Lipschitz Hessian constant alone.  Important distributions that satisfy our regularity condition include posterior distributions used in Bayesian logistic regression for which the data satisfies an ``incoherence" property. Our result  compares favorably with the best available running time bounds for the class of strongly log-concave distributions, which grow like $d^{1/2}$ with the dimension.  Moreover, our simulations on synthetic data suggest that, when our regularity condition is satisfied, the leapfrog HMC performs better than its competitors -- both in terms of accuracy and running time. 
377. **Multi-Task Zipping via Layer-wise Neuron Sharing** --*Xiaoxi He &middot; Zimu Zhou &middot; Lothar Thiele*
 > Future mobile devices are anticipated to perceive, understand and react to the world on their own by running multiple correlated deep neural networks on-device. Yet the complexity of these neural networks needs to be trimmed down both within-model and cross-model to fit in mobile storage and memory. Previous studies focus on squeezing the redundancy within a single neural network. In this work, we aim to reduce the redundancy across multiple models. We propose Multi-Task Zipping (MTZ), a framework to automatically merge correlated, pre-trained deep neural networks for cross-model compression. Central in MTZ is a layer-wise neuron sharing and incoming weight updating scheme that induces a minimal change in the error function. MTZ inherits information from each model and demands light retraining to re-boost the accuracy of individual tasks. Evaluations show that MTZ is able to fully merge the hidden layers of two VGG-16 networks with a 3.18% increase in the test error averaged on ImageNet and CelebA, or share 39.61% parameters between the two networks with &lt;0.5% increase in the test errors for both tasks. The number of iterations to retrain the combined network is at least 17.8 times lower than that of training a single VGG-16 network.
378. **Dirichlet-based Gaussian Processes for Large-scale Calibrated Classification** --*Dimitrios Milios &middot; Raffaello Camoriano &middot; Pietro Michiardi &middot; Lorenzo Rosasco &middot; Maurizio Filippone*
 > In this paper, we study the problem of deriving fast and accurate classification algorithms with uncertainty quantification. Gaussian process classification provides a principled approach, but the corresponding computational burden is hardly sustainable in large-scale problems and devising efficient alternatives is a challenge. In this work, we investigate if and how Gaussian process regression directly applied to the classification labels  can be used to tackle this question. While in this case training time is remarkably  faster, predictions need be calibrated for classification and uncertainty estimation. To this aim, we propose a novel approach based on  interpreting  the labels as the output of a Dirichlet distribution. Extensive experimental results show  that the proposed approach provides  essentially the same accuracy and uncertainty quantification of  Gaussian process classification  while requiring only a fraction of computational resources.
379. **Stacked Semantics-Guided Attention Model for Fine-Grained Zero-Shot Learning** --*yunlong yu &middot; Zhong Ji &middot; Yanwei Fu &middot; Jichang Guo &middot; Yanwei Pang &middot; Zhongfei (Mark) Zhang*
 > Zero-Shot Learning (ZSL) is achieved via aligning the semantic relationships between the global image feature vector and the corresponding class semantic descriptions. However, using the global features to represent fine-grained images may lead to sub-optimal results since they neglect the discriminative differences of local regions. Besides, different regions contain distinct discriminative information. The important regions should contribute more to the prediction. To this end, we propose a novel stacked semantics-guided attention (S2GA) model to obtain semantic relevant features by using individual class semantic features to progressively guide the visual features to generate an attention map for weighting the importance of different local regions. Feeding both the integrated visual features and the class semantic features into a multi-class classification architecture, the proposed framework can be trained end-to-end. Extensive experimental results on CUB and NABird datasets show that the proposed approach has a consistent improvement on both fine-grained zero-shot classification and retrieval tasks.
380. **Automating Bayesian optimization with Bayesian optimization** --*Gustavo Malkomes &middot; Roman Garnett*
 > Bayesian optimization is a powerful tool for global optimization of expensive functions. One of its key components is the underlying probabilistic model used for the objective function f. In practice, however, it is often unclear how one should appropriately choose a model, especially when gathering data is expensive.  In this work, we introduce a novel automated Bayesian optimization approach that dynamically selects promising models for explaining the observed data using Bayesian Optimization in the model space. Crucially, we account for the uncertainty in the model choice; our method is capable of using multiple models to represent its current belief about f and subsequently using this information for decision making. We argue, and demonstrate empirically, that our approach automatically finds suitable models for the objective function, which ultimately results in more-efficient optimization.
381. **The Convergence of Sparsified Gradient Methods** --*Dan Alistarh &middot; Torsten Hoefler &middot; Mikael Johansson &middot; Nikola Konstantinov &middot; Sarit Khirirat &middot; Cedric Renggli*
 > Distributed training of massive machine learning models, in particular deep neural networks, via Stochastic Gradient Descent (SGD) is becoming commonplace. Several families of communication-reduction methods, such as quantization, large-batch methods, and gradient sparsification, have been proposed. To date, gradient sparsification methods--where each node sorts gradients by magnitude, and only communicates a subset of the components, accumulating the rest locally--are known to yield some of the largest practical gains. Such methods can reduce the amount of communication per step by up to \emph{three orders of magnitude}, while preserving model accuracy. Yet, this family of methods currently has no theoretical justification. 
382. **Memory Replay GANs: Learning to Generate New Categories without Forgetting** --*Chenshen Wu &middot; Xialei Liu &middot; yaxing wang &middot; Luis Herranz &middot; Bogdan Raducanu &middot; Joost van de Weijer*
 > Previous works on sequential learning address the problem of forgetting in discriminative models. In this paper we consider the case of generative models. In particular, we investigate generative adversarial networks (GANs) in the task of learning new categories in a sequential fashion. We first show that sequential fine tuning renders the network unable to properly generate images from previous categories (i.e. forgetting). Addressing this problem, we propose Memory Replay GANs (MeRGANs), a conditional GAN framework that integrates a memory replay generator. We study two methods to prevent forgetting by leveraging these replays, namely joint training with replay and replay alignment. Qualitative and quantitative experimental results in MNIST, SVHN and LSUN datasets show that our memory replay approach can generate competitive images while significantly mitigating the forgetting of previous categories.
383. **Constructing Fast Network through Deconstruction of Convolution** --*Yunho Jeon &middot; Junmo Kim*
 > Convolutional neural networks have achieved great success in various vision tasks; however, they incur heavy resource costs. By using deeper and wider networks, network accuracy can be improved rapidly. However, in an environment with limited resources (e.g., mobile applications), heavy networks may not be usable. This study deconstructs naive convolution into a shift operation and pointwise convolution. To cope with various convolutions, we propose a new shift operation called active shift layer (ASL) that formulates the amount of shift as a learnable function with shift parameters. This new layer can be optimized end-to-end through backpropagation and provide optimal shift values. Finally, we apply this layer to a light and fast network that surpasses existing state-of-the-art networks.
384. **Exact natural gradient in deep linear networks and its application to the nonlinear case** --*Alberto Bernacchia &middot; Mate Lengyel &middot; Guillaume Hennequin*
 > Stochastic gradient descent (SGD) remains the method of choice for deep learning, despite the limitations arising for ill-behaved objective functions. In cases where it could be estimated, the natural gradient has proven very effective at mitigating the catastrophic effects of pathological curvature in the objective function, but little is known theoretically about its convergence properties, and it has yet to find a practical implementation that would scale to very deep and large networks. Here, we derive an exact expression for the natural gradient in deep linear networks, which exhibit pathological curvature similar to the nonlinear case, and provide for the first time an analytical solution for its convergence rate, showing that natural gradient descent converges exponentially fast to the global minimum in parameter space. Our expression for the natural gradient is surprisingly simple, computationally tractable, and explains why some approximations proposed previously work well in practice. This opens new avenues for approximating the natural gradient in the nonlinear case, and we show that, promisingly, our online natural gradient descent outperforms SGD for MNIST autoencoders while sharing its computational simplicity.
385. **Deep Generative Models for Distribution-Preserving Lossy Compression** --*Michael Tschannen &middot; Eirikur Agustsson &middot; Mario Lucic*
 > We propose and study the problem of distribution-preserving lossy compression. Motivated by the recent advances in extreme image compression which allow to maintain artifact-free reconstructions even at very low bitrates, we propose to optimize the rate-distortion tradeoff under the constraint that the reconstructed samples follow the distribution of the training data. Such a compression system recovers both ends of the spectrum: On one hand, at zero bitrate it learns a generative model of the data, and at high enough bitrates it achieves perfect reconstruction. Furthermore, for intermediate bitrates it smoothly interpolates between matching the distribution of the training data and perfectly reconstructing the training samples. We study several methods to approximately solve the proposed optimization problem, including a novel combination of Wasserstein GAN and Wasserstein Autoencoder, and present strong theoretical and empirical results for the proposed compression system.
386. **Binary Classification from Positive-Confidence Data** --*Takashi Ishida &middot; Gang Niu &middot; Masashi Sugiyama*
 > Reducing labeling costs in supervised learning is a critical issue in many practical machine learning applications.  In this paper, we consider positive-confidence (Pconf) classification, the problem of training a binary classifier only from positive data equipped with confidence.  Pconf classification can be regarded as a discriminative extension of one-class classification (which is aimed at <code>describing'' the positive class by clustering-related methods), with ability to tune hyper-parameters for</code>classifying'' positive and negative samples.  Pconf classification is also related to positive-unlabeled (PU) classification (which uses hard-labeled positive data and unlabeled data), but the difference is that it enables us to avoid estimating the class priors, which is a critical bottleneck in typical PU classification methods.  For the Pconf classification problem, we provide a simple empirical risk minimization framework and give a formulation for linear-in-parameter models that can be implemented easily and computationally efficiently.  We also theoretically establish the consistency and an estimation error bound for Pconf classification, and demonstrate the practical usefulness of the proposed method for deep neural networks through experiments.
387. **Diverse Ensemble Evolution: Curriculum based Data-Model Marriage** --*Tianyi Zhou &middot; Shengjie Wang &middot; Jeff A Bilmes*
 > We study how to train an ensemble of models based on their changing diversity requirements and expertise. Previous ensemble methods usually determine diversity before training starts, either by resampling training data or via random initialization. Instead, we propose ``Diverse Ensemble Evolution (DivE$^2$),'' a method that assigns data to models at each training epoch, based on their capabilities and a scheduled diversity requirement. DivE$^2$ starts with selecting easy-to-learn samples for every model, and slowly moves to selecting models with accurate predictions for a data sample. To expand the realm of expertise for each model while enforcing diversity over all models, we propose an intra-model diversity term on data assigned to each model, and an inter-model diversity term to penalize redundancy over data assigned to different models. We formulate such data assignment problem as a generalized bipartite matching problem with two partition matroid constraints. DivE$^2$ solves a sequence of continuous-combinatorial optimizations with slowly varying objectives and constraints. The combinatorial part handles the data assignment with submodular maximization, and the continuous part updates model based on the assigned data. In experiments, DivE$^2$ outperforms other ensemble training methods under several inference techniques while maintaining competitive efficiency.
388. **Dual Swap Disentangling** --*Zunlei Feng &middot; Xinchao Wang &middot; Chenglong Ke &middot; An-Xiang Zeng &middot; Dacheng Tao &middot; Mingli Song*
 > Learning interpretable disentangled representations is a crucial yet challenging task. In this paper, we propose a weakly semi-supervised method, termed as \emph{Dual Swap Disentangling~(DSD)}, for disentangling using both labeled and unlabeled data. Unlike conventional weakly supervised methods that rely on full annotations on the group of samples, we require only limited annotations on paired samples that indicate their shared attribute like the color. Our model takes the form of a dual autoencoder structure. To achieve disentangling using the labeled pairs, we follow a <code>encoding-swap-decoding'' process, where we first swap the parts of their encodings corresponding to the shared attribute, and then decode the obtained hybrid codes to reconstruct the original input pairs. For unlabeled pairs, we follow the</code>encoding-swap-decoding'' process twice on designated encoding parts and enforce the final outputs to approximate the input pairs. By isolating parts of the encoding and swapping them back and forth, we impose the dimension-wise modularity and portability of the encodings of the unlabeled samples, which implicitly encourages disentangling under the guidance of labeled pairs. This dual swap mechanism, tailored for semi-supervised setting, turns out to be very effective. Experiments on image datasets from a wide domain show that our model yields state-of-the-art disentangling performances.
389. **A Bayes-Sard Cubature Method** --*Toni Karvonen &middot; Chris J Oates &middot; Simo Sarkka*
 > This paper focusses on the formulation of numerical integration as an inferential task. To date, research effort has largely focussed on the development of Bayesian cubature, whose distributional output provides uncertainty quantification for the integral. However, the point estimators associated to Bayesian cubature can be inaccurate and acutely sensitive to the prior when the domain is high-dimensional. To address these drawbacks we introduce Bayes–Sard cubature, a probabilistic framework that combines the flexibility of Bayesian cubature with the robustness of classical cubatures which are well-established. This is achieved by considering a Gaussian process model for the integrand whose mean is a parametric regression model, with an improper flat prior on each regression coefficient. The features in the regression model consist of test functions which are guaranteed to be exactly integrated, with remaining degrees of freedom afforded to the non-parametric part. The asymptotic convergence of the Bayes–Sard cubature method is established and the theoretical results are numerically verified. In particular, we report two orders of magnitude reduction in error compared to Bayesian cubature in the context of a high-dimensional financial integral.
390. **Practical Deep Stereo (PDS): Toward applications-friendly deep stereo matching** --*Stepan Tulyakov &middot; Anton Ivanov &middot; François Fleuret*
 > End-to-end deep-learning networks recently demonstrated extremely good performance for stereo matching. However, existing networks are difficult to use for practical applications since (1) they are memory-hungry and unable to process even modest-size images, (2) they have to be fully re-trained to handle a different disparity range.
391. **Differential Properties of Sinkhorn Approximation for Learning with Wasserstein Distance** --*Giulia Luise &middot; Alessandro Rudi &middot; Massimiliano Pontil &middot; Carlo Ciliberto*
 > Applications of optimal transport have recently gained remarkable attention as a result of the computational advantages of entropic regularization. However, in most situations the  Sinkhorn approximation to the Wasserstein distance is replaced by a regularized version that is less accurate but easy to differentiate. In this work we characterize the differential properties of the original Sinkhorn distance, proving that it enjoys the same smoothness of its regularized version and we explicitly provide an efficient algorithm to compute its gradient. We show that this result benefits both theory and applications: on one hand, high order smoothness confers statistical guarantees to learning with Wasserstein approximations. On the other hand, the gradient formula allows to efficiently solve learning and optimization problems in practice. Promising preliminary experiments complement our analysis. 
392. **On GANs and GMMs** --*Eitan Richardson &middot; Yair Weiss*
 > A longstanding problem in machine learning is to find unsupervised methods that can learn the statistical structure of high dimensional signals. In recent years, GANs have gained much attention as a possible solution to the problem, and in particular have shown the ability to generate remarkably realistic high resolution sampled images. At the same time, many authors have pointed out that GANs may fail to model the full distribution ("mode collapse") and that using the learned models for anything other than generating samples may be very difficult. In this paper, we examine the utility of GANs in learning statistical models of images by comparing them to perhaps the simplest statistical model, the  Gaussian Mixture Model. First, we present a simple method to evaluate generative models based on relative proportions of samples that fall into predetermined bins. Unlike previous automatic methods for evaluating models, our method does not rely on an additional neural network nor does it require  approximating intractable computations.  Second, we compare the performance of GANs to GMMs trained on the same datasets. While GMMs have previously been shown to be successful in modeling small patches of images, we show how to  train them on full sized images despite the high dimensionality. Our results show that  GMMs can generate realistic samples (although less sharp than those of GANs) but also capture the full distribution which  GANs fail to do. Furthermore, GMMs allow efficient inference and explicit representation of the underlying statistical structure.  Finally, we discuss how a pix2pix network can be used to add high-resolution details to GMM samples while maintaining the basic diversity.
393. **Masking: A New Perspective of Noisy Supervision** --*Bo Han &middot; Jiangchao Yao &middot; Gang Niu &middot; Mingyuan Zhou &middot; Ivor Tsang &middot; Ya Zhang &middot; Masashi Sugiyama*
 > It is important to learn classifiers under noisy labels due to their ubiquities. As noisy labels are corrupted from ground-truth labels by an unknown noise transition matrix, the accuracy of classifiers can be improved by estimating this matrix, without introducing either sample-selection or regularization biases. However, such estimation is often inexact, which inevitably degenerates the accuracy of classifiers. The inexact estimation is due to either a heuristic trick, or the brutal-force learning by deep networks under a finite dataset. In this paper, we present a human-assisted approach called ``\textit{masking}''. The masking conveys human cognition of invalid class transitions, and naturally speculates the structure of the noise transition matrix. Given the structure information, we only learn the sparse noise transition probability to reduce the estimation burden. To instantiate this approach, we derive a structure-aware probabilistic model, which incorporates a structure prior. During the model realization, we solve the challenges from structure extraction and alignment in principle. Empirical results on benchmark datasets with three noise structures show that, our approach can improve the robustness of classifiers significantly.
394. **Gamma-Poisson Dynamic Matrix Factorization Embedded with Metadata Influence** --*Trong Dinh Thac Do &middot; Longbing Cao*
 > A conjugate Gamma-Poisson model for Dynamic Matrix Factorization incorporated with metadata influence (mGDMF for short) is proposed to effectively and efficiently model massive, sparse and dynamic data in recommendations. Modeling recommendation problems with a massive amount of ratings and very sparse or even no ratings on some users/items in a dynamic setting is very demanding and poses critical challenges for well-studied matrix factorization models due to the large-scale, sparse and dynamic nature of the data. Our proposed mGDMF tackles these challenges by introducing three strategies: (1) constructing a stable Gamma-Markov chain model that smoothly drifts over time by combining both static and dynamic latent features of data; (2) incorporating the user/item metadata into the model to tackle sparse ratings; and (3) undertaking stochastic variational inference to  efficiently handle massive data. mGDMF is conjugate, dynamic and scalable. Experiments show that mGDMF significantly (both effectively and efficiently) outperforms the state-of-the-art static and dynamic models on large, sparse and dynamic data.
396. **Transparency by Disentangling Interactions** --*Michael Tsang &middot; Hanpeng Liu &middot; Sanjay Purushotham &middot; Pavankumar Murali &middot; Yan Liu*
 > Neural networks are known to model statistical interactions, but they entangle the interactions at intermediate hidden layers for shared representation learning. We propose a framework, DI, that Disentangles Interactions by  counteracting the shared learning across different interactions to obtain their intrinsic lower-order and interpretable structure. This is done through a novel regularizer that directly penalizes interaction order. We show that disentangling interactions reduces a feedforward neural network to a generalized additive model with interactions, which can lead to transparent models that perform comparably to the state-of-the-art models. DI is also flexible and efficient; it can learn generalized additive models with maximum K-order interactions by training only $O(1)$ models.
397. **Computing Kantorovich-Wasserstein Distances on $d$-dimensional histograms using $(d+1)$-partite graphs** --*Stefano Gualandi &middot; Gennaro Auricchio &middot; Marco Veneroni &middot; Federico Bassetti*
 > This paper presents a novel method to compute the exact Kantorovich-Wasserstein distance between a pair of $d$-dimensional histograms having $n$ bins each. We prove that this problem is equivalent to an uncapacitated minimum cost flow problem on a $(d+1)$-partite graph with $(d+1)n$ nodes and $dn^{\frac{d+1}{d}}$ arcs, whenever the cost is separable along the principal $d$-dimensional directions. We show numerically the benefits of our approach by computing the Kantorovich-Wasserstein distance of order 2 among two sets of instances: gray scale images and $d$-dimensional biomedical histograms. On these types of instances, our approach is competitive with state-of-the-art optimal transport algorithms.
398. **Loss Functions for Multiset Prediction** --*Sean Welleck &middot; Zixin Yao &middot; Yu Gai &middot; Jialin Mao &middot; Zheng Zhang &middot; Kyunghyun Cho*
 > We study the problem of multiset prediction. The goal of multiset prediction is to train a predictor that maps an input to a multiset consisting of multiple items. Unlike existing problems in supervised learning, such as classification, ranking and sequence generation, there is no known order among items in a target multiset, and each item in the multiset may appear more than once, making this problem extremely challenging. In this paper, we propose a novel multiset loss function by viewing this problem from the perspective of sequential decision making. The proposed multiset loss function is empirically evaluated on two families of datasets, one synthetic and the other real, with varying levels of difficulty, against various baseline loss functions including reinforcement learning, sequence, and aggregated distribution matching loss functions. The experiments reveal the effectiveness of the proposed loss function over the others.
399. **Learning to Multitask** --*Yu Zhang &middot; Ying Wei &middot; Qiang Yang*
 > Multitask learning has shown promising performance in many applications and many multitask models have been proposed. In order to identify an effective multitask model for a given multitask problem, we propose a learning framework called learning to multitask (L2MT). To achieve the goal, L2MT exploits historical multitask experience which is organized as a training set consists of several tuples, each of which contains a multitask problem with multiple tasks, a multitask model and the relative test error. Based on such training set, L2MT first uses a proposed layerwise graph neural network to learn task embeddings for all the tasks in a multitask problem and then learns an estimation function to estimate the relative test error based on task embeddings and the representation of the multitask model based on a unified formulation. Given a new multitask problem, the estimation function is used to identify a suitable multitask model. Experiments on benchmark datasets show the effectiveness of the proposed L2MT method.
400. **Adversarially Robust Optimization with Gaussian Processes** --*Ilija Bogunovic &middot; Jonathan Scarlett &middot; Stefanie Jegelka &middot; Volkan Cevher*
 > In this paper, we consider the problem of Gaussian process (GP) optimization with an added robustness requirement: The returned point may be perturbed by an adversary, and we require the function value to degrade as little as possible as a result. This problem is motivated by settings where the underlying functions during optimization and implementation stages are different (e.g., due to time variations), or when one is interested in finding an entire region of good inputs rather than only a single point. We show that standard GP optimization algorithms do not exhibit the desired robustness properties, and give a novel confidence bound based algorithm StableOPT for this purpose. We rigorously establish the required number of samples for StableOPT to find a near-optimal point, and we complement this guarantee with an algorithm-independent lower bound. We experimentally demonstrate a variety of potential applications of interest on real world data sets, and we show that StableOPT consistently succeeds in finding a stable maximizer where several baseline methods fail.
401. **Mental Sampling in Multimodal Representations** --*Jianqiao Zhu &middot; Adam Sanborn &middot; Nick Chater*
 > Both resources in the natural environment and concepts in a semantic space are distributed "patchily", with large gaps in between the patches. To describe people's internal and external foraging behavior, various random walk models have been proposed. In particular, internal foraging has been modeled as sampling: in order to gather relevant information for making a decision, people draw samples from a mental representation using random-walk algorithms such as Markov chain Monte Carlo (MCMC). However, two common empirical observations argue against people using simple sampling algorithms such as MCMC for internal foraging. First, the distance between samples is often best described by a Levy flight distribution: the probability of the distance between two successive locations follows a power-law on the distances. Second, humans and other animals produce long-range, slowly decaying autocorrelations characterized as 1/f-like fluctuations, instead of the 1/f^2 fluctuations produced by random walks. We propose that mental sampling is not done by simple MCMC, but is instead adapted to multimodal representations and is implemented by Metropolis-coupled Markov chain Monte Carlo (MC3), one of the first algorithms developed for sampling from multimodal distributions. MC3 involves running multiple Markov chains in parallel but with target distributions of different temperatures, and it swaps the states of the chains whenever a better location is found. Heated chains more readily traverse valleys in the probability landscape to propose moves to far-away peaks, while the colder chains make the local steps that explore the current peak or patch. We show that MC3 generates distances between successive samples that follow a Levy flight distribution and produce 1/f-like autocorrelations, providing a single mechanistic account of these two puzzling empirical phenomena of internal foraging.
402. **Variational Inference with Tail Adapted f-Divergence** --*Dilin Wang &middot; Hao Liu &middot; Qiang Liu*
 > Variational inference with alpha-divergences has been widely used in modem probabilistic machine learning. Compared to Kullback-Leibler (KL) divergence, a major advantage of using alpha-divergences is their mass-covering property. However, alpha-divergences require importance sampling to estimate and optimize, which can be extremely ineffective when the importance weights have a heavy tail. In this paper, we propose new variants of f-divergences that adaptively change with the tail of the importance ratios. Compared to alpha-divergences, our approach theoretically guarantees finite mean of importance weights and simultaneously produce overdispersed approximations. We test our methods on Bayesian neural networks and Reinforcement learning in which our method is applied to improve a recent soft actor-critic (SAC) algorithm. Our results show that our approach yields significant advantages compared with classic KL and alpha-divergence based VI. 
403. **Insights on representational similarity in neural networks with canonical correlation** --*Ari Morcos &middot; Maithra Raghu &middot; Jascha Sohl-Dickstein &middot; Samy Bengio*
 > Comparing different neural network representations and determining how representations evolve over time remain challenging open questions in our understanding of the function of neural networks. Comparing representations in neural networks is fundamentally difficult as the structure of representations varies greatly, even across groups of networks trained on identical tasks, and over the course of training. Here, we develop projection weighted CCA (Canonical Correlation Analysis) as a tool for understanding neural networks, building off of SVCCA, a recently proposed method. We first improve the core method, showing how to differentiate between signal and noise, and then apply this technique to compare across a group of CNNs, demonstrating that networks which generalize converge to more similar representations than networks which memorize, that wider networks converge to more similar solutions than narrow networks, and that trained networks converge to distinct clusters with diverse representations. We also investigate the representational dynamics of RNNs, across both training and sequential timesteps, finding that RNNs converge in a bottom-up pattern over the course of training and that the hidden state is highly variable over the course of a sequence, even when accounting for linear transforms. Together, these results provide new insights into the function of CNNs and RNNs, and demonstrate the utility of using CCA to understand representations.
405. **Learning convex polytopes with margin** --*Lee-Ad Gottlieb &middot; Eran Kaufman &middot; Aryeh Kontorovich &middot; Gabriel Nivasch*
 > We present a near-optimal algorithm for properly learning convex polytopes in the realizable PAC setting from data with a margin. Our first contribution is to identify distinct generalizations of the notion of {\em margin} from hyperplanes to polytopes and to understand how they relate geometrically; this result may be of interest beyond the learning setting. Our novel learning algorithm constructs a consistent polytope as an intersection of about $t \log t$ halfspaces in time polynomial in $t$ (where $t$ is the number of halfspaces forming an optimal polytope). This is an exponential improvement over the state of the art [Arriaga and Vempala, 2006]. We also improve over the super-polynomial-in-$t$ algorithm of Klivans and Servedio [2008], while achieving a better sample complexity. Finally, we provide the first nearly matching hardness-of-approximation lower bound, whence our claim of near optimality.
406. **Efficient inference for time-varying behavior during learning** --*Nicholas Roy &middot; Ji Hyun Bak &middot; Athena Akrami &middot; Carlos Brody &middot; Jonathan W Pillow*
 > The process of learning new behaviors is of great interest to various domains of neuroscience and artificial intelligence. However, most standard analyses of training data either treat behavior as fixed or track only coarse performance statistics (e.g., accuracy, choice bias), providing limited insight into evolving behavioral strategies. To overcome these limitations, we propose a dynamic psychophysical model that efficiently tracks trial-to-trial changes in behavior over the course of training. Based on a dynamic logistic regression model, our model infers a high-dimensional time-varying weight vector that expresses the dynamic dependencies of behavior on task stimuli and common task-irrelevant variables including choice history, sensory history, reward history, and choice bias. Our implementation scales to the largest behavioral datasets, allowing us to infer 500K parameters (e.g. 10 weights over 50K trials) in a few hours on a desktop computer. We optimize hyperparameters with the decoupled Laplace approximation, an efficient method for maximizing marginal likelihood that allows us to estimate directly from the data how quickly each weight evolves. To illustrate performance and utility, we apply our method to psychophysical data from both human subjects and rats learning the same delayed sensory discrimination task. We successfully track the dynamics of psychophysical weights during training, capturing day-to-day and trial-to-trial fluctuations that underly changes in performance, choice bias, and dependencies on task history. Finally, we leverage the flexibility of our model to investigate why rats frequently make mistakes on easy trials, demonstrating that this lapse phenomenon occurs due to sub-optimal weighting of task covariates.
407. **Unsupervised Video Object Segmentation for Deep Reinforcement Learning** --*Vikash Goel &middot; Jameson Weng &middot; Pascal Poupart*
 > We present a new technique for deep reinforcement learning that automatically detects moving objects and uses the relevant information for action selection. The detection of moving objects is done in an unsupervised way by exploiting structure from motion. Instead of directly learning a policy from raw images, the agent first learns to detect and segment moving objects by exploiting flow information in video sequences.  The learned representation is then used to focus the policy of the agent on the moving objects. Over time, the agent identifies which objects are critical for decision making and gradually builds a policy based on relevant moving objects. This approach, which we call Motion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of Atari games where the ability to detect moving objects reduces the amount of interaction needed with the environment to obtain a good policy.  Furthermore, the resulting policy is more interpretable than policies that directly map images to actions or values with a black box neural network. We can gain insight into the policy by inspecting the segmentation and motion of each object detected by the agent. This allows practitioners to confirm whether a policy is making decisions based on sensible information.
408. **On Fast Leverage Score Sampling and Optimal Learning** --*Alessandro Rudi &middot; Daniele Calandriello &middot; Luigi Carratino &middot; Lorenzo Rosasco*
 > Leverage score sampling provides an appealing way to perform approximate computations for large matrices. Indeed, it allows to derive  faithful approximations with a  complexity  adapted to the  problem at hand.  Yet, performing leverage scores  sampling  is a challenge in its own right and further approximations  are typically needed.  In this paper, we study the problem of leverage score sampling for positive definite matrices defined by a kernel.  Our contribution is twofold. First we provide a novel   algorithm for leverage score sampling. We provide theoretical guarantees as well as empirical results proving that the  proposed algorithm is currently the fastest and most accurate solution to this problem. Second, we analyze the properties of the proposed method in a downstream supervised learning task. Combining several algorithmic ideas, we derive the fastest solver for kernel ridge regression and Gaussian process regression  currently available. Also in this case, theoretical findings   are corroborated by experimental results.
409. **Bandit Learning in Concave N-Person Games** --*Mario Bravo &middot; David Leslie &middot; Panayotis Mertikopoulos*
 > This paper examines the long-run behavior of learning with bandit feedback in non-cooperative concave games. The bandit framework accounts for extremely low-information environments where the agents may not even know they are playing a game; as such, the agents’ most sensible choice in this setting would be to employ a no-regret learning algorithm. In general, this does not mean that the players' behavior stabilizes in the long run: no-regret learning may lead to cycles, even with perfect gradient information. However, if a standard monotonicity condition is satisfied, our analysis shows that no-regret learning based on mirror descent with bandit feedback converges to Nash equilibrium with probability 1. We also derive an upper bound for the convergence rate of the process that nearly matches the best attainable rate for single-agent bandit stochastic optimization.
410. **Online Improper Learning with an Approximation Oracle** --*Elad Hazan &middot; Wei Hu &middot; Yuanzhi Li &middot; Zhiyuan Li*
 > We study the following question: given an efficient approximation algorithm for an optimization problem, can we learn efficiently in the same setting? We give a formal affirmative answer to this question in the form of a reduction from online learning to offline approximate optimization using an efficient algorithm that guarantees near optimal regret. The algorithm is efficient in terms of the number of oracle calls to a given approximation oracle – it makes only logarithmically many such calls per iteration. This resolves an open question by Kalai and Vempala, and by Garber.
411. **Contextual Pricing for Lipschitz Buyers** --*Jieming Mao &middot; Renato Leme &middot; Jon Schneider*
 > We investigate the problem of learning a Lipschitz function from binary   feedback. In this problem, a learner is trying to learn a Lipschitz function   $f:[0,1]^d \rightarrow [0,1]$ over the course of $T$ rounds. On round $t$, an   adversary provides the learner with an input $x_t$, the learner submits a   guess $y_t$ for $f(x_t)$, and learns whether $y_t > f(x_t)$ or $y_t \leq   f(x_t)$. The learner's goal is to minimize their total loss $\sum_t\ell(f(x_t),   y_t)$ (for some loss function $\ell$). The problem is motivated by \textit{contextual dynamic pricing},   where a firm must sell a stream of differentiated products to a collection of   buyers with non-linear valuations for the items and observes only whether the   item was sold or not at the posted price.    For the symmetric loss $\ell(f(x_t), y_t) = \vert f(x_t) - y_t \vert$,  we   provide an algorithm for this problem achieving total loss $O(\log T)$   when $d=1$ and $O(T^{(d-1)/d})$ when $d>1$, and show that both bounds are   tight (up to a factor of $\sqrt{\log T}$). For the pricing loss function   $\ell(f(x_t), y_t) = f(x_t) - y_t {\bf 1}\{y_t \leq f(x_t)\}$ we show a regret   bound of $O(T^{d/(d+1)})$ and show that this bound is tight. We present   improved bounds in the special case of a population of linear buyers.
412. **Learning Others' Intentional Models in Multi-Agent Settings Using Interactive POMDPs** --*Yanlin Han &middot; Piotr Gmytrasiewicz*
 > Interactive partially observable Markov decision processes (I-POMDPs) provide a principled framework for planning and acting in a partially observable, stochastic and multi-agent environment. It extends POMDPs to multi-agent settings by including models of other agents in the state space and forming a hierarchical belief structure. In order to predict other agents' actions using I-POMDPs, we propose an approach that effectively uses Bayesian inference and sequential Monte Carlo sampling to learn others' intentional models which ascribe to them beliefs, preferences and rationality in action selection. Empirical results show that our algorithm accurately learns models of the other agent and has superior performance than other methods. Our approach serves as a generalized Bayesian learning algorithm that learns other agents' beliefs, and transition, observation and reward functions. It also effectively mitigates the belief space complexity due to the nested belief hierarchy. 
413. **Fast Greedy MAP Inference for Determinantal Point Process to Improve Recommendation Diversity** --*Laming Chen &middot; Guoxin Zhang &middot; Hanning Zhou*
 > The determinantal point process (DPP) is an elegant probabilistic model of repulsion with applications in various machine learning tasks including summarization and search. However, the maximum a posteriori (MAP) inference for DPP which plays an important role in many applications is NP-hard, and even the popular greedy algorithm can still be too computationally expensive to be used in large-scale real-time scenarios. To overcome the computational challenge, in this paper, we propose a novel algorithm to greatly accelerate the greedy MAP inference for DPP. In addition, our algorithm also adapts to scenarios where the repulsion is only required among nearby few items in the result sequence. We apply the proposed algorithm to generate relevant and diverse recommendations. Experimental results show that our proposed algorithm is significantly faster than state-of-the-art competitors, and provides a better relevance-diversity trade-off on several public datasets, which is also confirmed in an online A/B test.
414. **Manifold Structured Prediction** --*Alessandro Rudi &middot; Carlo Ciliberto &middot; Gian Marconi &middot; Lorenzo Rosasco*
 > Structured prediction provides a general framework to deal with supervised problems where the outputs have semantically rich structure. While classical approaches consider finite, albeit potentially huge, output spaces, in this paper we discuss how structured prediction can be extended to a continuous scenario. Specifically, we study a structured prediction approach to manifold-valued regression. We characterize a class of problems for which the considered approach is statistically consistent and study how geometric optimization can be used to compute the corresponding estimator. Promising experimental results on both simulated and real data complete our study.
415. **Impossibility of deducing preferences and rationality from human policy** --*Stuart Armstrong &middot; Sören Mindermann*
 > Inverse reinforcement learning (IRL) attempts to infer human rewards or preferences from observed behavior. Since human planning systematically deviates from rationality, several approaches have been tried to account for specific human shortcomings. However, there has been little analysis of the general problem of inferring the reward of a human of unknown rationality. The observed behavior can, in principle, be decomposed into two components: a reward function and a planning algorithm, both of which have to be inferred from behavior. This paper presents a No Free Lunch theorem, showing that, without making `normative' assumptions beyond the data, nothing about the human reward function can be deduced from human behavior. Unlike most No Free Lunch theorems, this cannot be alleviated by regularising with simplicity assumptions. We show that the simplest hypotheses which explain the data are generally degenerate.
416. **How Much Restricted Isometry is Needed In Nonconvex Matrix Recovery?** --*Richard Zhang &middot; Cedric Josz &middot; Somayeh Sojoudi &middot; Javad Lavaei*
 > When the linear measurements of an instance of low-rank matrix recovery satisfy a restricted isometry property (RIP) --- i.e. they are approximately norm-preserving --- the problem is known to contain no spurious local minima, so exact recovery is guaranteed. In this paper, we show that moderate RIP is not enough to eliminate spurious local minima, so existing results can only hold for near-perfect RIP. In fact, counterexamples are ubiquitous: every $x$ is the spurious local minimum of a rank-1 instance of matrix recovery that satisfies RIP. One specific counterexample has RIP constant $\delta=1/2$, but causes randomly initialized stochastic gradient descent (SGD) to fail 12\% of the time. SGD is frequently able to avoid and escape spurious local minima, but this empirical result shows that it can occasionally be defeated by their existence. Hence, while exact recovery guarantees will likely require a proof of no spurious local minima, arguments based solely on norm preservation will only be applicable to a narrow set of nearly-isotropic instances.
417. **Multimodal Generative Models for Scalable Weakly-Supervised Learning** --*Mike Wu &middot; Noah Goodman*
 > Multiple modalities often co-occur when describing natural phenomena. Learning a joint representation of these modalities should yield deeper and more useful representations. Previous generative approaches to multi-modal input either do not learn a joint distribution or require additional computation to handle missing data. Here, we introduce a multimodal variational autoencoder (MVAE) that uses a product-of-experts inference network and a sub-sampled training paradigm to solve the multi-modal inference problem. Notably, our model shares parameters to efficiently learn under any combination of missing modalities. We apply the MVAE on four datasets and show that we match state-of-the-art performance using many fewer parameters. In addition, we show that the MVAE is directly applicable to weakly-supervised learning, and is robust to incomplete supervision. We then consider a case study of learning image transformations—edge detection, colorization, facial landmark segmentation, etc.—as a set of modalities. We find appealing results across this range of tasks.
418. **A Simple Proximal Stochastic Gradient Method for Nonsmooth Nonconvex Optimization** --*Zhize Li &middot; Jian Li*
 > We analyze stochastic gradient algorithms for optimizing nonconvex, nonsmooth finite-sum problems. In particular, the objective function is given by the summation of a differentiable (possibly nonconvex) component, together with a possibly non-differentiable but convex component. We propose a proximal stochastic gradient algorithm based on variance reduction, called ProxSVRG+. Our main contribution lies in the analysis of ProxSVRG+. It recovers several existing convergence results (in terms of the number of stochastic gradient oracle calls and proximal operations), and improves/generalizes them. In particular, ProxSVRG+ generalizes the best results given by the SCSG (stochastically controlled stochastic gradient) algorithm, recently proposed by [Lei et al., NIPS'17] for the smooth nonconvex case. ProxSVRG+ is more straightforward than SCSG and yields simpler analysis. Moreover, ProxSVRG+ outperforms the deterministic proximal gradient descent (ProxGD) for a wide range of minibatch sizes, which partially solves an open problem proposed in [Reddi et al., NIPS'16]. Also, ProxSVRG+ uses much less proximal oracle calls than ProxSVRG [Reddi et al., NIPS'16] if minibatch size $b<n^{2/3}$. Besides, for nonconvex functions satisfied Polyak-\L{}ojasiewicz condition, we show that ProxSVRG+ achieves global linear convergence rate without restart unlike ProxSVRG. ProxSVRG+ also improves ProxGD and ProxSVRG/SAGA, and generalizes the results of SCSG in this case. Finally, we conduct several numerical experiments and the experimental results are consistent with the theoretical results.
419. **Reparameterization Gradient for Non-differentiable Models** --*Wonyeol Lee &middot; Hangyeol Yu &middot; Hongseok Yang*
 > We present a new algorithm for stochastic variational inference that targets at models with non-differentiable densities. One of the key challenges in stochastic variational inference is to come up with a low-variance estimator of the gradient of a variational objective. We tackle the challenge by generalizing the reparameterization trick, one of the most effective techniques for addressing the variance issue for differentiable models, so that the trick works for non-differentiable models as well. Our algorithm splits the space of latent variables into regions where the density of the variables is differentiable, and their boundaries where the density may fail to be differentiable. For each differentiable region, the algorithm applies the standard reparameterization trick and estimates the gradient restricted to the region. For each potentially non-differentiable boundary, it uses a form of manifold sampling and computes the direction for variational parameters that, if followed, would increase the boundary’s contribution to the variational objective. The sum of all the estimates becomes the gradient estimate of our algorithm. Our estimator enjoys the reduced variance of the reparameterization gradient while remaining unbiased even for non-differentiable models. The experiments with our preliminary implementation confirm the benefit of reduced variance and unbiasedness.
420. **To Trust Or Not To Trust A Classifier** --*Heinrich Jiang &middot; Been Kim &middot; Maya Gupta*
 > Knowing when a classifier's prediction can be trusted is useful in many applications and critical for safely using AI. While the bulk of the effort in machine learning research has been towards improving classifier performance, understanding when a classifier's predictions should and should not be trusted has received far less attention. The standard approach is to use the classifier's discriminant or confidence score; however, we show there exists a considerably more effective alternative.
421. **First-order Stochastic Algorithms for Escaping From Saddle Points in Almost Linear Time** --*Yi Xu &middot; Jing Rong &middot; Tianbao Yang*
 > (This is a theory paper) In this paper, we consider first-order methods for solving stochastic non-convex optimization problems. The key building block of the proposed algorithms is first-order procedures to extract negative curvature from the Hessian matrix through a principled sequence starting from noise, which are referred to {\it NEgative-curvature-Originated-from-Noise or NEON} and are of independent interest. Based on this building block, we design purely first-order stochastic algorithms for escaping from non-degenerate saddle points with a much better time complexity (almost linear time in  the problem's dimensionality). In particular, we develop a general framework of {\it first-order stochastic algorithms} with a second-order convergence guarantee based on our new technique and existing algorithms that may only converge to a first-order stationary point. For finding a nearly {\it second-order stationary point} $\x$ such that $\|\nabla F(\x)\|\leq \epsilon$ and $\nabla^2 F(\x)\geq -\sqrt{\epsilon}I$ (in high probability), the best time complexity of the presented algorithms is $\widetilde O(d/\epsilon^{3.5})$, where $F(\cdot)$ denotes the objective function and $d$ is the dimensionality of the problem. To the best of our knowledge, this is the first theoretical result of first-order stochastic algorithms with an almost linear time in terms of problem's dimensionality for finding second-order stationary points, which is  even competitive with  existing stochastic algorithms hinging on the second-order information. 
423. **Inference Aided Reinforcement Learning for Incentive Mechanism Design in Crowdsourcing** --*Zehong Hu &middot; Yitao Liang &middot; Yang Liu &middot; Jie Zhang*
 > Incentive mechanisms for crowdsourcing are designed to incentivize financially self-interested workers to generate and report high-quality labels. Existing mechanisms are often developed as one-shot static solutions, assuming a certain level of knowledge about worker models (expertise levels, costs for exerting efforts, etc.). In this paper, we propose a novel inference aided reinforcement mechanism that acquires data sequentially and requires no such prior assumptions. Specifically, we first design a Gibbs sampling augmented Bayesian inference algorithm to estimate workers' labeling strategies from the collected labels at each step. Then we propose a reinforcement incentive learning (RIL) method, building on top of the above estimates, to uncover how workers respond to different payments. RIL dynamically determines the payment without accessing any ground-truth labels. We theoretically prove that RIL is able to incentivize rational workers to provide high-quality labels both at each step and in the long run. Empirical results show that our mechanism performs consistently well under both rational and non-fully rational (adaptive learning) worker models. Besides, the payments offered by RIL are more robust and have lower variances compared to existing one-shot mechanisms.
424. **Low-rank Interaction with Sparse Additive Effects Model for Large Data Frames** --*Geneviève Robin &middot; Hoi-To Wai &middot; Julie Josses &middot; Olga Klopp &middot; Eric Moulines*
 > Many applications of machine learning involve the analysis of large data frames -- matrices collecting heterogeneous measurements (binary, numerical, counts, etc.) across samples -- with missing values. Low-rank models, as studied by Udell et al. (2016), are popular in this framework for tasks such as visualization, clustering and missing value imputation. Yet, available methods with statistical guarantees and efficient optimization do not allow explicit modeling of main additive effects such as row and column, or covariate effects. In this paper, we introduce a low-rank interaction and sparse additive effects (LORIS) model which combines matrix regression on a dictionary and low-rank design, to estimate main effects and interactions simultaneously. We provide statistical guarantees in the form of upper bounds on the estimation error of both components. Then, we introduce a mixed coordinate gradient descent (MCGD) method which provably converges sub-linearly to an optimal solution and is computationally efficient for large scale data sets. We show on simulated and survey data that the method has a clear advantage over current practices.
425. **A Riemannian approach to trace norm regularized low-rank tensor completion** --*Madhav Nimishakavi &middot; Pratik Kumar Jawanpuria &middot; Bamdev Mishra*
 > One of the popular approaches for low-rank tensor completion is to use the latent trace norm regularization. However, most existing works in this direction learn a sparse combination of tensors. In this work, we fill this gap by proposing a variant of the latent trace norm that helps in learning a non-sparse combination of tensors. We develop a dual framework for solving the proposed low-rank tensor completion problem. In this framework, we first show a novel characterization of the solution space with an interesting factorization of the optimal solution. This allows to propose two scalable optimization formulations. The problems are shown to lie on a Cartesian  product of Riemannian spectrahedron manifolds. We exploit the versatile Riemannian optimization framework for proposing computationally efficient trust region algorithms. The experiments illustrate the efficacy of the proposed algorithms on several real-world datasets across applications.
426. **Community Exploration: From Offline Optimization to Online Learning** --*Xiaowei Chen &middot; Weiran Huang &middot; Wei Chen &middot; John C. S. Lui*
 > We introduce the community exploration problem that has various real-world applications such as online advertising. In the problem, an explorer allocates limited budget to explore communities so as to maximize the number of members he could meet. We provide a systematic study of the community exploration problem, from offline optimization to online learning. For the offline setting where the sizes of communities are known, we prove that the greedy methods for both of non-adaptive exploration and adaptive exploration are optimal. For the online setting where the sizes of communities are not known and need to be learned from the multi-round explorations, we propose an ``upper confidence'' like algorithm that achieves the logarithmic regret bounds. By combining the feedback from different rounds, we can achieve a constant regret bound. 
427. **Algorithmic Assurance: An Active Approach to Algorithmic Testing using Bayesian Optimisation** --*Shivapratap Gopakumar &middot; Vu Nguyen &middot; Sunil Gupta &middot; Santu Rana &middot; Svetha Venkatesh*
 > We introduce algorithmic assurance, the problem of testing whether machine learning algorithms are conforming to their intended design goal. We address this problem by proposing an efficient framework for algorithmic testing. To provide assurance, we need to efficiently discover scenarios where an algorithm decision deviates maximally from its intended gold standard. We mathematically formulate this task as an optimisation problem of an expensive, black-box function. We use an active learning approach based on Bayesian optimisation to solve this optimisation problem. We extend this framework to algorithms with vector-valued outputs by making appropriate modification in Bayesian optimisation via the Hedge algorithm. We theoretically analyse our methods for convergence. Using two real-world applications, we demonstrate the efficiency of our methods. The significance of our problem formulation and initial solutions is that it will serve as the foundation in building trust between humans and machines in complex decision making tasks.
428. **Estimating Learnability in the Sublinear Data Regime** --*Weihao Kong &middot; Gregory Valiant*
 > We consider the problem of estimating how well a model class is capable of fitting a distribution of labeled data.  We show that it is often possible to accurately estimate this ``learnability'' even when given an amount of data that is too small to reliably learn any accurate model.   Our first result applies to the setting where the data is drawn from a $d$-dimensional distribution with isotropic covariance, and the label of each datapoint is an arbitrary noisy function of the datapoint.  In this setting, we show that with $O(\sqrt{d})$ samples, one can accurately estimate the fraction of the variance of the label that can be explained via the best linear function of the data.  We extend these techniques to a binary classification, and show that the prediction error of the best linear classifier can be accurately estimated given $O(\sqrt{d})$ labeled samples.  For comparison, in both the linear regression and binary classification settings, even if there is no noise in the labels, a sample size linear in the dimension, $d$, is required to \emph{learn} any function correlated with the underlying model.  We further extend our estimation approach to the setting where the data distribution has an (unknown) arbitrary covariance matrix, allowing these techniques to be applied to settings where the model class consists of a linear function applied to a nonlinear embedding of the data.  We demonstrate the practical viability of our approaches on synthetic and real data.  This ability to estimate the explanatory value of a set of features (or dataset), even in the regime in which there is too little data to realize that explanatory value, may be relevant to the scientific and industrial settings for which data collection is expensive and there are many potentially relevant feature sets that could be collected. 
429. **Adversarial Logit Pairing** --*Harini Kannan &middot; Ian Goodfellow &middot; Alexey Kurakin*
 > We introduce adversarial logit pairing (ALP), a new regularization technique designed to increase robustness to adversarial examples. We first demonstrate that ALP is a generalization of weight decay. Then, using the ImageNet dataset, we empirically show that the performance of the state of the art adversarial training defense from Madry et al. degrades on high dimensional input spaces. Next, we show that ALP achieves the state of the art defense on ImageNet against PGD white box attacks, with an accuracy improvement from 1.5% to 27.9%. Unlike previous work on adversarial training, we achieve this improvement without an increase in model size. Finally, we show that examples generated from an ALP-trained model are the current state-of-the-art transfer attack. This transfer attack successfully damages the current state of the art defense against black box attacks on ImageNet (Tramer et al.), dropping its accuracy from 66.6% to 47.1%. With this new accuracy drop, adversarial logit pairing ties with Tramer et al. for the state of the art on black box attacks on ImageNet.
430. **Policy Optimization via Importance Sampling** --*Alberto Maria Metelli &middot; Matteo Papini &middot; Francesco Faccio &middot; Marcello Restelli*
 > Policy optimization is an effective reinforcement learning approach to solve continuous control tasks. Recent achievements have shown that alternating on-line and off-line optimization is a successful choice for efficient trajectory reuse. However, deciding when to stop optimizing and collect new trajectories is non-trivial as it requires to account for the variance of the objective function estimate. In this paper, we propose a novel model-free policy search algorithm, POIS, applicable in both control-based and parameter-based settings. We first derive a high-confidence bound for importance sampling estimation and then we define a surrogate objective function which is optimized off-line using a batch of trajectories. Finally, the algorithm is tested on a selection of continuous control tasks, with both linear and deep policies, and compared with the state-of-the-art policy optimization methods.
431. **Differentially Private k-Means with Constant Multiplicative Error** --*Uri Stemmer &middot; Haim Kaplan*
 > We design new differentially private algorithms for the Euclidean k-means problem, both in the centralized model and in the local model of differential privacy. In both models, our algorithms achieve significantly improved error guarantees than the previous state-of-the-art. In addition, in the local model, our algorithm significantly reduces the number of interaction rounds.
432. **Learning Concave Conditional Likelihood Models for Improved Analysis of Tandem Mass Spectra** --*John Halloran &middot; David M Rocke*
 > The most widely used technology to identify the proteins present in a complex biological sample is tandem mass spectrometry, which quickly produces a large collection of spectra representative of the peptides (i.e., protein subsequences) present in the original sample. In this work, we greatly expand the parameter learning capabilities of a dynamic Bayesian network (DBN) peptide-scoring algorithm, Didea, by deriving emission distributions for which its conditional log-likelihood scoring function remains concave. We show that this class of emission distributions, called Convex Virtual Emissions (CVEs), naturally generalizes the log-sum-exp function while rendering both maximum likelihood estimation and conditional maximum likelihood estimation concave for a wide range of Bayesian networks. Utilizing CVEs in Didea allows efficient learning of a large number of parameters while ensuring global convergence, in stark contrast to Didea’s previous parameter learning framework (which could only learn a single parameter using a costly grid search) and other trainable models (which only ensure convergence to local optima). The newly trained scoring function substantially outperforms the state-of-the-art in both scoring function accuracy and downstream Fisher kernel analysis. Furthermore, we significantly improve Didea’s runtime performance through successive optimizations to its message passing schedule and derive explicit connections between Didea’s new concave score and related MS/MS scoring functions.
433. **The Spectrum of the Fisher Information Matrix of a Single-Hidden-Layer Neural Network** --*Jeffrey Pennington &middot; Pratik Worah*
 > An important factor contributing to the success of deep learning has been the remarkable ability to optimize large neural networks using simple first-order optimization algorithms like stochastic gradient descent. While the efficiency of such methods depends crucially on the local curvature of the loss surface, very little is actually known about how this geometry depends on network architecture and hyperparameters. In this work, we extend a recently-developed framework for studying spectra of nonlinear random matrices to characterize an important measure of curvature, namely the eigenvalues of the Fisher information matrix. We focus on a single-hidden-layer neural network with Gaussian data and weights and provide an exact expression for the spectrum in the limit of infinite width. We find that linear networks suffer worse conditioning than nonlinear networks and that nonlinear networks are generically non-degenerate. We also predict and demonstrate empirically that by adjusting the nonlinearity, the spectrum can be tuned so as to improve the efficiency of first-order optimization methods.
434. **Evolved Policy Gradients** --*Rein Houthooft &middot; Yuhua Chen &middot; Phillip Isola &middot; Bradly Stadie &middot; Filip Wolski &middot; OpenAI Jonathan Ho &middot; Pieter Abbeel*
 > We propose a metalearning approach for learning gradient-based reinforcement learning (RL) algorithms. The idea is to evolve a differentiable loss function, such that an agent, which optimizes its policy to minimize this loss, will achieve high rewards. The loss is parametrized via temporal convolutions over the agent's experience. Because this loss is highly flexible in its ability to take into account the agent's history, it enables fast task learning. Empirical results show that our evolved policy gradient algorithm (EPG) achieves faster learning on several randomized environments compared to an off-the-shelf policy gradient method. We also demonstrate that EPG's learned loss can generalize to out-of-distribution test time tasks, and exhibits qualitatively different behavior from other popular metalearning algorithms.
435. **Fully Understanding The Hashing Trick** --*Lior Kamma &middot; Casper B Freksen &middot; Kasper Green Larsen*
 > Feature hashing, also known as {\em the hashing trick}, introduced by Weinberger et al. (2009), is one of the key techniques used in scaling-up machine learning algorithms. Loosely speaking, feature hashing uses a random sparse projection matrix $A : \mathbb{R}^n \to \mathbb{R}^m$ (where $m \ll n$) in order to reduce the dimension of the data from $n$ to $m$ while approximately preserving the Euclidean norm. Every column of $A$ contains exactly one non-zero entry, equals to either $-1$ or $1$.  Weinberger et al. showed tail bounds on $\|Ax\|_2^2$. Specifically they showed that for every $\varepsilon, \delta$, if $\|x\|_{\infty} / \|x\|_2$ is sufficiently small, and $m$ is sufficiently large, then  \begin{equation*}\Pr[ \; | \;\|Ax\|_2^2 - \|x\|_2^2\; | < \varepsilon \|x\|_2^2 \;] \ge 1 - \delta \;.\end{equation*} These bounds were later extended by Dasgupta et al. (2010) and most recently refined by Dahlgaard et al. (2017), however, the true nature of the performance of this key technique, and specifically the correct tradeoff between the pivotal parameters $\|x\|_{\infty} / \|x\|_2, m, \varepsilon, \delta$ remained an open question.  We settle this question by giving tight asymptotic bounds on the exact tradeoff between the central parameters, thus providing a complete understanding of the performance of feature hashing. We complement the asymptotic bound with empirical data, which shows that the constants "hiding" in the asymptotic notation are, in fact, very close to $1$, thus further illustrating the tightness of the presented bounds in practice.
436. **Learning an olfactory topography from neural activity in piriform cortex** --*Anqi Wu &middot;  Stan Pashkovski &middot; Sandeep Datta &middot; Jonathan W Pillow*
 > A major difficulty afflicting the study of olfactory perception is the lack of any obvious spatial organization or topography governing the relationship between odorants or the percepts they elicit. Here we develop a Gaussian process latent variable model to extract such a topography directly from olfactory responses measured in piriform cortex. Our approach seeks to map odorants to points in a low-dimensional embedding space, where the distance between points in this embedding space relates to the similarity of population responses they elicit. The model is specified by an explicit continuous mapping from a latent embedding space to the space of high-dimensional neural population activity patterns via a set of nonlinear neural tuning curves, each parametrized by a Gaussian process, followed by a low-rank model of correlated, odor-dependent Gaussian noise. We apply this model to large-scale calcium fluorescence imaging measurements of population activity in layers 2 and 3 of mouse piriform cortex following presentation of a diverse set of odorants. We show that we can learn a low-dimensional embedding of each odor, and a smooth tuning curve over the latent embedding space that accurately captures each neuron's response to different odorants. The model captures both signal and noise correlations across more than 500 neurons. We perform a co-smoothing analysis to show that the model can accurately predict responses of a population held-out neurons to test odorants.
437. **Learning Task Specifications from Demonstrations** --*Marcell Vazquez-Chanlatte &middot; Susmit Jha &middot; Ashish Tiwari &middot; Mark K Ho &middot; Sanjit Seshia*
 > Real world applications often naturally decompose into several   sub-tasks. In many settings (e.g., robotics) demonstrations provide   a natural way to specify the sub-tasks. However, most methods for   learning from demonstrations either do not provide guarantees that   the artifacts learned for the subtasks can be safely recombined or   limit the types of composition available.  Motivated by this   deficit, we consider the problem of inferring binary non-Markovian   rewards, also known as logical trace properties or   \emph{specifications}, from demonstrations provided by an agent   operating in an uncertain, stochastic environment. Crucially,   specifications admit well-defined composition rules that are   typically easy to interpret.  In this paper, we formulate the   specification inference task as a maximum a posteriori (MAP)   probability inference problem, apply the principle of maximum   entropy to derive an analytic demonstration likelihood model and   give an efficient approach to search for the most likely   specification in a large candidate pool of a specifications. In our   experiments, we demonstrate how learning specifications can help   avoid common reward hacking bugs that often occur due to ad-hoc   reward composition.
439. **Hyperbolic Neural Networks** --*Octavian E Ganea &middot; Gary Becigneul &middot; Thomas Hofmann*
 > Hyperbolic spaces have recently gained momentum in the context of machine learning due to their high capacity and tree-likeliness properties. However, the representational power of hyperbolic geometry is not yet on par with Euclidean geometry, firstly because of the absence of corresponding hyperbolic neural network layers. Here, we bridge this gap in a principled manner by combining the formalism of Möbius gyrovector spaces with the Riemannian geometry of the Poincaré model of hyperbolic spaces. As a result, we derive hyperbolic versions of important deep learning tools: multinomial logistic regression, feed-forward and recurrent neural networks. This allows to embed sequential data and perform classification in the hyperbolic space. Empirically, we show that, even if hyperbolic optimization tools are limited, hyperbolic sentence embeddings either outperform or are on par with their Euclidean variants on textual entailment and noisy-prefix recognition tasks.
