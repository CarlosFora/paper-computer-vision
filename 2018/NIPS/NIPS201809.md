951. **A Neural Compositional Paradigm for Image Captioning** --*Bo Dai &middot; Sanja Fidler &middot; Dahua Lin*
 > Mainstream captioning models often follow a sequential structure to generate cap- tions, leading to issues such as introduction of irrelevant semantics, lack of diversity in the generated captions, and inadequate generalization performance. In this paper, we present an alternative paradigm for image captioning, which factorizes the captioning procedure into two stages: (1) extracting an explicit semantic representation from the given image; and (2) constructing the caption based on a recursive compositional procedure in a bottom-up manner. Compared to conventional ones, our paradigm better preserves the semantic content through an explicit factorization of semantics and syntax. By using the compositional generation procedure, caption construction follows a recursive structure, which naturally fits the properties of human language. Moreover, the proposed compositional procedure requires less data to train, generalizes better, and yields more diverse captions.
952. **On Learning Markov Chains** --*Yi HAO &middot; Alon Orlitsky &middot; Venkatadheeraj Pichapati*
 > Estimating an unknown discrete distribution from its samples is a fundamental problem in statistical learning. Over the past decade, this problem has attracted a significant amount of research effort and has been solved for different divergence measures. Surprisingly, an equally important problem, estimating an unknown Markov chain from its samples, is still far from understood. We consider the problem of determining the minimax risk (expected loss) of estimating an unknown $k$-state Markov chain from its $n$ sequential sample points. We present two related but different formulations: (1) predicting the conditional distribution of the next sample point with respect to the KL-divergence. Under this formulation, we show that the minimax prediction risk is both $\Omega(k\log\log n/n)$ and $\mathcal{O}(k^2\log\log n/n)$. (2) estimating the transition matrix with respect to a natural loss induced by some $f$-divergence measure. Under this formulation, if we allow the transition probabilities to be arbitrarily small, then certain states may not even be observable. Therefore, we consider the case when the transition probabilities are bounded away from zero. We completely resolve the latter problem for essentially all sufficiently smooth $f$-divergences, including but not limited to $L_2$-, Chi-squared, KL-, Hellinger, and Alpha-divergences. Additionally, we show that for the KL-divergence, if one allows the transition probabilities to be as small as $1/n$, then the minimax risk would be roughly $\log\log n$ times larger.  The agreement between our theory and experimental results is excellent.
953. **Maximum-Entropy Fine Grained Classification** --*Abhimanyu Dubey &middot; Otkrist Gupta &middot; Ramesh Raskar &middot; Nikhil Naik*
 > Fine-Grained Visual Classification (FGVC) is an important computer vision problem that involves small diversity within the different classes, and often requires expert annotators to collect data. Utilizing this notion of small visual diversity, we revisit Maximum-Entropy learning in the context of fine-grained classification, and provide a training routine that maximizes the entropy of the output probability distribution for training convolutional neural networks on FGVC tasks. We provide a theoretical as well as empirical justification of our approach, and achieve state-of-the-art performance across a variety of classification tasks in FGVC, that can potentially be extended to any fine-tuning task. Our method is robust to different hyperparameter values, amount of training data and amount of training label noise and can hence be a valuable tool in many similar problems.
954. **Removing the Feature Correlation Effect of Multiplicative Noise** --*Zijun Zhang &middot; Zongpeng Li*
 > Multiplicative noise, including dropout, is widely used to regularize deep neural networks (DNNs), and is shown to be effective in a wide range of architectures and tasks. From an information perspective, we consider injecting multiplicative noise into a DNN as training the network to solve the task with noisy information pathways, which leads to the observation that multiplicative noise tends to increase the correlation between features, so as to increase the signal-to-noise ratio of information pathways. However, high feature correlation is undesirable, as it increases redundancy in representations. In this work, we propose feature-decorrelating multiplicative noise (FDMN), which exploits batch normalization to remove the correlation effect in a simple yet effective way. We show that FDMN significantly improves the performance of standard multiplicative noise on image classification tasks, providing a better alternative to dropout for batch-normalized networks. Additionally, we present a unified view of FDMN and shake-shake regularization, which explains the performance gain of the latter.
955. **A Unified Framework for Extensive-Form Game Abstraction with Bounds** --*Christian Kroer &middot; Tuomas Sandholm*
 > Abstraction has long been a key component in the practical solving of large-scale extensive-form games. Despite this, abstraction remains poorly understood. There have been some recent theoretical results but they have been confined to specific assumptions on abstraction structure and are specific to various specific disjoint types of abstraction, and specific solution concepts, for example, exact Nash equilibria or strategies with bounded immediate regret. In this paper we present a unified framework for analyzing abstractions that can express all types of abstractions and solution concepts used in prior papers with performance guarantees---while maintaining comparable bounds on abstraction quality. Moreover, our framework extends well beyond prior work. We present the first exact decomposition of abstraction error for a broad class of abstractions that encompasses abstractions used in practice. Because it is significantly more general, this decomposition has a stronger dependence on the specific strategy computed in the abstraction. We show that this dependence can be removed by making similar, though slightly weaker, assumptions than in prior work. We also show, via counterexample, that such assumptions are necessary for some games. Finally, we prove the first bounds for how $\epsilon$-Nash equilibria computed in abstractions perform in the original game. This is important because often one cannot afford to compute an exact Nash equilibrium in the abstraction. All our results apply to general-sum n-player games.
956. **HitNet: Hybrid Ternary Recurrent Neural Network** --*Peiqi Wang &middot; Xinfeng Xie &middot; Lei Deng &middot; Guoqi Li &middot; Dongsheng Wang &middot; Yuan Xie*
 > Quantization is a promising technique to reduce the model size, memory footprint, and massive computation operations of recurrent neural networks (RNNs) for embedded devices with limited resources. Although extreme low-bit quantization has achieved impressive success on convolutional neural networks, it still suffers from huge accuracy degradation on RNNs with the same low-bit precision. In this paper, we first investigate the accuracy degradation on RNN models under different quantization schemes, and the distribution of tensor values in the full precision model. Our observation reveals that due to the difference between the distributions of weights and activations, different quantization methods are suitable for different parts of models. Based on our observation, we propose HitNet, a hybrid ternary recurrent neural network, which bridges the accuracy gap between the full precision model and the quantized model. In HitNet, we develop a hybrid quantization method to quantize weights and activations. Moreover, we introduce a sloping factor motivated by prior work on Boltzmann machine to activation functions, further closing the accuracy gap between the full precision model and the quantized model. Overall, our HitNet can quantize RNN models into ternary values, {-1, 0, 1}, outperforming the state-of-the-art quantization methods on RNN models significantly. We test it on typical RNN models, such as Long-Short-Term Memory (LSTM) and Gated Recurrent Units (GRU), on which the results outperform previous work significantly. For example, we improve the perplexity per word (PPW) of a ternary LSTM on Penn Tree Bank (PTB) corpus from 126 (the state-of-the-art result to the best of our knowledge) to 110.3 with a full precision model in 97.2, and a ternary GRU from 142 to 113.5 with a full precision model in 102.7.   
957. **Explanations based on the Missing: Towards Contrastive Explanations with Pertinent Negatives** --*Amit Dhurandhar &middot; Pin-Yu Chen &middot; Ronny Luss &middot; Chun-Chen Tu &middot; Paishun Ting &middot; Karthikeyan Shanmugam &middot; Payel Das*
 > In this paper we propose a novel method that provides contrastive explanations justifying the classification of an input by a black box classifier such as a deep neural network. Given an input we find what should be minimally and sufficiently present (viz. important object pixels in an image) to justify its classification and analogously what should be  minimally and necessarily \emph{absent} (viz. certain background pixels). We argue that such explanations are natural for humans and are used commonly in domains such as health care and criminology. What is minimally but critically \emph{absent} is an important part of an explanation, which to the best of our knowledge, has not been explicitly identified by current explanation methods that explain predictions of neural networks. We validate our approach on three real datasets obtained from diverse domains; namely, a handwritten digits dataset MNIST, a large procurement fraud dataset and a brain activity strength dataset. In all three cases, we witness the power of our approach in generating precise explanations that are also easy for human experts to understand and evaluate.
958. **Which Neural Net Architectures Give Rise to Exploding and Vanishing Gradients?** --*Boris Hanin*
 > We give a rigorous analysis of the statistical behavior of gradients in a randomly initialized fully connected network N with ReLU activations. Our results show that the empirical variance of the squares of the entries in the input-output Jacobian of N is exponential in the sum of the reciprocals of the hidden layer widths. Our approach complements the mean field theory analysis of random neural nets. From this point of view, we rigorously compute the finite width corrections to gradients at the edge of chaos. 
959. **How to Start Training: The Effect of Initialization and Architecture** --*Boris Hanin &middot; David Rolnick*
 > We identify and study two common failure modes for early training in deep ReLU nets. For each, we give a rigorous proof of when it occurs and how to avoid it, for fully connected, convolutional, and residual architectures. We show that the first failure mode, exploding or vanishing mean activation length, can be avoided by initializing weights from a symmetric distribution with variance 2/fan-in and, for ResNets, by correctly scaling the residual modules. We prove that the second failure mode, exponentially large variance of activation length, never occurs in residual nets once the first failure mode is avoided. In contrast, for fully connected nets, we prove that this failure mode can happen and is avoided by keeping constant the sum of the reciprocals of layer widths. We demonstrate empirically the effectiveness of our theoretical results in predicting when networks are able to start training. In particular, we note that many popular initializations fail our criteria, whereas correct initialization and architecture allows much deeper networks to be trained.
960. **LinkNet: Relational Embedding for Scene Graph** --*Sanghyun Woo &middot; Dahun Kim &middot; Donghyeon Cho &middot; In So Kweon*
 > Objects and their relationships are critical contents for image understanding. A scene graph provides a structured description that captures these properties of an image. However, reasoning about the relationships between objects is very challenging and only a few recent works have attempted to solve the problem of generating a scene graph from an image. In this paper, we present a novel method that improves scene graph generation by explicitly modeling inter-dependency among the entire object instances. We design a simple and effective relational embedding module that enables our model to jointly represent connections among all related objects, rather than focus on an object in isolation. Our novel method significantly benefits two main parts of the scene graph generation task: object classification and relationship classification. Using it on top of a basic Faster R-CNN, our model achieves state-of-the-art results on the Visual Genome benchmark. We further push the performance by introducing global context encoding module and geometrical layout encoding module. We validate our final model, LinkNet, through extensive ablation studies, demonstrating its efficacy in scene graph generation.
961. **Self-Handicapping Network for Integral Object Attention** --*Qibin Hou &middot; PengTao Jiang &middot; Yunchao Wei &middot; Ming-Ming Cheng*
 > Recently, adversarial erasing for weakly-supervised object attention has been deeply studied due to its capability in localizing integral object regions. However, such a strategy raises one key problem that attention regions will gradually expand to non-object regions as training iterations continue, which significantly decreases the quality of the produced attention maps. To tackle such an issue as well as promote the quality of object attention, we introduce a simple yet effective Self-Handicapping Network (ShaNet) to prohibit attentions from spreading to unexpected background regions. In particular, ShaNet leverages two self-handicapping strategies to encourage networks to use reliable object and background cues for learning to attention. In this way, integral object regions can be effectively highlighted without including much more background regions. To test the quality of the generated attention maps, we employ the mined object regions as heuristic cues for learning semantic segmentation models. Experiments on Pascal VOC well demonstrate the superiority of the ShaNet over other state-of-the-art methods.
962. **Combinatorial Optimization with Graph Convolutional Networks and Guided Tree Search** --*Zhuwen Li &middot; Qifeng Chen &middot; Vladlen Koltun*
 > We present a learning-based approach to computing solutions for certain NP-hard problems. Our approach combines deep learning techniques with useful algorithmic elements from classic heuristics. The central component is a graph convolutional network that is trained to estimate the likelihood, for each vertex in a graph, of whether this vertex is part of the optimal solution. The network is designed and trained to synthesize a diverse set of solutions, which enables rapid exploration of the solution space via tree search. The presented approach is evaluated on four canonical NP-hard problems and five datasets, which include benchmark satisfiability problems and real social network graphs with up to a hundred thousand nodes. Experimental results demonstrate that the presented approach substantially outperforms recent work, generalizes across datasets, and scales to graphs that are orders of magnitude larger than those used during training.
963. **Multi-Task Learning as Multi-Objective Optimization** --*Ozan Sener &middot; Vladlen Koltun*
 > In multi-task learning, multiple tasks are solved jointly, sharing inductive bias between them. Multi-task learning is inherently a multi-objective problem since different tasks may conflict, necessitating a trade-off between them. A common approach to this trade-off is to optimize a proxy objective that minimizes a weighted linear combination of per-task losses. However, this proxy is only valid when the tasks do not compete, which is rarely the case. In this paper, we explicitly cast multi-task learning as multi-objective optimization, with the overall objective of finding a Pareto optimal solution. To this end, we use algorithms developed in the gradient-based multi-objective optimization literature. Although these algorithms have desirable theoretical guarantees, they are not directly applicable to large-scale learning problems. We therefore propose efficient and accurate approximations. We apply our method to a variety of multi-task deep learning problems including digit classification, scene understanding (joint semantic segmentation, instance segmentation, and depth estimation), and multi-label classification. Our method yields higher-performing models than recent multi-task learning formulations or per-task training.
964. **Learning to Decompose and Disentangle Representations for Video Prediction** --*Jun-Ting Hsieh &middot; Bingbin Liu &middot; De-An Huang &middot; Li Fei-Fei &middot; Juan Carlos Niebles*
 > Our goal is to predict future video frames given a sequence of input frames. Despite large amounts of video data, this remains a challenging task because of the high-dimensionality of video frames. We address this challenge by proposing the Decompositional Disentangled Predictive Auto-Encoder (DDPAE), a framework that combines structured probabilistic models and deep networks to automatically (i) decompose the high-dimensional video that we aim to predict into components, and (ii) disentangle each component to have low-dimensional temporal dynamics that are easier to predict. Crucially, with an appropriately specified generative model of video frames, our DDPAE is able to learn both the latent decomposition and disentanglement without explicit supervision. For the Moving MNIST dataset, we show that DDPAE is able to recover the underlying components (individual digits) and disentanglement (appearance and location) as we would intuitively do. We further demonstrate that DDPAE can be applied to the Bouncing Balls dataset involving complex interactions between multiple objects to predict the video frame directly from the pixels and recover physical states without explicit supervision.
965. **Are ResNets Provably Better than Linear Predictors?** --*Ohad Shamir*
 > A residual network (or ResNet) is a standard deep neural net architecture, with state-of-the-art performance across numerous applications. The main premise of ResNets is that they allow the training of each layer to focus on fitting just the residual of the previous layer's output and the target output. Thus, we should expect that the trained network is no worse than what we can obtain if we remove the residual layers and train a shallower network instead. However, due to the non-convexity of the optimization problem, it is not at all clear that ResNets indeed achieve this behavior, rather than getting stuck at some arbitrarily poor local minimum. In this paper, we rigorously prove that arbitrarily deep, nonlinear residual units indeed exhibit this behavior, in the sense that the optimization landscape contains no local minima with value above what can be obtained with a linear predictor (namely a 1-layer network). Notably, we show this under minimal or no assumptions on the precise network architecture, data distribution, or loss function used. We also provide a quantitative analysis of approximate stationary points for this problem. Finally, we show that with a certain tweak to the architecture, training the network with standard stochastic gradient descent achieves an objective value close or better than any linear predictor.
966. **Nonlocal Neural Networks, Nonlocal Diffusion and Nonlocal Modeling** --*Yunzhe Tao &middot; Qi Sun &middot; Qiang Du &middot; Wei Liu*
 > Nonlocal neural networks have been proposed and shown to be effective in several computer vision tasks, where the nonlocal operations can directly capture long-range dependencies in the feature space. In this paper, we study the nature of diffusion and damping effect of nonlocal networks by doing the spectrum analysis on the weight matrices of the well-trained networks, and propose a new formulation of the nonlocal block. The new block not only learns the nonlocal interactions but also has stable dynamics and thus allows deeper nonlocal structures. Moreover, we interpret our formulation from the general nonlocal modeling perspective, where we make connections between the proposed nonlocal network and other nonlocal models, such as nonlocal diffusion processes and nonlocal Markov jump processes.
967. **Deep Functional Dictionaries: Learning Consistent Semantic Structures on 3D Models from Functions** --*Minhyuk Sung &middot; Ronald Yu &middot; Leonidas J Guibas &middot; Hao Su*
 > Various 3D semantic attributes such as segmentation masks, geometric features, keypoints, and materials can be encoded as per-point probe functions on 3D geometries. Given a collection of related 3D shapes, we consider how to jointly analyze such probe functions over different shapes, and how to discover common latent structures using a neural network --- even in the absence of any correspondence information. Our network is trained on point cloud representations of shape geometry and associated semantic functions on that point cloud. These functions express a shared semantic understanding of the shapes but are not coordinated in any way. For example, in a segmentation task, the functions can be indicator functions of arbitrary sets of shape parts, with the particular combination involved not known to the network. Our network is able to produce a small dictionary of basis functions for each shape, a dictionary whose span includes the semantic functions provided for that shape.  Even though our shapes have independent discretizations and no functional correspondences are provided, the network is able to generate latent bases, in a consistent order, that reflect the shared semantic structure among the shapes. We demonstrate the effectiveness of our technique in various segmentation and keypoint selection applications.
968. **Soft-Gated Warping-GAN for Pose-Guided Person Image Synthesis** --*Haoye Dong &middot; Xiaodan Liang &middot; Ke Gong &middot; Hanjiang Lai &middot; Jia Zhu &middot; Jian Yin*
 > Despite remarkable advances in image synthesis research, existing works often fail in manipulating images under the context of large geometric transformations. Synthesizing person images conditioned on arbitrary poses is one of the most representative examples where the generation quality largely relies on the capability of identifying and modeling arbitrary transformations on different body parts. Current generative models are often built on local convolutions and overlook the key challenges (e.g. heavy occlusions, different views or dramatic appearance changes) when distinct geometric changes happen for each part, caused by arbitrary pose manipulations. This paper aims to resolve these challenges induced by geometric variability and spatial displacements via a new Soft-Gated Warping Generative Adversarial Network (Warping-GAN), which is composed of two stages: 1) it first synthesizes a target part segmentation map given a target pose, which depicts the region-level spatial layouts for guiding image synthesis with higher-level structure constraints; 2) the Warping-GAN equipped with a soft-gated warping-block learns feature-level mapping to render textures from the original image into the generated segmentation map. Warping-GAN is capable of controlling different transformation degrees given distinct target poses. Moreover, the proposed warping-block is light-weight and flexible enough to be injected into any networks. Human perceptual studies and quantitative evaluations demonstrate the superiority of our Warping-GAN that significantly outperforms all existing methods on two large datasets.
969. **A Model for Learned Bloom Filters and Optimizing by Sandwiching** --*Michael Mitzenmacher*
 > Recent work has suggested enhancing Bloom filters by using a pre-filter, based on applying machine learning to determine a function that models the data set the Bloom filter is meant to represent.  Here we model such learned Bloom filters, with the following outcomes: (1) we clarify what guarantees can and cannot be associated with such a structure; (2) we show how to estimate what size the learning function must obtain in order to obtain improved performance;  (3) we provide a simple method, sandwiching, for optimizing learned Bloom filters;  and (4) we propose a design and analysis approach for a learned Bloomier filter, based on our modeling approach.
970. **Training DNNs with Hybrid Block Floating Point** --*Mario Drumond &middot; Tao LIN &middot; Martin Jaggi &middot; Babak Falsafi*
 > The wide adoption of DNNs has given birth to unrelenting computing requirements, forcing datacenter operators to adopt domain-specific accelerators to train them. These accelerators typically employ densely packed full precision floating-point arithmetic to maximize performance per area. Ongoing research efforts seek to further increase that performance density by replacing floating-point with fixed-point arithmetic. However, a significant roadblock for these attempts has been fixed point's narrow dynamic range, which is insufficient for DNN training convergence. We identify block floating point~(BFP) as a promising alternative representation since it exhibits wide dynamic range and enables the majority of DNN operations to be performed with fixed-point logic. Unfortunately, BFP alone introduces several limitations that preclude its direct applicability. In this work, we introduce HBFP, a hybrid BFP-FP approach, which performs all dot products in BFP and other operations in floating point. HBFP delivers the best of both worlds: the high accuracy of floating point at the superior hardware density of fixed point. For a wide variety of models we show that HBFP matches floating point's accuracy while enabling hardware implementations that deliver up to 8.5x higher throughput.
971. **Implicit Reparameterization Gradients** --*Mikhail Figurnov &middot; Shakir Mohamed &middot; Andriy Mnih*
 > By providing a simple and efficient way of computing low-variance gradients of continuous random variables, the reparameterization trick has become the technique of choice for training a variety of latent variable models. However, it is not applicable to a number of important continuous distributions.  We introduce an alternative approach to computing reparameterization gradients based on implicit differentiation and demonstrate its broader applicability by applying it to Gamma, Beta, Dirichlet, and von Mises distributions, which cannot be used with the classic reparameterization trick. Our experiments show that the proposed approach is faster and more accurate than the existing gradient estimators for these distributions.
972. **Rest-Katyusha: Exploiting the Solution's Structure via Scheduled Restart Schemes** --*Junqi Tang &middot; Mohammad Golbabaee &middot; Francis Bach &middot; Mike E davies*
 > We propose a structure-adaptive variant of the state-of-the-art stochastic variance-reduced gradient algorithm Katyusha for  regularized empirical risk minimization. The proposed method is able to exploit the intrinsic low-dimensional structure of the solution, such as sparsity or low rank which is enforced by a non-smooth regularization, to achieve even faster convergence rate. This provable algorithmic improvement is done by restarting the Katyusha algorithm according to restricted strong-convexity constants. We demonstrate the effectiveness of our approach via numerical experiments.
973. **Deep Defense: Training DNNs with Improved Adversarial Robustness** --*Ziang Yan &middot; Yiwen Guo &middot; Changshui Zhang*
 > Despite the efficacy on a variety of computer vision tasks, deep neural networks (DNNs) are vulnerable to adversarial attacks, limiting their applications in security-critical systems. Recent works have shown the possibility of generating imperceptibly perturbed image inputs (a.k.a., adversarial examples) to fool well-trained DNN classifiers into making arbitrary predictions. To address this problem, we propose a training recipe named ``deep defense''. Our core idea is to integrate an adversarial perturbation-based regularizer into the classification objective, such that the obtained models learn to resist potential attacks, directly and precisely. The whole optimization problem is solved just like training a recursive network. Experimental results demonstrate that our method outperforms training with adversarial/Parseval regularizations by large margins on various datasets (including MNIST, CIFAR-10 and ImageNet) and different DNN architectures. Code and models for reproducing our results will be made publicly available.
974. **(Probably) Concave Graph Matching** --*Haggai Maron &middot; Yaron Lipman*
 > In this paper we address the graph matching problem. Following the recent works of \cite{zaslavskiy2009path,Vestner2017} we analyze and generalize the idea of concave relaxations. We introduce the concepts of \emph{conditionally concave} and \emph{probably conditionally concave} energies on polytopes and show that they encapsulate many instances of the graph matching problem, including matching Euclidean graphs and graphs on surfaces. We further prove that local minima of probably conditionally concave energies on general matching polytopes (\eg, doubly stochastic) are with high probability extreme points of the matching polytope (\eg, permutations). 
975. **Optimization for Approximate Submodularity** --*Yaron Singer &middot; Avinatan Hassidim*
 > We consider the problem of maximizing a submodular function when given access to its approximate version. Submodular functions are heavily studied in a wide variety of disciplines, since they are used to model many real world phenomena, and are amenable to optimization. However, there are many cases in which the phenomena we observe is only approximately submodular and the approximation guarantees cease to hold. We describe a technique which we call the sampled mean approximation that yields strong guarantees for maximization of submodular functions from approximate surrogates under cardinality and intersection of matroid constraints. In particular, we show tight guarantees for maximization under a cardinality constraint and 1/(1+P) approximation under intersection of P matroids.
976. **Algorithmic Regularization in Learning Deep Homogeneous Models: Layers are Automatically Balanced** --*Simon Du &middot; Wei Hu &middot; Jason Lee*
 > We study the implicit regularization imposed by gradient descent for learning multi-layer homogeneous functions including feed-forward fully connected and convolutional neural networks with linear, ReLU or Leaky ReLU activation. We rigorously prove that gradient flow (gradient descent with infinitesimal step size) effectively enforces the differences between squared norms across different layers to remain invariant without any explicit regularization. This result implies that if the weights are initially small, gradient flow automatically balances the magnitudes of all layers. Using a discretization argument, we analyze gradient descent with positive step size for the non-convex low-rank asymmetric matrix factorization problem without any regularization. Inspired by our findings for gradient flow, we prove that gradient descent with O(1/t) step sizes automatically balances two low-rank factors and converges to a bounded global optimum. Furthermore, for rank-1 asymmetric matrix factorization we give a finer analysis showing gradient descent with constant step size converges to the global minimum at a globally linear rate. We believe that the idea of examining the invariance imposed by first order algorithms in learning homogeneous models could serve as a fundamental building block for studying optimization for learning deep models.
977. **How Many Samples are Needed to Learn a Convolutional Neural Network?** --*Simon Du &middot; Yining Wang &middot; Xiyu Zhai &middot; Sivaraman Balakrishnan &middot; Ruslan Salakhutdinov &middot; Aarti Singh*
 > A widespread folklore for explaining the success of convolutional neural network (CNN) is that CNN is a more compact representation than the fully connected neural network (FNN) and thus requires fewer samples for learning. We initiate the study of rigorously characterizing the sample complexity of learning convolutional neural networks. We show that for learning an $m$-dimensional convolutional filter with linear activation acting on a $d$-dimensional input, the sample complexity of achieving population prediction error of $\epsilon$ is $\widetilde{O}(m/\epsilon^2)$ whereas its FNN counterpart needs at least $\Omega(d/\epsilon^2)$ samples. Since $m \ll d$, this result demonstrates the advantage of using CNN. We further consider the sample complexity of learning a one-hidden-layer CNN with linear activation where both the $m$-dimensional convolutional filter and the $r$-dimensional output weights are unknown. For this model, we show the sample complexity is $\widetilde{O}\left((m+r)/\epsilon^2\right)$ when the ratio between the stride size and the filter size is a constant. For both models, we also present lower bounds showing our sample complexities are tight up to logarithmic factors. Our main tools for deriving these results are localized empirical process and a new lemma characterizing the convolutional structure. We believe these tools may inspire further developments in understanding CNN.
978. **Self-Supervised Generation of Spatial Audio for 360-degree Video** --*Pedro Morgado &middot; Nuno Nvasconcelos &middot; Timothy Langlois &middot; Oliver Wang*
 > We introduce an approach to convert mono audio recorded by a 360-degree video camera into spatial audio, a representation of the distribution of sound over the full viewing sphere. Spatial audio is an important component of immersive 360-degree video viewing, but spatial audio microphones are still rare in current 360-degree video production. Our system consists of end-to-end trainable neural networks that separate individual sound sources and localize them on the viewing sphere, conditioned on multi-modal analysis from the audio and 360-degree video frames. We introduce several datasets, including one filmed ourselves, and one collected in-the-wild from YouTube, consisting of 360-degree videos uploaded with spatial audio. During training, ground truth spatial audio serves as self-supervision and a mixed down mono track forms the input to our network. Using our approach we show that it is possible to infer the spatial localization of sounds based only on a synchronized 360-degree video and the mono audio track.
979. **A^2-Nets: Double Attention Networks** --*Yunpeng Chen &middot; Yannis Kalantidis &middot; Jianshu Li &middot; Shuicheng Yan &middot; Jiashi Feng*
 > Learning to capture long-range relations is fundamental to image/video recognition. Existing CNN models generally rely on increasing depth to model such relations which is highly inefficient. In this work, we propose the ``double attention block'', a novel component that aggregates and propagates informative global features from the entire spatio-temporal space of input images/videos, enabling subsequent convolution layers to access features from the entire space efficiently. The component is designed with a double attention mechanism in two steps, where the first step gathers features from the entire space into a compact set through second-order attention pooling and the second step adaptively selects and distributes features to each location via another attention. The proposed double attention block is easy to adopt and can be plugged into existing deep neural networks conveniently. We conduct extensive ablation studies and experiments on both image and video recognition tasks for evaluating its performance. On the image recognition task, a ResNet-50 equipped with our double attention blocks outperforms a much larger ResNet-152 architecture on ImageNet-1k dataset with over 40% less the number of parameters and less FLOPs. On the action recognition task, our proposed model achieves the state-of-the-art results on the Kinetics and UCF-101 datasets with significantly higher efficiency than recent works.
980. **On Misinformation Containment in Online Social Networks** --*Guangmo Tong &middot; Ding-Zhu Du &middot; Weili Wu*
 > The widespread online misinformation could cause public panic and serious economic damages. The misinformation containment problem aims at limiting the spread of misinformation in online social networks by launching competing campaigns. Motivated by realistic scenarios, we present the first analysis of the misinformation containment problem for the case when an arbitrary number of cascades are allowed. This paper makes four contributions. First, we provide a formal model for multi-cascade diffusion and introduce an important concept called as cascade priority. Second, we show that the misinformation containment problem cannot be approximated within a factor of $\Omega(2^{\log^{1-\epsilon}n^4})$ in polynomial time unless $NP \subseteq DTIME(n^{\polylog{n}})$. Third, we introduce several types of cascade priority that are frequently seen in real social networks. Finally, we design novel algorithms for solving the misinformation containment problem. The effectiveness of the proposed algorithm is supported by encouraging experimental results.
981. **Image Inpainting via Generative Multi-column Convolutional Neural Networks** --*Yi Wang &middot; Xin Tao &middot; Xiaojuan Qi &middot; Jiaya Jia &middot; Xiaoyong Shen*
 > In this paper, we propose a generative multi-column network for image inpainting. This network can synthesize different image components in a parallel manner within one stage. To better characterize global structures, we design a confidence-driven reconstruction loss while an implicit diversified MRF regularization is adopted to enhance local details. The multi-column network combined with the reconstruction and MRF loss propagates local and global information derived from context to the target inpainting regions. Extensive experiments on challenging street view, face, natural objects and scenes manifest that our method can produce visual compelling results even without previously common post-processing.
982. **MetaAnchor: Learning to Detect Objects with Customized Anchors** --*Tong Yang &middot; Xiangyu Zhang &middot; Wenqiang Zhang &middot; Jian Sun*
 > We propose a novel and flexible anchor mechanism named MetaAnchor for object detection frameworks. Unlike many previous detectors model anchors via a predefined manner, in MetaAnchor anchor functions could be dynamically generated from the arbitrary customized prior boxes. Taking advantage of weight prediction, MetaAnchor is able to work with most of the anchor-based object detection systems such as RetinaNet. Compared with the predefined anchor scheme, we empirically find that MetaAnchor is more robust to anchor settings and bounding box distributions; in addition, it also shows the potential on the transfer task. Our experiment on COCO detection task shows MetaAnchor consistently outperforms the counterparts in various scenarios.
983. **Probabilistic Pose Graph Optimization via Bingham Distributions and Tempered Geodesic MCMC** --*Tolga Birdal &middot; Umut Simsekli &middot; Mustafa Onur Eken &middot; Slobodan Ilic*
 > We introduce Tempered Geodesic MCMC (TG-MCMC) algorithm for initializing pose graph optimization problems, arising in various scenarios such as SFM (structure from motion) or SLAM (simultaneous localization and mapping). TG-MCMC is first of its kind as it unites asymptotically global non-convex optimization on the spherical manifold of quaternions  with posterior sampling, in order to provide both reliable initial poses and uncertainty estimates that are informative about the quality of individual solutions. We devise rigorous theoretical convergence guarantees for our method and extensively evaluate it on synthetic and real benchmark datasets. Besides its elegance in formulation and theory, we show that our method is robust to missing data, noise and the estimated uncertainties capture intuitive properties of the data.
984. **Deep Non-Blind Deconvolution via Generalized Low-Rank Approximation** --*Wenqi Ren &middot; Jiawei Zhang &middot; Lin Ma &middot; Jinshan Pan &middot; Xiaochun Cao &middot; Wei Liu &middot; Ming-Hsuan Yang*
 > In this paper, we present a deep convolutional neural network to capture the inherent properties of image degradation,  which can handle different kernels and saturated pixels in a unified framework. The proposed neural network is motivated by the low-rank property of pseudo-inverse kernels. We first compute a generalized low-rank approximation for a large number of blur kernels, and then use separable filters to initialize the convolutional parameters in the network. Our analysis shows that the estimated decomposed matrices contain the most essential information of the input kernel,  which ensures the proposed network to handle various blurs in a unified framework and generate high-quality deblurring results. Experimental results on benchmark datasets with noise and saturated pixels demonstrate that the proposed algorithm performs favorably against state-of-the-art methods.
986. **Chain of Reasoning for Visual Question Answering** --*Chenfei Wu &middot; Jinlai Liu &middot; Xiaojie Wang &middot; Xuan Dong*
 > Reasoning plays an essential role in Visual Question Answering (VQA). Multi-step and dynamic reasoning is often necessary for answering complex questions. For example, a question "What is placed next to the bus on the right of the picture?" talks about a compound object "bus on the right," which is generated by the relation <bus, on the right of, picture>. Furthermore, a new relation including this compound object <sign, next to, bus on the right> is then required to infer the answer. However, previous methods support either one-step or static reasoning, without updating relations or generating compound objects. This paper proposes a novel reasoning model for addressing these problems. A chain of reasoning (CoR) is constructed for supporting multi-step and dynamic reasoning on changed relations and objects. In detail, iteratively, the relational reasoning operations form new relations between objects, and the object refining operations generate new compound objects from relations. We achieve new state-of-the-art results on four publicly available datasets. The visualization of the chain of reasoning illustrates the progress that the CoR generates new compound objects that lead to the answer of the question step by step.
987. **See and Think: Disentangling Semantic Scene Completion** --*Shice Liu &middot; YU HU &middot; Yiming Zeng &middot; Qiankun Tang &middot; Beibei Jin &middot; Yinhe Han &middot; Xiaowei Li*
 > Semantic scene completion predicts volumetric occupancy and object category of a 3D scene, which helps intelligent agents to understand and interact with the surroundings. In this work, we propose a disentangled framework, sequentially carrying out 2D semantic segmentation, 2D-3D reprojection and 3D semantic scene completion. This three-stage framework has three advantages: (1) explicit semantic segmentation significantly boosts performance; (2) flexible fusion ways of sensor data bring good extensibility; (3) progress in any subtask will promote the holistic performance. Experimental results show that regardless of inputing a single depth or RGB-D, our framework can generate high-quality semantic scene completion, and outperforms state-of-the-art approaches on both synthetic and real datasets.
988. **Snap ML: A Hierarchical Framework for Machine Learning** --*Celestine Dünner &middot; Thomas Parnell*
 > We describe a new software framework for fast training of generalized linear models. The framework, named Snap Machine Learning (Snap ML), combines recent advances in machine learning systems and algorithms in a nested manner to reflect the hierarchical architecture of modern computing systems. We prove theoretically that such a hierarchical system can accelerate training in distributed environments where intra-node communication is cheaper than inter-node communication. Additionally, we provide a review of the implementation of Snap ML in terms of GPU acceleration, pipelining, communication patterns and software architecture, highlighting aspects that were critical for achieving high performance. We evaluate the performance of Snap ML in both single-node and multi-node environments, quantifying the benefit of the hierarchical scheme and the data streaming functionality, and comparing with other widely-used machine learning software frameworks. Finally, we present a logistic regression benchmark on the Criteo Terabyte Click Logs dataset and show that Snap ML achieves the same test loss an order of magnitude faster than any of the previously reported results. 
989. **Sparse DNNs with Improved Adversarial Robustness** --*Yiwen Guo &middot; Chao Zhang &middot; Changshui Zhang &middot; Yurong Chen*
 > Deep neural networks (DNNs) are computationally/memory-intensive and vulnerable to adversarial attacks, making them prohibitive in some real-world applications. By converting dense models into sparse ones, pruning appears to be a promising solution to reducing the computation/memory cost. This paper studies classification models, especially DNN-based ones, to demonstrate that there exists intrinsic relationships between their sparsity and adversarial robustness. Our analyses reveal, both theoretically and empirically, that nonlinear DNN-based classifiers behave differently under $l_2$ attacks from some linear ones. We further demonstrate that an appropriately higher model sparsity implies better robustness of nonlinear DNNs, whereas over-sparsified models can be more difficult to resist adversarial examples.
990. **PAC-learning in the presence of adversaries** --*Daniel Cullina &middot; Arjun Nitin Bhagoji &middot; Prateek Mittal*
 > The existence of evasion attacks during the test phase of machine learning algorithms represents a significant challenge to both their deployment and understanding. These attacks can be carried out by adding imperceptible perturbations to inputs to generate adversarial examples and finding effective defenses and detectors has proven to be difficult. In this paper, we step away from the attack-defense arms race and seek to understand the limits of what can be learned in the presence of a test-time adversary. In particular, we extend the Probably Approximately Correct (PAC)-learning framework to account for the presence of an adversary. We first define corrupted hypothesis classes which arise from standard binary hypothesis classes in the presence of an evasion adversary and derive the Vapnik-Chervonenkis (VC)-dimension for these, denoted as the Adversarial VC-dimension. We then show that a corresponding Fundamental Theorem of Statistical learning can be proved for evasion adversaries, where the sample complexity is controlled by the Adversarial VC-dimension. We then explicitly derive the Adversarial VC-dimension for halfspace classifiers in the presence of a sample-wise norm-constrained adversary of the type commonly studied for evasion attacks and show that it is the same as the standard VC-dimensiont, closing an open question. Finally, we prove that the Adversarial VC-dimension can be either larger or smaller than the standard VC-dimension depending on the hypothesis class and adversary, making it an interesting object of study in its own right.
993. **Geometrically Coupled Monte Carlo Sampling** --*Mark Rowland &middot; Krzysztof M Choromanski &middot; François Chalus &middot; Aldo Pacchiano &middot; Tamas Sarlos &middot; Richard E Turner &middot; Adrian Weller*
 > Monte Carlo sampling in high-dimensional, low-sample settings is important in many machine learning tasks.  We improve current methods for sampling in Euclidean spaces by avoiding independence, and instead consider ways to couple samples. We show fundamental connections to optimal transport theory, leading to novel sampling algorithms, and providing new theoretical grounding for existing strategies.  We compare our new strategies against prior methods for improving sample efficiency, including QMC, by studying discrepancy. We explore our findings empirically, and observe benefits of our sampling schemes for reinforcement learning and generative modelling.
994. **Learning Deep Disentangled Embeddings With the F-Statistic Loss** --*Karl.ridgeway@colora Ridgeway &middot; Michael Mozer*
 > Deep-embedding methods aim to discover representations of a domain that make explicit the domain's class structure and thereby support few-shot learning. Disentangling methods aim to make explicit compositional or factorial structure. We combine these two active but independent lines of research and propose a new paradigm suitable for both goals. We propose and evaluate a novel loss function based on the $F$ statistic, which describes the separation of two or more distributions. By ensuring that distinct classes are well separated on a subset of embedding dimensions, we obtain embeddings that are useful for few-shot learning. By not requiring separation on all dimensions, we encourage the discovery of disentangled representations. Our embedding method matches or beats state-of-the-art, as evaluated by performance on recall@$k$ and few-shot learning tasks. Our method also obtains performance superior to a variety of alternatives on disentangling, as evaluated by two key properties of a disentangled representation: modularity and explicitness. The goal of our work is to obtain more interpretable, manipulable, and generalizable deep representations of concepts and categories.
995. **Fast Similarity Search via Optimal Sparse Lifting** --*Wenye Li &middot; Jingwei Mao &middot; Yin Zhang &middot; Shuguang Cui*
 > Similarity search is a fundamental problem in computing science with various applications, and has attracted significant research attention, especially for large-scale search problems in high dimensions. Motivated by the evidence in biological science, we propose a novel approach for similarity search. Fundamentally different from existing methods which mostly try to reduce the dimension of the data during the search, our approach projects the data into an even higher-dimensional space and ensures the data to be sparse and binary in the output space, where the search speed can be significantly improved. Specifically, our approach has two key steps and contributions. Firstly, we seek an {\em optimal sparse lifting} for the input data that increases the dimension of the data while approximately preserving the pairwise similarity through a general matrix factorization method. Secondly, we seek a {\em lifting operator} that maps input samples to their {\em sparse lifting} by solving an optimization model. In empirical studies, our approach reported significantly improved search results over the state-of-the-art solution in information retrieval applications, and exhibited its high potential in solving practical problems.
996. **Joint Sub-bands Learning with Clique Structures for Wavelet Domain Super-Resolution** --*Zhisheng Zhong &middot; Tiancheng Shen &middot; Yibo Yang &middot; Zhouchen Lin &middot; Chao Zhang*
 > Convolutional neural networks (CNNs) have recently achieved great success in single-image super-resolution (SISR).  However, these methods tend to produce over-smoothed outputs and miss some textural details. To solve these problems, we propose the Super-Resolution CliqueNet (SRCliqueNet) to reconstruct the high resolution (HR) image with better textural details in the wavelet domain. The proposed SRCliqueNet firstly extracts a set of feature maps from the low resolution (LR) image by the clique blocks group. Then we send the set of feature maps to the clique up-sampling module to reconstruct the HR image. The clique up-sampling module consists of four sub-nets which predict the high resolution wavelet coefficients of four sub-bands. Since we consider the edge feature properties of four sub-bands, the four sub-nets are connected to the others so that they can learn the coefficients of four sub-bands jointly.  Finally we apply inverse discrete wavelet transform (IDWT) to the output of four sub-nets at the end of the clique up-sampling module to increase the resolution and reconstruct the HR image. Extensive quantitative and qualitative experiments on benchmark datasets show that our method achieves superior performance over the state-of-the-art methods.
997. **Learning long-range spatial dependencies with horizontal gated-recurrent units** --*Drew Linsley &middot; Junkyung Kim &middot; Vijay Veerabadran &middot; Charles Windolf &middot; Thomas Serre*
 > Progress in deep learning has spawned great successes in many engineering applications. As a prime example, convolutional neural networks, a type of feedforward neural networks, are now approaching -- and sometimes even surpassing -- human accuracy on a variety of visual recognition tasks. Here, however, we show that these neural networks and their recent extensions struggle in recognition tasks where co-dependent visual features must be detected over long spatial ranges. We introduce the horizontal gated-recurrent unit (hGRU) to learn intrinsic horizontal connections -- both within and across feature columns. We demonstrate that a single hGRU layer matches or outperforms all tested feedforward hierarchical baselines including state-of-the-art architectures which have orders of magnitude more free parameters. We further discuss the biological plausibility of the hGRU in comparison to anatomical data from the visual cortex as well as human behavioral data on a classic contour detection task.
998. **Learning Pipelines with Limited Data and Domain Knowledge: A Study in Parsing Physics Problems** --*Mrinmaya Sachan &middot; Kumar Avinava Dubey &middot; Tom Mitchell &middot; Dan Roth &middot; Eric Xing*
 > As machine learning becomes more widely used in practice, we need new methods to build complex intelligent systems that integrate learning with existing software, and with domain knowledge encoded as rules. As a case study, we present such a system that learns to parse Newtonian physics problems in textbooks. This system, Nuts&amp;Bolts, learns a pipeline process that incorporates existing code, pre-learned machine learning models, and human engineered rules.  It jointly trains the entire pipeline to prevent propagation of errors, using a combination of labelled and unlabelled data.  Our approach achieves a good performance on the parsing task, outperforming the simple pipeline and its variants. We further use Nuts&amp;Bolts to show improvements on the end task of answering these problems.
999. **Understanding Weight Normalized Deep Neural Networks with Rectified Linear Units** --*YIXI XU &middot; Xiao  Wang*
 > This paper presents a general framework for norm-based capacity control for $L_{p,q}$ weight normalized deep neural networks. We first establish the upper bound on the Rademacher complexities of this family. In particular, with an $L_{1,q}$ normalization, we discuss properties of an architecture-independent capacity control. For the regression problem, we provide both the generalization bound and the approximation bound. We argue that both generalization and approximation errors can be controlled by the $L_1$ norm of the output layer for any $L_{1,\infty}$ weight normalized neural network without relying on the network width and depth.
1001. **Supervised autoencoders: Improving generalization performance with unsupervised regularizers** --*Lei Le &middot; Andrew Patterson &middot; Martha White*
 > Generalization performance is a central goal in machine learning, particularly when learning representations with large neural networks. A common strategy to improve generalization has been through the use of regularizers, typically as a norm constraining the parameters. Regularizing hidden layers in a neural network architecture, however, is not straightforward. There have been a few effective layer-wise suggestions, but without theoretical guarantees for improved performance. In this work, we theoretically and empirically analyze one such model, called a supervised auto-encoder: a neural network that predicts both inputs (reconstruction error) and targets jointly. We provide a novel generalization result for linear auto-encoders, proving uniform stability based on the inclusion of the reconstruction error---particularly as an improvement on simplistic regularization such as norms or even on more advanced regularizations such as the use of auxiliary tasks. Empirically, we then demonstrate that, across an array of architectures with a different number of hidden units and activation functions, the supervised auto-encoder compared to the corresponding standard neural network never harms performance and can significantly improve generalization. 
1002. **An Off-policy Policy Gradient Theorem Using Emphatic Weightings** --*Eric Graves &middot; Ehsan Imani &middot; Martha White*
 > Policy gradient methods are widely used for control in reinforcement learning, particularly for the continuous action setting. There have been a host of theoretically sound algorithms proposed for the on-policy setting, due to the existence of the policy gradient theorem which provides a simplified form for the gradient. In off-policy learning, however, where the behaviour policy is not necessarily attempting to learn and follow the optimal policy for the given task, the existence of such a theorem has been elusive. In this work, we solve this open problem by providing the first off-policy policy gradient theorem. The key to the derivation is the use of emphatic weightings. We develop a new actor-critic algorithm---called Actor Critic with Emphatic weightings (ACE)---that approximates the simplified gradients provided by the theorem. We demonstrate in a simple counterexample that previous off-policy policy gradient methods---particularly OffPAC and DPG---converge to the wrong solution whereas ACE finds the optimal solution. 
1003. **Generalized Inverse Optimization through Online Learning** --*Chaosheng Dong &middot; Yiran Chen &middot; Bo Zeng*
 > Inverse optimization is a powerful paradigm for learning preferences and restrictions that explain the behavior of a decision maker, based on a set of external signal and the corresponding decision pairs. However, most inverse optimization algorithms are designed specially in batch setting, where all the data is available in advance. As a consequence, there has been rarely use of these methods in an online setting suitable for real-time applications. In this paper, we propose a general framework for inverse optimization through online learning. Specifically,  we develop an online learning algorithm that uses an implicit update rule which can handle noisy data. Moreover, under additional regularity assumptions in terms of the data and the model, we prove that our algorithm converges at a rate of $\mathcal{O}(1/\sqrt{T})$ and is statistically consistent. In our experiments, we show the online learning approach can learn the parameters with great accuracy and is very robust to noises, and achieves a drastic improvement in computational efficacy over the batch learning approach.
1005. **Doubly Robust Bayesian Inference for Non-Stationary Streaming Data with $\beta$-Divergences** --*Jeremias Knoblauch &middot; Jack Jewson &middot; Theodoros Damoulas*
 > We present the very first robust Bayesian Online Changepoint Detection algorithm through General Bayesian Inference (GBI) with $\beta$-divergences. The resulting inference procedure is doubly robust for both the predictive and the changepoint (CP) posterior, with linear time and constant space complexity. We provide a construction for exponential models and demonstrate it on the Bayesian Linear Regression model. In so doing, we make two additional contributions: Firstly, we make GBI scalable using Structural Variational approximations that are exact as $\beta \to 0$. Secondly, we give a principled way of choosing the divergence parameter $\beta$ by minimizing expected predictive loss on-line. We offer the state of the art and improve the False Discovery Rate of CPs by more than 80% on real world data.
1007. **Text-Adaptive Generative Adversarial Networks: Manipulating Images with Natural Language** --*Seonghyeon Nam &middot; Yunji Kim &middot; Seon Joo Kim*
 > This paper addresses the problem of manipulating images using natural language description. Our task aims to semantically modify visual attributes of an object in an image according to the text describing the new visual appearance. Although existing methods synthesize images having new attributes, they do not fully preserve text-irrelevant contents of the original image. In this paper, we propose the text-adaptive generative adversarial network (TAGAN) to generate semantically manipulated images while preserving text-irrelevant contents. The key to our method is the text-adaptive discriminator that creates word level local discriminators according to input text to classify fine-grained attributes independently. With this discriminator, the generator learns to generate images where only regions that correspond to the given text is modified. Experimental results show that our method outperforms existing methods on CUB and Oxford-102 datasets, and our results were mostly preferred on a user study. Extensive analysis shows that our method is able to effectively disentangle visual attributes and produce pleasing outputs. 
1009. **Kalman Normalization** --*Guangrun Wang &middot; jiefeng peng &middot; Ping Luo &middot; Xinjiang Wang &middot; Liang Lin*
 > As an indispensable component, Batch Normalization (BN) has successfully improved the training of deep neural networks (DNNs) with mini-batches, by normalizing the distribution of the internal representation for each hidden layer. However, the effectiveness of BN would diminish with the scenario of micro-batch (\eg~less than 4 samples in a mini-batch), since the estimated statistics in a mini-batch are not reliable with insufficient samples. This limits BN's room in training larger models on segmentation, detection, and video-related problems, which require small batches constrained by memory consumption. In this paper, we present a novel normalization method, called Kalman Normalization (KN), for improving and accelerating the training of DNNs, particularly under the context of micro-batches. Specifically, unlike the existing solutions treating each hidden layer as an isolated system, KN treats all the layers in a network as a whole system, and estimates the statistics of a certain layer by considering the distributions of all its preceding layers, mimicking the merits of Kalman Filtering. On ResNet50 trained in ImageNet, KN has 3.4\% lower error than its BN counterpart when using a batch size of 4; Even when using typical batch sizes, KN still maintains an advantage over BN while other BN variants suffers a performance degradation. Moreover, KN can be naturally generalized to many existing normalization variants to obtain gains, \eg equipping Group Normalization \cite{wu2018group} with Group Kalman Normalization (GKN). KN can outperform BN and its variants for large scale object detection and segmentation task in COCO 2017.
1010. **Structure-Aware Convolutional Neural Networks** --*Jianlong Chang &middot; Jie Gu &middot; Lingfeng Wang &middot; Gaofeng Meng &middot; SHIMING XIANG &middot; Chunhong Pan*
 > Convolutional neural networks (CNNs) are inherently subject to invariable filters that can only aggregate local inputs with the same topological structures. It causes that CNNs are allowed to manage data with Euclidean or grid-like structures (e.g., images), not ones with non-Euclidean or graph structures (e.g., traffic networks). To broaden the reach of CNNs, we develop structure-aware convolution to eliminate the invariance, yielding a unified mechanism of dealing with both Euclidean and non-Euclidean structured data. Technically, filters in the structure-aware convolution are generalized to univariate functions, which are capable of aggregating local inputs with diverse topological structures. Since infinite parameters are required to determine a univariate function, we parameterize these filters with numbered learnable parameters in the context of the function approximation theory. By replacing the classical convolution in CNNs with the structure-aware convolution, Structure-Aware Convolutional Neural Networks (SACNNs) are readily established. Extensive experiments on eleven datasets strongly evidence that SACNNs outperform current models on various machine learning tasks, including image classification and clustering, text categorization, skeleton-based action recognition, molecular activity detection, and taxi flow prediction. Code will be available.
1011. **Efficient Algorithms for Non-convex Isotonic Regression through Submodular Optimization** --*Francis Bach*
