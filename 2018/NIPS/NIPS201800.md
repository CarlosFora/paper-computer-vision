1. **Zero-Shot Transfer with Deictic Object-Oriented Representation in Reinforcement Learning** --*Ofir Marom &middot; Benjamin Rosman*
 > Object-oriented representations in reinforcement learning have shown promise in transfer learning, with previous research introducing a propositional object-oriented framework that has provably efficient learning bounds with respect to sample complexity. However, this framework has limitations in terms of the classes of tasks it can efficiently learn. In this paper we introduce a novel deictic object-oriented framework that has provably efficient learning bounds and can solve a broader range of tasks. Additionally, we show that this framework is capable of zero-shot transfer of transition dynamics across tasks and demonstrate this empirically for the Taxi and Sokoban domains.
2. **GroupReduce: Block-Wise Low-Rank Approximation for Neural Language Model Shrinking** --*Patrick Chen &middot; Si Si &middot; Yang Li &middot; Ciprian Chelba &middot; Cho-Jui Hsieh*
 > Model compression is essential for serving large deep neural nets on devices with limited resources or applications that require real-time responses. For advanced NLP problems, a neural language model usually consists of recurrent layers (e.g., using LSTM cells), an embedding matrix for representing input tokens, and a softmax layer for generating output tokens. For problems with a very large vocabulary size, the embedding and the softmax matrices can account for more than half of the model size. For instance, the bigLSTM model achieves state-of-the-art performance on the One-Billion-Word (OBW) dataset with around 800k vocabulary, and its word embedding and softmax matrices use more than 6GBytes space, and are responsible for over 90\% of the model parameters. In this paper, we propose GroupReduce, a novel compression method for neural language models, based on vocabulary-partition (block) based low-rank matrix approximation and the inherent frequency distribution of tokens (the power-law distribution of words). We start by grouping words into $c$ blocks based on their frequency, and then refine the clustering iteratively by constructing weighted low-rank approximation for each block, where the weights are based the frequencies of the words in the block. The experimental results show our method can significantly outperform traditional compression methods such as low-rank approximation and pruning. On the OBW dataset, our method achieved 6.6x compression rate for the embedding and softmax matrices, and when combined with quantization, our method can achieve 26x compression rate without losing prediction accuracy. 
4. **Transfer of Deep Reactive Policies for MDP Planning** --*Aniket Bajpai &middot; Sankalp Garg &middot; Mausam *
 > Domain-independent probabilistic planners input an MDP description in a factored representation language such as PPDDL or RDDL, and exploit the specifics of the representation for faster planning. Traditional algorithms operate on each problem instance independently, and good methods for transferring experience from policies of other instances of a domain to a new instance do not exist.  Recently, researchers have begun exploring the use of deep reactive policies, trained via deep reinforcement learning (RL), for MDP planning domains. One advantage of deep reactive policies is that they are more amenable to transfer learning.  
5. **Sequential Data Classification for Resource-constrained Devices** --*Prateek Jain &middot; Harsha Vardhan Simhadri &middot; Don Dennis &middot;  *
 > We study the problem of fast and efficient classification of sequential data (such as time-series) on tiny devices, which is critical for various IoT related applications like audio keyword detection or gesture detection. Deploying sequential data classification modules on tiny devices is challenging as predictions over sliding windows of data need to be invoked continuously at a high frequency. Each of these predictors themselves are expensive as they evaluate large models over long windows of data. In this paper, we address this challenge by exploiting the following two observations about classification tasks arising in typical IoT related applications: (a) the "signature" of a particular class (e.g. an audio keyword) typically occupies a small fraction of the overall data, and (b) class signatures tend to discernible early-on in the data.  We propose a method that exploits these observations by using a multiple instance learning formulation along with an early prediction technique to learn a model that can achieve better accuracy compared to baseline models, while reducing the computation by a large fraction. For instance, on an audio keyword detection benchmark  our model improves standard LSTM model's accuracy by up to 1.5\% while decreasing the computation cost by more than 60\%. This enables us to deploy such models for continuous real-time prediction on a small device such as Raspberry Pi0, a task that the baseline LSTM could not achieve. Finally, we also provide an analysis of our multiple instance learning algorithm in a simple setting and show that the proposed algorithm can efficiently converge to the global optima, one of the first such result in this domain.
6. **Sparse PCA from Sparse Linear Regression** --*Madalina Persu &middot; Guy Bresler &middot; Sam Park*
 > Sparse Principal Component Analysis (SPCA) and Sparse Linear Regression (SLR) are two problems that have a wide range of applications and have attracted a tremendous amount of attention in the last two decades as canonical examples of statistical problems in high dimension. A variety of algorithms have been proposed for both SPCA and SLR, but their literature has been disjoint for the most part. We have a fairly good understanding of conditions and regimes under which these algorithms succeed. But is there be a deeper connection between computational structure of SPCA and SLR? In this paper we show how to efficiently transform a blackbox solver for SLR into an algorithm for SPCA. Assuming the SLR solver satisfies prediction error guarantees achieved by existing efficient algorithms such as those based on the Lasso, we show that the SPCA algorithm derived from it achieves state of the art performance, matching guarantees for testing and for support recovery under the single spiked covariance model as obtained by the current best polynomial-time algorithms. Our reduction not only highlights the inherent similarity between the two problems, but also, from a practical standpoint, it allows one to obtain a collection of algorithms for SPCA directly from known algorithms for SLR. Experiments on simulated data show that these algorithms perform well.
7. **Computationally and Statistically Efficient Learning of Bayes Nets Using Path Queries** --*Kevin Bello &middot; Jean Honorio*
 > Causal discovery from empirical data is a fundamental problem in many scientific domains. Observational data allows for identifiability only up to Markov equivalence class. In this paper we first propose a polynomial time algorithm for learning the exact correctly-oriented structure of the transitive reduction of any causal Bayesian networks with high probability, by using interventional path queries. Each path query takes as input an origin node and a target node, and answers whether there is a directed path from the origin to the target. This is done by intervening the origin node and observing samples from the target node.  We theoretically  show the logarithmic sample complexity for the size of interventional data per path query, for continuous and discrete networks.  We then show how to learn the transitive edges using also logarithmic sample complexity (albeit in time exponential in the maximum number of parents for discrete networks), which allows us to learn the full network. We further extend our work by reducing the number of interventional path queries for learning rooted trees. We also provide an analysis of imperfect interventions.
8. **Point process latent variable models of freely swimming larval zebrafish** --*Anuj Sharma &middot; Scott Linderman &middot; Robert Johnson &middot; Florian Engert*
 > A fundamental goal of systems neuroscience is to understand how neural activity gives rise to rich natural behavior.  In order to achieve this goal, we must first build comprehensive models that offer quantitative descriptions of behavior.  We develop a new class of probabilistic models to tackle this challenge in the study of larval zebrafish, an important model organism for neuroscience.  Larval zebrafish locomote via sequences of punctate swim bouts---brief flicks of the tail---which are naturally modeled as a marked point process.  However, these sequences of swim bouts belie a set of discrete and continuous internal states, latent variables that are not captured by standard point process models.  We incorporate these variables as latent marks of a point process and explore various models for their dynamics.  To infer the latent variables and fit the parameters of this model, we develop an amortized variational inference algorithm that targets the collapsed posterior distribution, analytically marginalizing out the discrete latent variables.  With a dataset of over 120,000 swim bouts, we show that our models reveal interpretable discrete classes of swim bouts and continuous internal states like hunger that modulate their dynamics.  These models are a first step toward understanding the behavioral program of larval zebrafish and, ultimately, its neural underpinnings.
9. **Contrastive Learning from Pairwise Measurements** --*  &middot; Zhuoran Yang &middot; Yuchen Xie &middot; Princeton Zhaoran Wang*
 > Learning from pairwise measurements naturally arises from many applications, such as rank aggregation, ordinal embedding, and crowdsourcing. However, most existing models and algorithms are susceptible to potential model misspecification. In this paper, we study a semiparametric model where the pairwise measurements follow a natural exponential family distribution with an unknown base measure. Such a semiparametric model includes various popular parametric models, such as the Bradley-Terry-Luce model and the paired cardinal model, as special cases. To estimate this semiparametric model without specifying the base measure, we propose a data augmentation technique to create virtual examples, which enables us to define a contrastive estimator. In particular, we prove that such a contrastive estimator is invariant to model misspecification within the natural exponential family, and moreover, attains the optimal statistical rate of convergence up to a logarithmic factor. We provide numerical experiments to corroborate our theory. 
10. **Topkapi: Parallel and Fast Algorithm for Finding Top-K Frequent Elements** --*Ankush Mandal &middot; He Jiang &middot; Anshumali Shrivastava &middot; Vivek Sarkar*
 > Identifying the top-K frequent items is one of the most common and important operations in large data processing systems. As a result, several solutions have been proposed to solve this problem approximately. In this paper, we identify that in modern distributed settings with both multi-node as well as multi-core parallelism, existing algorithms, although theoretically sound, are suboptimal from the performance perspective. In particular, for identifying top-K frequent items, Count-Min Sketch (CMS) has fantastic update time but lack the important property of reducibility which is needed for exploiting available massive data parallelism. On the other end, popular Frequent algorithm (FA) leads to reducible summaries but the update costs are significant. In this paper, we present Topkapi, a fast and parallel algorithm for finding top-K frequent items, which gives the best of both worlds, i.e., it is reducible as well as efficient update time similar to CMS. Topkapi possesses strong theoretical guarantees and leads to significant performance gains due to increased parallelism, relative to past work. Topkapi also demonstrates the power of carefully tailored randomized algorithms accelerated over high-performance computing in obtaining disruptive speedups over distributed word counting benchmarks over the popular Spark frameworks.
11. **Removing Hidden Confounding by Experimental Grounding** --*Uri Shalit &middot; Nathan Kallus &middot; Aahlad Manas Puli*
 > Observational data is being increasingly used as a means for making individual-level causal predictions and intervention recommendations. The foremost challenge of causal inference from observational data is hidden confounding, whose presence cannot be tested in data and can invalidate any causal conclusion. Experimental data does not stuffer from confounding but is usually limited in both scope and scale. We introduce a novel method of using limited experimental data to correct the hidden confounding in causal effect models trained on larger observational data, even if the observational data does not fully overlap with the experimental data. Our method makes strictly weaker assumptions than existing approaches, and we prove conditions under which our method yields a consistent estimator. We demonstrate our method's efficacy using real-world data from a large educational experiment. 
12. **Semidefinite relaxations for certifying robustness to adversarial examples** --*Aditi Raghunathan &middot; Percy Liang &middot; Jacob Steinhardt*
 > Research on adversarial examples are evolved in arms race between defenders who attempt to train robust networks and attackers who try to prove them wrong. This has spurred interest in methods for certifying the robustness of a network. Methods based on combinatorial optimization compute the true robustness but do not yet scale.  Methods based on convex relaxations scale better but can only yield non-vacuous bounds on networks trained with those relaxations. In this paper, we propose a new semidefinite relaxation that applies to ReLU networks with any number of layers. We show that it produces meaningful robustness guarantees across a spectrum of networks that were trained against other objectives, something previous convex relaxations are not able to achieve.
13. **MixLasso: Generalized Mixed Regression via Convex Atomic-Norm Regularization** --*Ian En-Hsu Yen &middot; Pradeep Ravikumar &middot; Shou-De Lin &middot; Wei-Cheng Lee*
 > We consider a generalization of mixed regression where the response is an additive combination of several mixture components. Standard mixed regression is a special case where each response is generated from exactly one component. Typical approaches to the mixture regression problem employ local search methods such as Expectation Maximization (EM) that are prone to spurious local optima. On the other hand, a number of recent theoretically-motivated \emph{Tensor-based methods} either have high sample complexity, or require the knowledge of the input distribution, which is not available in most of practical situations. In this work, we study a novel convex estimator \emph{MixLasso} for the estimation of generalized mixed regression, based on an atomic norm specifically constructed to regularize the number of mixture components. Our algorithm gives a risk bound that trades off between prediction accuracy and model sparsity without imposing stringent assumptions on the input/output distribution, and can be easily adapted to the case of non-linear functions. In our numerical experiments on mixtures of linear as well as nonlinear regressions, the proposed method yields high-quality solutions in a wider range of settings than existing approaches.
14. **Smoothed Analysis of Discrete Tensor Decomposition and Assemblies of Neurons** --*Nima Anari &middot; Constantinos Daskalakis &middot; Wolfgang Maass &middot; Christos Papadimitriou &middot; Amin Saberi &middot; Santosh Vempala*
 > We analyze linear independence of rank one tensors produced by tensor powers of randomly perturbed vectors. This enables efficient decomposition of sums of high-order tensors. Our analysis builds upon [BCMV14] but allows for a wider range of perturbation models, including discrete ones. We given an application to recovering assemblies of neurons. 		 		 		Assemblies are large sets of neurons representing specific memories or concepts. The size of the intersection of two assemblies has been shown in experiments to represent the extent to which these memories co-occur or these concepts related; the phenomenon is called association of assemblies.  This that an animal's memory is a complex web of associations, and poses the problem of recovering this representation from cognitive data.  Motivated by this problem, we study the following more general question: Can we reconstruct the Venn diagram of a family of sets, given the sizes of their $\ell$-wise intersections? We show that as long as the family of sets is randomly perturbed, it is enough for the number of measurements to be polynomially larger than the number of nonempty regions of the Venn diagram to fully reconstruct the diagram.
15. **Domain Adaptation by Using Causal Inference to Predict Invariant Conditional Distributions** --*Sara Magliacane &middot; Thijs van Ommen &middot; Tom Claassen &middot; Stephan Bongers &middot; Philip Versteeg &middot; Joris M Mooij*
 > An important goal common to domain adaptation and causal reasoning is to make accurate predictions when the distributions for the target domain(s) and the source domain(s) differ. We consider the case in which the domains correspond to different contexts in which a system has been measured, for example, a purely observational context and several interventional contexts in which the system has been perturbed by external interventions. We consider a class of such causal domain adaptation problems, where data for multiple source domains are given, and the task is to predict the distribution of a certain target variable from measurements of other variables in one or more target domains. We propose an approach for solving these problems that exploits causal inference and does not rely on prior knowledge of the causal graph, nor of the type of the interventions or the intervention targets. We propose a practical implementation of the approach and evaluate it on simulated and real world data.
16. **Multi-value Rule Sets for Interpretable Classification with Feature-Efficient Representations** --*Tong Wang*
 > We present Multi-value Rule Sets (MRS) for interpretable classification with feature efficient presentations. Compared to rule sets built from single-valued rules, MRS adopts a more generalized form of association rules that allows multiple values in a condition. Rules of this form are more concise than classical single-valued rules in capturing and describing patterns in data. Our formulation also pursues a higher efficiency of feature utilization, which reduces possible cost in data collection and storage. We propose a Bayesian framework for formulating a MRS model and propose an efficient inference method for learning a maximum a posteriori, incorporating theoretically grounded bounds to iteratively reduce the search space and improve the search efficiency. Experiments on synthetic and real-world data demonstrate that MRS models have significantly smaller complexity and fewer features than baseline models while being competitive in predictive accuracy. 
17. **Differentially Private Change-Point Detection** --*Sara Krehbiel &middot; Rachel Cummings &middot; Wanrong Zhang &middot; Yajun Mei &middot; Rui Tuo*
 > The change-point detection problem seeks to identify distributional changes at an unknown change-point k* in a stream of data. This problem appears in many important practical settings involving personal data, including biosurveillance, fault detection, finance, signal detection, and security systems. The field of differential privacy offers data analysis tools that provide powerful worst-case privacy guarantees. We study the statistical problem of change-point problem through the lens of differential privacy. We give private algorithms for both online and offline change-point detection, analyze these algorithms theoretically, and then provide empirical validation of these results. 
18. **Support Recovery for Orthogonal Matching Pursuit: Upper and Lower bounds** --*Raghav Somani &middot; Chirag Gupta &middot; Prateek Jain &middot; Praneeth Netrapalli*
 > This paper studies the problem of sparse regression where the goal is to learn a sparse vector that best optimizes a given objective function. Under the assumption that the objective function satisfies restricted strong convexity (RSC), we analyze orthogonal matching pursuit (OMP), a greedy algorithm that is used heavily in applications, and obtain support recovery result as well as a tight generalization error bound for OMP. Furthermore, we obtain lower bounds for OMP, showing that both our results on support recovery and generalization error are tight up to logarithmic factors. To the best of our knowledge, these support recovery and generalization bounds are the first such matching upper and lower bounds (up to logarithmic factors) for {\em any} sparse regression algorithm under the RSC assumption. 
21. **Learning Temporal Point Processes via Reinforcement Learning** --*Shuang Li &middot; SHUAI XIAO &middot; Shixiang Zhu &middot; Nan Du &middot; Yao Xie &middot; Le Song*
 > Many real world problems from sustainability, healthcare and Internet generate discrete events in continuous time. The generative processes of these data can be very complex, requiring flexible models to capture their dynamics. Temporal point processes offer an elegant framework for modeling such event data. However,  sophisticated point process models typically leads to intractable likelihood functions, making model fitting difficult in practice. We address this challenge from the perspective of reinforcement learning (RL), and relate the intensity function of a point process to a stochastic policy in reinforcement learning. We parameterize the policy as a flexible recurrent neural network, and reward models which can mimic the observed event distribution. Since the reward function is unknown in practice, we also uncover an analytic form of the reward function using an inverse reinforcement learning formulation and functions from a reproducing kernel Hilbert space. This new RL framework allows us to derive  an efficient policy gradient algorithm for learning flexible point process models, and we show that it performs well in both synthetic and real data. 
22. **Benefits of overparameterization with EM** --*Ji Xu &middot; Daniel Hsu &middot; Arian Maleki*
 > Expectation Maximization (EM) is among the most popular algorithms for finding the maximizer of the log-likelihood objective. However, due to the non-concavity of log-likelihood, EM is generally only guaranteed to find its stationary points. The goal of this article is to present theoretical and empirical evidence to confirm that over-parameterization can help EM avoid the local minima of the likelihood objective. More specifically, we consider the problem of estimating the mean vectors of a spherical Gaussian mixture model under the following two scenarios: (i) the weights of each mixture is known, and (ii) the weights of the mixture are not known. Our study of the global behavior of EM reveals the better convergence properties of EM for the second model. Hence, it suggests that even if the weights of the mixtures are known, it is better to ignore this piece of information and run a more general EM that learns the weights. For a mixture of two symmetric Gaussians, we will prove that introducing the (statistically redundant) weight parameters enables EM to find the global minimizer under any initialization, despite the existence of local minima. For the mixture of three and four Gaussian, we present strong empirical evidence that confirms a similar behavior. Our results corroborate the value of over-parameterization in solving non-convex optimization problems, a phenomenon that has been observed in other areas of research, such as neural nets. 
23. **Learning Beam Search Policies via Imitation Learning** --*Renato Negrinho &middot; Matthew Gormley &middot; Geoffrey Gordon*
 > Beam search is widely used for approximate decoding in structured prediction problems. Models often use a beam at test time but ignore its existence at train time, and therefore do not explicitly learn how to use the beam. We develop an unifying meta-algorithm for learning beam search policies using imitation learning. In our setting, the beam is part of the model and not just an artifact of approximate decoding. Our meta-algorithm captures existing learning algorithms and suggests new ones. It also lets us show novel no-regret guarantees for learning beam search policies.
24. **Data-Driven Clustering** --*Maria-Florina Balcan &middot; Travis Dick &middot; Colin White*
 > Algorithms for clustering points in metric spaces is a long-studied area of research. Clustering has seen a multitude of work both theoretically, in understanding the approximation guarantees possible for many objective functions such as k-median and k-means clustering, and experimentally, in finding the fastest algorithms and seeding procedures for Lloyd's algorithm. The best clustering algorithm depends on the specific application at hand, and this may not be known up front. For example, for many applications such as clustering proteins by function or clustering communities in a social network, there is some unknown target clustering, and the hope is that approximately minimizing a chosen objective will produce clusterings which are close to matching the target clustering. Furthermore, since a ``typical instance'' may vary depending on the application, clustering heuristics often see differing performance across different applications.
26. **Fully Neural Network Based Speech Recognition on Mobile and Embedded Devices** --*Jinhwan Park &middot; Yoonho Boo &middot; Iksoo Choi &middot; Sungho Shin &middot; Wonyong Sung*
 > Real-time automatic speech recognition (ASR) on mobile and embedded devices has been of great interests for many years.  We present real-time speech recognition on smart-phones or embedded systems by employing recurrent neural network (RNN) based acoustic models, RNN based language models, and beam-search decoding. The acoustic model is end-to-end trained with connectionist temporal classification (CTC) loss. The RNN implementation on embedded devices can suffer from excessive DRAM accesses because the parameter size of a neural network usually exceeds that of the cache memory and the parameters are used only once for each time step. To remedy this problem, we employ a multi-time step parallelization approach that computes multiple output samples at a time with the parameters fetched from the DRAM. Since the number of DRAM accesses can be reduced in proportion to the number of parallelization steps, we can achieve a high processing speed. However, conventional RNNs, such as long short term memory (LSTM) or gated recurrent unit (GRU), do not permit multi-time step parallelization. We construct an acoustic model by combining simple recurrent units (SRUs) and simple 1-dimensional convolution layers for multi-time step parallelization. Both the character and word piece models are developed for acoustic modeling, and the corresponding RNN based language models are used for beam search decoding. We achieve a competitive WER for WSJ corpus using the entire model size of around 30MB and achieve real-time speed using only a single core ARM without GPU or special hardware.
28. **Sketching Method for Large Scale Combinatorial Inference** --*Wei Sun &middot; Junwei Lu &middot; Han Liu*
 > We present computationally efficient algorithms to test various combinatorial structures of large-scale graphical models. In order to test the hypotheses on their topological structures, we propose two adjacency matrix sketching frameworks: neighborhood  sketching and subgraph sketching. The neighborhood sketching algorithm is proposed to test the connectivity of graphical models. This algorithm randomly subsamples vertices and conducts neighborhood regression and screening. The global sketching algorithm is proposed to test the topological properties requiring exponential computation complexity, especially testing the chromatic number and maximum clique. This algorithm infers the corresponding property based on the sampled subgraph. Our algorithms are shown to substantially accelerate the computation of existing methods. We validate our theory and method through both synthetic simulations and real application in neuroscience.
29. **Regret Bounds for Online Portfolio Selection with a Cardinality Constraint** --*Shinji Ito &middot; Daisuke Hatano &middot; Sumita Hanna &middot; Akihiro Yabe &middot; Takuro Fukunaga &middot; Naonori Kakimura &middot; Ken-Ichi Kawarabayashi*
 > Online portfolio selection is a sequential decision making problem in which a learner repetitively selects a portfolio over a set of assets, aiming to maximize long-term return. In this paper, we study the problem with a cardinality constraint that the number of assets in a portfolio is restricted to be at most k, and consider two scenarios: (i) in the full-feedback setting, the learner can observe price relatives (rates of return to cost) for all assets, and (ii) in the bandit-feedback setting, the learner can observe price relatives only for invested assets. We propose efficient algorithms for these scenarios, which achieve sublinear regrets. On the other hand, we also provide regret (statistical) lower bounds for both scenarios, nearly matching the upper bounds when k is a constant. In addition, we give a computational lower bound, which implies that no algorithm maintains both computational efficiency and a small regret upper bound. 
31. **Fast deep reinforcement learning using online adjustments from the past** --*Steven Hansen &middot; Alexander Pritzel &middot; Pablo Sprechmann &middot; Andre Barreto &middot; Charles Blundell*
 > We propose Ephemeral Value Adjusments (EVA): a means of allowing deep reinforcement learning agents to rapidly adapt to experience in their replay buffer. EVA shifts the value predicted by a neural network with an estimate of the value function found by prioritised sweeping over experience tuples from the replay buffer near the current state. EVA combines a number of recent ideas around combining episodic memory-like structures into reinforcement learning agents: slot-based storage, content-based retrieval, and memory-based planning. We show that EVA is performant on a demonstration task and Atari games.
32. **Streamlining constraints for random k-SAT** --*Aditya Grover &middot; Tudor Achim*
 > Several competitive algorithms for random $k$-SAT are based on survey propagation, a variational inference scheme used to obtain approximate marginals.  These marginals are used to inform branching decisions during search; however, survey propagation marginals are approximate and this can lead to contradictions. We introduce a more general branching strategy based on streamlining constraints, which sidestep hard assignments to variables. We show that streamlined solvers consistently outperform decimation-only solvers for random $k$-SAT for several problem sizes, shrinking the gap between empirical performance and theoretical limits of satisfiability by $16.3\%$ on average for $k=3,4,5,6$.
33. **Learning a Warping Distance from Unlabeled Time Series Using Sequence Autoencoders** --*Abubakar Abid &middot; James Zou*
 > Measuring similarities between unlabeled time series trajectories is an important problem in many domains such as medicine, economics, and vision. It is often unclear what is the appropriate metric to use because of the complex nature of noise in the trajectories (e.g. different sampling rates or outliers). Experts typically hand-craft or manually select a specific metric, such as Dynamic Time Warping (DTW), to apply on their data. In this paper, we propose an end-to-end framework, autowarp, that optimizes and learns a good metric given unlabeled trajectories. We define a flexible and differentiable family of warping metrics, which encompasses common metrics such as DTW, Edit Distance, Euclidean, etc. Autowarp then leverages the representation power of sequence autoencoders to optimize for a member of this warping family. The output is an metric which is easy to interpret and can be robustly learned from relatively few  trajectories. In systematic experiments across different domains, we show that autowarp often outperforms hand-crafted trajectory similarity metrics.  
34. **Gated Complex Recurrent Neural Networks** --*Moritz Wolter &middot;  *
 > Complex number have long been favoured for digital signal processing, yet complex representations rarely appear in deep learning architectures.  RNNs, widely used to process time series and sequence information, could greatly benefit from complex representations.  We present a novel complex gate recurrent cell.  When used together with norm-preserving state transition matrices, our complex gated RNN exhibits excellent stability and convergence properties.  We demonstrate competitive performance of our complex gated RNN on the synthetic memory and adding task, as well as on the real-world task of human motion prediction.
35. **Bayesian Structure Learning by Recursive Bootstrap** --*Raanan Yehezkel Rohekar &middot; Yaniv Gurwicz &middot; shami nisimov &middot; Guy Koren &middot; Gal Novik*
 > We address the problem of Bayesian structure learning for domains with hundreds of variables by employing non-parametric bootstrap, recursively. Essentially, we provide an algorithm for learning a tree, in which each node represents a scored CPDAG for a subset of variables and the level of the node corresponds to the maximal order of conditional independencies that are encoded in the graph. As higher order independencies are tested in deeper recursive calls, they benefit from more bootstrap samples, and therefor more resistant to the curse-of-dimensionality. Moreover, the re-use of stable low order independencies allows greater computational complexity. Using the learned tree, sampling CPDAGs from their posterior is efficient. We empirically demonstrate that the proposed algorithm scales well to hundreds of variables, and learns better MAP models and more reliable causal relationships between variables, than other state-of-the-art-methods.
36. **The Sparse Manifold Transform** --*Yubei Chen &middot; Dylan Paiton &middot; Bruno A Olshausen*
 > We present a signal representation framework called the {\em sparse manifold transform} that combines key ideas from sparse coding, manifold learning and slow feature analysis. It turns non-linear transformations in the primary sensory signal space into linear interpolations in a representational embedding space while maintaining approximate invertibility. The sparse manifold transform is an unsupervised and generative framework that explicitly and simultaneously models the sparse discreteness and low-dimensional manifold structure found in natural scenes. When stacked, it also models hierarchical composition. We provide a theoretical description of the transform and demonstrate properties of the learned representation on both synthetic data and natural videos.
37. **Deep Generative Models with Learnable Knowledge Constraints** --*Zhiting Hu &middot; Zichao Yang  &middot; Ruslan Salakhutdinov &middot; LIANHUI Qin &middot; Xiaodan Liang &middot; Haoye Dong &middot; Eric Xing*
 > The broad set of deep generative models (DGMs) has achieved remarkable advances. However, it is often difficult to incorporate rich structured domain knowledge with the end-to-end DGMs. Posterior regularization (PR) offers a principled framework to impose structured constraints on probabilistic models, but has limited applicability to the diverse DGMs that can lack a Bayesian formulation or even explicit density evaluation. PR also  requires constraints to be fully specified a priori, which is impractical or suboptimal for complex knowledge with learnable uncertain parts. In this paper, we establish mathematical correspondence between PR and reinforcement learning (RL), and, based on the connection, expand PR to learn constraints as the extrinsic reward in RL. The resulting algorithm is model-agnostic to apply to any DGMs, and is flexible to adapt arbitrary constraints with the model jointly. Experiments on human image generation and templated sentence generation show models with learned knowledge constraints by our algorithm greatly improve over base generative models.
38. **Diversity-Driven Exploration Strategy for Deep Reinforcement Learning** --*Zhang-Wei Hong &middot; Tzu-Yun Shann &middot; Shih-Yang Su &middot; Yi-Hsiang Chang &middot; Tsu-Jui Fu &middot; Chun-Yi Lee*
 > Efficient exploration remains a challenging research problem in reinforcement learning, especially when an environment contains large state spaces, deceptive local optima, or sparse rewards. To tackle this problem, we present a diversity-driven approach for exploration, which can be easily combined with both off- and on-policy reinforcement learning algorithms. We show that by simply adding a distance measure to the loss function, the proposed methodology significantly enhances an agent's exploratory behaviors, and thus preventing the policy from being trapped in local optima. We further propose an adaptive scaling method for stabilizing the learning process. We demonstrate the effectiveness of our method in huge 2D gridworlds and a variety of benchmark environments, including Atari 2600 and MuJoCo. Experimental results show that our method outperforms baseline approaches in most tasks in terms of mean scores and exploration efficiency.
39. **Regret bounds for meta Bayesian optimization with an unknown Gaussian process prior** --*Zi Wang &middot; Beomjoon Kim &middot; Leslie Kaelbling*
 > Bayesian optimization usually assumes that a Bayesian prior is given. However, the strong theoretical guarantees in Bayesian optimization are often regrettably compromised in practice because of unknown parameters in the prior. In this paper, we adopt a variant of empirical Bayes and show that,  by estimating the Gaussian process prior from offline data sampled from the same prior and constructing unbiased estimators of the posterior, variants of both GP-UCB and \emph{probability of improvement} achieve a near-zero regret bound, which decreases to a constant proportional to the observational noise as the number of offline data and the number of online evaluations increase. Empirically, we have verified our approach on challenging simulated robotic problems featuring task and motion planning.
40. **Discretely Relaxing Continuous Variables for tractable Variational Inference** --*Trefor Evans &middot; Prasanth Nair*
 > We explore a new research direction in Bayesian variational inference with discrete latent variable priors where we exploit Kronecker matrix algebra for efficient and exact computations of the evidence lower bound (ELBO). The proposed "DIRECT" approach has several advantages over its predecessors; (i) it can exactly compute ELBO gradients (i.e. unbiased, zero-variance gradient estimates), eliminating the need for high-variance stochastic gradient estimators and enabling the use of quasi-Newton optimization methods; (ii) its training complexity is independent of the number of training points, permitting inference on large datasets; and (iii) its posterior samples consist of sparse and low-precision quantized integers which permit fast inference on hardware limited devices. In addition, our DIRECT models can exactly compute statistical moments of the parameterized predictive posterior without relying on Monte Carlo sampling. Our numerical studies demonstrate accurate inference using latent variables discretized as extremely low-precision 4-bit quantized integers. While the ELBO computations considered require over 10^{2352} log-likelihood evaluations, we train on datasets with over two-million points in just seconds.
41. **Using Trusted Data to Train Deep Networks on Labels Corrupted by Severe Noise** --*Mantas Mazeika &middot; Dan Hendrycks*
 > The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have. Sources of label noise include automatic labeling for large datasets, non-expert labeling, and label corruption by data poisoning adversaries. In the latter case, corruptions may be arbitrarily bad, even so bad that a classifier predicts the wrong labels with high confidence. To protect against such sources of noise, we leverage the fact that a small set of clean labels is often easy to procure. We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels, and propose a loss correction that utilizes trusted examples in a data-efficient manner to mitigate the effects of label noise on deep neural network classifiers. Across vision and natural language processing tasks, we experiment with various label noises at several strengths, and show that our method significantly outperforms existing methods.
42. **Temporal alignment and latent Gaussian process factor inference in population spike trains** --*Lea Duncker &middot; Maneesh Sahani*
 > We introduce a novel scalable approach to identifying common latent structure in neural population spike-trains, which allows for variability both in the trajectory and in the rate of progression of the underlying computation. Our approach is based on shared latent Gaussian processes (GPs) which are combined linearly, as in the Gaussian Process Factor Analysis (GPFA) algorithm. We extend GPFA to handle unbinned spike-train data by incorporating a continuous time point-process likelihood model, achieving scalability with a sparse variational approximation. Shared variability is separated into terms that express condition dependence, as well as trial-to-trial variation in trajectories. Finally, we introduce a nested GP formulation to capture variability in the rate of evolution along the trajectory. We show that the new method learns to recover latent trajectories in synthetic data, and can accurately identify the trial-to-trial timing of movement-related parameters from motor cortical data without any supervision.
43. **Bounded-Loss Private Prediction Markets** --*Rafael Frongillo &middot; Bo Waggoner*
 > Prior work has investigated variations of prediction markets that preserve participants' (differential) privacy, which formed the basis of useful mechanisms for purchasing data for machine learning objectives.   Such markets required potentially unlimited financial subsidy, however, making them impractical.   In this work, we design an adaptively-growing prediction market with a bounded financial subsidy, while achieving privacy, incentives to produce accurate predictions, and precision in the sense that market prices are  not heavily impacted by the added privacy-preserving noise.   We briefly discuss how our mechanism can extend to the data-purchasing setting, and its relationship to traditional learning algorithms.
44. **Learning Abstract Options** --*Matthew Riemer &middot; Miao Liu &middot; Gerald Tesauro*
 > Building systems that autonomously create temporal abstractions from data is a key challenge in scaling learning and planning in reinforcement learning. One popular approach for addressing this challenge is the options framework (Sutton et al., 2000). However, only recently in (Bacon et al., 2017) was a policy gradient theorem derived for online learning of general purpose options in an end to end fashion. In this work, we extend previous work on this topic that only focuses on learning a two-level hierarchy including options and primitive actions to enable learning simultaneously at multiple resolutions in time. We achieve this by considering an arbitrarily deep hierarchy of options where high level temporally extended options are composed of lower level options with finer resolutions in time. We extend results from (Bacon et al., 2017) and derive policy gradient theorems for a deep hierarchy of options. Our proposed hierarchical option-critic architecture is capable of learning internal policies, termination conditions, and hierarchical compositions over options without the need for any intrinsic rewards or subgoals.  Our empirical results in both discrete and continuous environments demonstrate the efficiency of our framework.
45. **Deep Learning for Supercomputers: Distributed Tensor Layouts Define Distributed Computation** --*Noam Shazeer &middot; Niki Parmar &middot; Youlong Cheng &middot; Ashish Vaswani &middot; Mingsheng Hong &middot; Peter Hawkins &middot; Cliff Young &middot; HyoukJoong Lee*
 > Data-parallelism is the dominant distributed DNN training strategy, due to its universal applicability across a wide range of model and hardware architectures.   However, memory constraints prevent its application for training very large models, which have been shown in many domains to produce superior results.  Model-parallelism can solve this problem, also reducing step times during training and inference. Unfortunately, model-parallel algorithms tend to be complicated to discover, describe, and to implement, and do not generalize well across model types and hardware types.  We solve this problem by introducing a language for simply specifying distributed tensor computations (model-parallel and/or data-parallel) across an n-dimensional mesh of processors by specifying the distributed storage layouts (split and/or replicated) of the tensors.  The computation is then compiled into processor-local operations, coupled with collective communication primitives such as Allreduce.  Using our new language, we demonstrate very short specifications of a variety of data-parallel and/or model-parallel DNN training algorithms on both a two-layer example model and the Transformer \cite{Vaswani17} sequence-to-sequence model. This allows us to train Transformer models with up to 5 billion parameters on up to 256-node clusters, surpassing SOTA results on WMT14 En-Fr and En-De translation tasks, as well as the one-billion-word language modeling benchmark.
47. **Context-aware Synthesis and Placement of Object Instances** --*Donghoon Lee &middot; Ming-Yu Liu &middot; Ming-Hsuan Yang &middot; Sifei Liu &middot; Jinwei Gu &middot; Jan Kautz*
 > Learning how to synthesize and place object instances into an image (semantic map) based on the scene context is a challenging and interesting problem in vision and learning. On one hand, solving this problem requires a joint decision of (a) generating an object mask from a certain class at a plausible scale, location, and shape, and (b) inserting the object instance mask into an existing scene so that the synthesized content is semantically realistic. On the other hand, such a model can synthesize realistic outputs to potentially facilitate numerous image editing and scene parsing tasks. In this paper, we propose an end-to-end trainable neural network that can synthesize and insert object instances into an image via a semantic map. The proposed network contains two generative modules that determine where the inserted object should be (i.e., location and scale) and what the object shape (and pose) should look like. The two modules are connected together with a spatial transformation network and jointly trained and optimized in a purely data-driven way. Specifically, we propose a novel network architecture with parallel supervised and unsupervised paths to guarantee diverse results. We show that the proposed network architecture learns the context-aware distribution of the location and shape of object instances to be inserted, and it can generate realistic and statistically meaningful object instances that simultaneously address the where and what sub-problems.
48. **3D Steerable CNNs: Learning Rotationally Equivariant Features in Volumetric Data** --*Maurice Weiler &middot; Wouter Boomsma &middot; Mario Geiger &middot; Max Welling &middot; Taco Cohen*
 > We present a convolutional network that is equivariant to rigid body motions. The model uses scalar-, vector-, and tensor fields over 3D Euclidean space to represent data, and equivariant convolutions to map between such representations. These SE(3)-equivariant convolutions utilize kernels which are parameterized as a linear combination of a complete steerable kernel basis, which is derived in this paper. We prove that equivariant convolutions are the most general equivariant linear maps between fields over R^3 . Our experimental results confirm the effectiveness of 3D Steerable CNNs for the problem of amino acid environment prediction and protein structure classification, both of which have inherent SE(3) symmetry.
49. **Gaussian Process Prior Variational Autoencoders** --*Francesco Paolo Casale &middot; Luca Saglietti &middot; Jennifer Listgarten &middot; Nicolo Fusi &middot; Adrian Dalca*
 > Variational autoencoders (VAE) are a powerful and widely-used class of models to learn complex data distributions in an unsupervised fashion. One substantial limitation of VAEs is the prior assumption that latent sample representations are independent. However, for many important applications, such as time-series of images, this assumptions is too strong. Correlations, such as those in time, need to be accounted for to achieve correct model specification, and hence optimal results. Herein, we introduce a new model, the Gaussian Process (GP) Prior Variational Autoencoder (GPVAE) to specifically address this issue. The GPVAE aims to combine the power of VAEs with the ability to model correlations afforded by GP priors. To achieve efficient inference in this new class of models, we leverage structure in the covariance matrix, but also introduce a new stochastic backpropagation strategy that enables full batch gradient descent (GD) in a distributed manner.  In two image-based applications, we show that our method outperforms  conditional VAEs (CVAEs), and an adaptation of standard VAEs.
50. **Adversarial Risk and Robustness for Discrete Distributions** --*Dimitrios Diochnos &middot; Saeed Mahlouji Far &middot; Mohammad Mahmoody*
 > We study adversarial risk and robustness when the adversary can tamper with test instances and focus on the case of discrete distributions. We prove that any classifier that labels instances uniformly sampled  from {0,1}^n suffers from inherent vulnerabilities to  tampering attacks.  To the best of our knowledge, no prior work proved inherent limitations of classification under adversarial perturbations for discrete distributions. In particular, we show that for  initial error 0.01, there always exists an adversarial tampering that changes 1.52\sqrt{n} bits of the instances to increase the risk to  0.5,  making  classifier's decisions essentially meaningless. We also show that the robustness of any such classifier is also inherently limited to 2.15 \sqrt{n}. Our experimental calculations point to even better bounds. These bounds apply to any classification problem for uniform distribution and \emph{any} classifier.
51. **Unsupervised Image-to-Image Translation Using Domain-Specific Variational Information Bound** --*Hadi Kazemi &middot; Sobhan Soleymani &middot; Fariborz Taherkhani &middot; Ali Dabouei &middot; Seyed Iranmanesh &middot;  *
 > Unsupervised image-to-image translation is a class of computer vision problems which aims at modeling conditional distribution of images in the target domain, given a set of unpaired images in the source and target domains. An image in the source domain might have multiple representations in the target domain. Therefore, ambiguity in modeling of the conditional distribution arises, specially when the images in the source and target domains come from different modalities. Current approaches mostly rely on simplifying assumptions to map both domains into a shared-latent space. Consequently, they are only able to model the domain-invariant information between the two modalities. These approaches cannot model domain-specific information which has no representation in the target domain. In this work, we propose an unsupervised image-to-image translation framework which maximizes a domain-specific variational information bound and learns the target domain-invariant representation of the two domain. The proposed framework makes it possible to map a single source image into multiple images in the target domain, utilizing several target domain-specific codes sampled randomly from the prior distribution, or extracted from reference images.
52. **Using Quantum Graphical Models to Perform Inference in Hilbert Space** --*Siddarth Srinivasan &middot; Carlton Downey &middot; Byron Boots*
 > Quantum Graphical Models (QGMs) generalize classical graphical models by adopting the formalism for reasoning about uncertainty from quantum mechanics. Unlike classical graphical models, QGMs represent uncertainty with density matrices in complex Hilbert spaces. Hilbert space embeddings (HSEs) also generalize Bayesian inference in Hilbert spaces. We investigate the link between QGMs and HSEs and show that the sum rule and Bayes rule for QGMs are equivalent to the kernel sum rule in HSEs and a special case of Nadaraya-Watson kernel regression respectively. We show that these operations can be kernelized, and use these insights to propose a Hilbert Space Embedding of Hidden Quantum Markov Models (HSE-HQMM) to model dynamics. We present experimental results showing that HSE-HQMMs can outperform state-of-the-art models like LSTMs and PSRNNs on several datasets, while also providing a nonparametric method for maintaining a probability distribution over continuous-valued features.
53. **Lifted Weighted Mini-Bucket** --*Nicholas Gallo &middot; Alexander Ihler*
 > Many real-world problems, such as Markov Logic Networks (MLNs) with evidence, possess highly symmetric sub-structures but no exact symmetries.   Efficiently exploiting the symmetric substructure of these problems to perform approximate inference is a challenge for which few principled methods exist. In this paper, we present a lifted variant of the Weighted Mini-Bucket elimination algorithm which provides a principled way to 1) exploit the highly symmetric substructure of MLN models, and 2) incorporate high-order inference terms, which are necessary for high quality approximate inference. Our method maintains a concrete connection to the ground problem and has significant control over the accuracy-time trade-off of the approximation. Experimental results demonstrate good anytime performance and the utility of this class of approximations, especially in models with strong repulsive potentials.
54. **Learning to solve SMT formulas** --*Mislav Balunovic &middot; Pavol Bielik &middot; Martin Vechev*
 > We present a new approach for learning to solve SMT formulas. We phrase the challenge of solving SMT formulas as a tree search problem where at each step a transformation is applied to the input formula until the formula is solved. Our approach works in two steps: first, we learn a model (e.g., based on imitation learning) and then synthesize a strategy in the form of a loop-free program with branches. This strategy is an interpretable representation of the model's decisions and can be directly passed and used to guide the SMT solver, without requiring any modification to the solver itself. We show that our technique is practically effective: it solves 20.0% more formulas over a number of benchmarks and achieves up to 1000x runtime improvement over a state-of-the-art SMT solver.
56. **Improving Simple Models with Confidence Profiles** --*Amit Dhurandhar &middot; Karthikeyan Shanmugam &middot; Ronny Luss &middot; Peder A Olsen*
 > In this paper, we propose a new method called ProfWeight for transferring information from a pre-trained deep neural network that has a high test accuracy to a simpler interpretable model or a very shallow network of low complexity and a priori low test accuracy. We are motivated by applications in interpretability and model deployment in severely memory constrained environments (like sensors). Our method uses linear probes to generate confidence scores through flattened intermediate representations. Our transfer method involves a theoretically justified weighting of samples during the training of the simple model using  confidence scores of these intermediate layers. The value of our method is first demonstrated on CIFAR-10, where our weighting method significantly  improves (3-4\%) networks with only a fraction of the number of Resnet blocks of a complex Resnet model. We further demonstrate operationally significant results on a real manufacturing problem, where we dramatically increase the test accuracy of a CART model (the domain standard) by roughly $13\%$. 
57. **Robust Learning of Fixed-Structure Bayesian Networks** --*Yu Cheng &middot; Ilias Diakonikolas &middot; Daniel Kane &middot; Alistair Stewart*
 > We investigate the problem of learning Bayesian networks in a robust model where an $\epsilon$-fraction of the samples are adversarially corrupted.  In this work, we study the fully observable discrete case where the structure of the network is given.  Even in this basic setting, previous learning algorithms either run in exponential time or lose dimension-dependent factors in their error guarantees.  We provide the first computationally efficient robust learning algorithm for this problem with dimension-independent error guarantees.  Our algorithm has near-optimal sample complexity, runs in polynomial time, and achieves error that scales nearly-linearly with the fraction of adversarially corrupted samples.  Finally, we show on both synthetic and semi-synthetic data that our algorithm performs well in practice.
59. **Predictive Approximate Bayesian Computation via Saddle Points** --*Yingxiang Yang &middot; Bo Dai &middot; Niao He &middot; Negar Kiyavash*
 > Approximate Bayesian Computation (ABC) has been an important methodology for Bayesian inference when the likelihood function is intractable. Traditional sampling-based ABC algorithms such as ABC rejection and K2-ABC are inefficient performance-wise, while the regression-based algorithms such as K-ABC and DR-ABC are hard to scale. In this paper, we introduce an optimization-based framework for ABC that addresses these deficiencies. Leveraging a generative model for posterior and joint distribution matching, we show that ABC can be framed into  saddle point problems, whose objectives can be accessed directly with samples. We present \emph{the predictive ABC algorithm (P-ABC)}, and provide a PAC bound guaranteeing its learning consistency. Numerical experiment shows that, when compared to K2-ABC and DR-ABC, the proposed P-ABC outperforms both with large margins.
60. **Learning to Share and Hide Intentions using Information Regularization** --*DJ Strouse &middot; Max Kleiman-Weiner &middot; Josh Tenenbaum &middot; Matt Botvinick &middot; David Schwab*
 > Learning to cooperate with friends and compete with foes is a key component of multi-agent reinforcement learning. Typically to do so, one requires access to either a model of or interaction with the other agent(s). Here we show how to learn effective strategies for cooperation and competition in an asymmetric information game with no such model or interaction. Our approach is to encourage an agent to reveal or hide their intentions using an information-theoretic regularizer. We consider both the mutual information between goal and action given state, as well as the mutual information between goal and state. We show how to stochastically optimize these regularizers in a way that is easy to integrate with policy gradient reinforcement learning. Finally, we demonstrate that cooperative (competitive) policies learned with our approach lead to more (less) reward for a second agent in two simple asymmetric information games.
61. **Generalizing Point Embeddings using the Wasserstein Space of Elliptical Distributions** --*Boris Muzellec &middot; marco Cuturi*
 > Embedding complex objects as vectors in low dimensional spaces is a longstanding problem in machine learning. We propose in this work an extension of that approach, which consists in embedding objects as elliptical probability distributions, namely distributions whose densities have elliptical level sets. We endow these measures with the 2-Wasserstein metric, with two important benefits: \emph{(i)} For such measures, the squared 2-Wasserstein metric has a closed form, equal to the sum of the squared Euclidean distance between means and the squared Bures metric between covariance matrices. The latter is a Riemannian metric between positive semi-definite matrices, which turns out to be Euclidean on a suitable factor representation of such matrices, which is valid on the entire geodesic between these matrices. \emph{(ii)} The 2-Wasserstein distance boils down to the usual Euclidean metric when comparing Diracs, and therefore provides the natural framework to extend point embeddings. We show that for these reasons Wasserstein elliptical embeddings are more intuitive and yield tools that are better behaved numerically than the alternative choice of Gaussian embeddings with the Kullback-Leibler divergence. In particular, and unlike previous work based on the KL geometry, we learn elliptical distributions that are not necessarily diagonal. We demonstrate the interest of elliptical embeddings by using them for visualization, to compute embeddings of words, and to reflect entanglement or hypernymy. 
62. **Glow: Generative Flow with Invertible 1x1 Convolutions** --*Durk Kingma &middot; Prafulla Dhariwal*
 > Flow-based generative models are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using invertible 1x1 convolution. Using our method we demonstrate a significant improvement in log-likelihood and qualitative sample quality. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient synthesis of large and subjectively realistic-looking images.
63. **Total stochastic gradient algorithms and applications in reinforcement learning** --*Paavo Parmas*
 > Back propagation and the chain rule of derivatives have been prominent, however, the total derivative rule has not enjoyed the same amount of attention. In this work we show how the total derivative rule leads to an intuitive visual framework for creating gradient estimators on graphical models. In particular, previous ”policy gradient theorems” are easily derived. We derive new gradient estimators based on density estimation, as well as a likelihood ratio gradient, which ”jumps” to an intermediate node, not directly to the objective function. We evaluate our methods on model-based policy gradient algorithms, achieve good performance, and present evidence towards demystifying the success of the popular PILCO algorithm.
64. **Learning with SGD and Random Features** --*Luigi Carratino &middot; Lorenzo Rosasco &middot; Alessandro Rudi*
 > Sketching and stochastic gradient methods are arguably the most common  techniques to derive efficient large scale learning algorithms. In this paper, we investigate their application in the context of nonparametric statistical learning. More precisely, we study the estimator defined by stochastic gradient with mini batches and   random features. The latter can be seen as form of nonlinear sketching and  used to define approximate kernel methods. The considered estimator is not explicitly penalized/constrained and regularization is implicit. Indeed, our study highlight how different parameters, such as number of features, iterations, step-size and mini-batch size control the learning properties of the solutions. We do this by deriving optimal finite sample bounds, under standard  assumptions. The obtained results are corroborated and illustrated by numerical experiments.
65. **Backpropagation with Callbacks: Towards Efficient and Expressive Differentiable Programming** --*Fei Wang &middot; James Decker &middot; Xilun Wu &middot; Gregory Essertel &middot; Tiark Rompf*
 > Deep learning rests in crucial ways on gradient-descent optimization and end- to-end differentiation. Under the slogan of differentiable programming, there is an increasing demand for efficient automatic gradient computation for emerging network architectures that incorporate dynamic control flow. In this paper we take a fresh look at backpropagation, and propose an implementation using functions with callbacks, where the forward pass is executed as a sequence of function calls and the backward pass when the functions return. A key realization is that this technique of chaining callbacks is well known in the programming languages community under the name continuation-passing style (CPS), and any program can be converted to this form using standard techniques. Our approach achieves the same flexibility as other reverse-mode automatic differentiation (AD) techniques, but it can be implemented without any auxiliary data structures, and it can easily be combined with native code generation techniques, leading to a highly efficient implementation that combines the performance benefits of deep learning frameworks based on explicit reified computation graphs (e.g., TensorFlow) with the expressiveness of pure library approaches (e.g., PyTorch).
66. **Learning To Learn Around A Common Mean** --*Massimiliano Pontil &middot; giulia.denevi@gmail.com Denevi &middot; Carlo Ciliberto &middot; Dimitris Stamos*
 > The problem of learning-to-learn (LTL) or meta-learning is gaining increasing attention due to recent empirical evidence of its effectiveness in applications. Motivated by recent work on few-shot learning, in this paper we tackle the LTL problem by a novel approach, in which the training datasets received by the meta-algorithm are splitted into two subsets used to train and test the underlying algorithm, respectively. As the underlying algorithm we consider a form of Ridge Regression, in which the regularizer is the square distance to an unknown mean vector. We observe that, in this setting, the LTL problem can be reformulated as a Least Squares (LS) problem and we exploit a stochastic procedure to efficiently solve it. Under specific assumptions, we present a bound for the generalization error of out meta-algorithm. An implication of this bound is that our approach provides a consistent estimate of the transfer risk as the number of tasks grows, even if the sample size is kept constant. Preliminary experiments highlight the advantage offered by our approach.
67. **Human-in-the-Loop Interpretability Prior** --*Isaac Lage &middot; Andrew Ross &middot; Samuel J Gershman &middot; Been Kim &middot; Finale Doshi-Velez*
 > We often desire our models to be interpretable as well as accurate. Prior work on optimizing models for interpretability has relied on easy-to-quantify proxies for interpretability, such as sparsity or the number of operations required.  In this work, we optimize for interpretability by directly including humans in the optimization loop.  We develop an algorithm that minimizes the number of user studies to find models that are both predictive and interpretable and demonstrate our approach on several data sets.  Our human subjects results show trends towards different proxy notions of interpretability on different datasets, which suggests that different proxies are preferred on different tasks.
68. **Synaptic Strength For Convolutional Neural Network** --*CHEN LIN &middot; Zhao Zhong &middot; Wu Wei*
 > Convolutional Neural Networks(CNNs) are both computation and memory intensive which hindered their deployment in many resource efficient devices.  Inspired by neural science research, we propose the synaptic pruning: a data-driven method to prune connections between convolution layers with a newly proposed class of parameters called Synaptic Strength. Synaptic Strength is designed to capture the importance of a synapse based on the amount of information it transports. Experimental results show the effectiveness of our approach empirically. On CIFAR-10, we can prune various CNN models with up to $96\%$ connections removed, which results in significant size reduction and computation saving. Further evaluation on ImageNet demonstrates that synaptic pruning is able to discover efficient models which are competitive to state-of-the-art compact CNNs such as MobileNet-V$2$ and NasNet-Mobile. Our contribution is summarized as follows: (1) We introduce Synaptic Strength, a new class of parameters for convolution layer to indicate the importance of each connection. (2) Our approach can prune various CNN models with high compression without compromising accuracy. (3) Further investigation shows, the proposed Synaptic Strength is a better indicator for kernel pruning compare with the previous approach both in empirical results and theoretical analysis.     
69. **A Spectral View of Adversarially Robust Features** --*Shivam Garg &middot; Vatsal Sharan &middot; Gregory Valiant &middot; Brian Zhang*
 > Given the apparent difficulty of learning models that are robust to adversarial perturbations, we propose tackling the simpler problem of developing adversarially robust features.  Specifically, given a dataset and metric of interest, the goal is to return a function (or multiple functions) that 1) is robust to adversarial perturbations, and 2) has significant variation across the datapoints.  We establish strong connections between adversarially robust features, and a natural spectral property of the geometry of the dataset and metric of interest.  This connection can be leveraged both to provide robust features, and to provide a lower bound on the robustness of any function that has significant variance across the dataset.  Finally, we provide empirical evidence that the adversarially robust features yielded via this spectral approach can be be fruitfully leveraged to learn a robust (and accurate) model.
70. **Bayesian Nonparametric Spectral Estimation** --*Felipe Tobar*
 > Spectral estimation (SE) aims to identify how the energy of a signal (e.g., time series) is distributed across different frequencies. This is a challenging task when only partial and noisy observations are available, where current methods fail to find expressive representations of the data and handle uncertainty appropriately. In this context, we propose a joint probabilistic model for signals, observations and spectra, where  SE is addressed as an inference problem. Assuming a Gaussian process prior over the signal, we apply Bayes' rule to find the analytic posterior distribution of the spectrum given a set of observations. Besides its expressiveness and natural ability to represent spectral uncertainty, the proposed model provides a functional-form estimate of the power spectral density which can be optimised efficiently. We include a comparison to previous methods for SE and validation on three experiments using synthetic and real-world data. 
71. **Clebsch–Gordan Nets: a Fully Fourier Space Spherical Convolutional Neural Network** --*Risi Kondor &middot; Zhen Lin &middot; Shubhendu Trivedi*
 > Recent work by Cohen et al. has achieved state-of-the-art results for learning spherical images in a rotation invariant way by using ideas from group representation theory and noncommutative harmonic analysis. In this paper we propose a generalization of this work that generally exhibits improved performace, but from an implementation point of view is actually simpler. An unusual feature of the proposed architecture is that it uses the Clebsch--Gordan transform as its only source of nonlinearity, thus avoiding repeated forward and backward Fourier transforms. The underlying ideas of the paper generalize to constructing neural networks that are invariant to the action of other compact groups.
72. **A Simple Cache Model for Image Recognition** --*Emin Orhan*
 > Training large-scale image recognition models is computationally expensive. This raises the question of whether there might be simple ways to improve the test performance of an already trained model without having to re-train or even fine-tune it with new data. Here, we show that, surprisingly, this is indeed possible. The key observation we make is that the layers of a deep network close to the output layer contain independent, easily extractable class-relevant information that is not contained in the output layer itself. We propose to extract this extra class-relevant information using a simple key-value cache memory to improve the classification performance of the model at test time. Our cache memory is directly inspired by a similar cache model previously proposed for language modeling (Grave et al., 2017). This cache component does not require any training or fine-tuning; it can be applied to any pre-trained model and, by properly setting only two hyper-parameters, leads to significant improvements in its classification performance. Improvements are observed across several architectures and datasets. In the cache component, using features extracted from layers close to the output (but not from the output layer itself) as keys leads to the largest improvements. Concatenating features from multiple layers to form keys can further improve performance over using single-layer features as keys. The cache component also has a regularizing effect, a simple consequence of which is that it substantially increases the robustness of models against adversarial attacks.
73. **Low-rank Tucker decomposition of large tensors using TensorSketch** --*Osman Asif Malik &middot; Stephen Becker*
 > We propose two randomized algorithms for low-rank Tucker decompositions of tensors. The algorithms, which incorporate sketching, only require a single pass of the input tensor and can handle tensors whose elements are streamed in any order. To the best of our knowledge, ours are the only algorithms which can do this. We test our algorithms on sparse synthetic data and compare them to multiple other methods. We also apply one of our algorithms to a real dense 38 GB tensor representing a video and use the resulting decomposition to correctly classify frames containing disturbances.
74. **Blockwise Parallel Decoding for Deep Autoregressive Models** --*Mitchell Stern &middot; Noam Shazeer &middot; Jakob Uszkoreit*
 > Deep autoregressive sequence-to-sequence models have demonstrated impressive performance across a wide variety of tasks in recent years. While several common architecture classes including recurrent, convolutional, and self-attention networks make different trade-offs between the amount of computation needed per layer and the length of the critical path at training time, inference for novel inputs still remains an inherently sequential process. We propose a novel blockwise parallel decoding scheme that takes advantage of the fact that some architectures can score sequences in sublinear time. By generating predictions for multiple time steps at once then backing off to the longest prefix validated by the scoring model, we can substantially improve the speed of greedy decoding without compromising performance. When tested on state-of-the-art self-attention models for machine translation and image super-resolution, our approach achieves iteration reductions of up to 2x over a baseline greedy decoder with no loss in quality. Relaxing the acceptance criterion and fine tuning model parameters allows for reductions of up to 7x in exchange for a slight decrease in performance. Our fastest models achieve a 4x speedup in wall-clock time.
75. **Thwarting Adversarial Examples: An $L_0$-Robust Sparse Fourier Transform** --*Nikhil Vyas &middot; Jack Murtagh &middot; Mitali Bafna*
 > We give a new algorithm for approximating the Discrete Fourier transform of an  approximately sparse signal that is robust to worst-case $L_0$ corruptions, namely that some coordinates of the signal can be corrupt arbitrarily. Our techniques generalize to a wide range of linear transformations that are used in data analysis such as the Discrete Cosine and Sine transforms, the Hadamard transform, and their high-dimensional analogs. We use our algorithm to successfully defend  against worst-case $L_0$ adversaries in the setting of image classification. We give  experimental results on the Jacobian-based Saliency Map Attack (JSMA) and  the CW $L_0$ attack on the MNIST and Fashion-MNIST datasets as well as the  Adversarial Patch on the ImageNet dataset.
76. **Testing for Families of Distributions via the Fourier Transform** --*Alistair Stewart &middot; Ilias Diakonikolas &middot; Clement Canonne*
 > We study the general problem of testing whether an unknown discrete distribution belongs to a specified family of distributions. More specifically, given a distribution family P and sample access to an unknown discrete distribution D , we want to distinguish (with high probability) between the case that D in P and the case that D is ε-far, in total variation distance, from every distribution in P . This is the prototypical hypothesis testing problem that has received significant attention in statistics and, more recently, in computer science. The main contribution of this work is a simple and general testing technique that is applicable to all distribution families whose Fourier spectrum satisfies a certain approximate sparsity property. We apply our Fourier-based framework to obtain near sample-optimal and  computationally efficient testers for the following fundamental distribution families: Sums of Independent Integer Random Variables (SIIRVs), Poisson Multinomial Distributions (PMDs), and Discrete Log-Concave Distributions. For the first two, ours are the first non-trivial testers in the literature, vastly generalizing previous work on testing Poisson Binomial Distributions. For the third, our tester improves on prior work in both sample and time complexity.
77. **A Retrieve-and-Edit Framework for Predicting Structured Outputs** --*Tatsunori B Hashimoto &middot; Kelvin Guu &middot; Yonatan Oren &middot; Percy Liang*
 > Generic sequence-to-sequence models have trouble generating outputs with highly-structured dependencies such as source code. Motivated by the observation that editing is easier than writing from scratch, we propose a general retrieve-and-edit paradigm that can leverage any base sequence-to-sequence model: given a test input, we first retrieve a training example and then edit the retrieved output into the final predicted output using the base model. The key challenge is to efficiently learn a retriever that is sensitive to the prediction task. We propose first learning a joint variational autoencoder over input-output pairs and then regressing a conditional retriever on the joint embeddings. On the Hearthstone cards benchmark, we show that applying the retrieve-and-edit paradigm to a vanilla sequence-to-sequence model results in BLEU scores approaching those of specialized AST-based code generation models. Additionally, we introduce a new autocomplete task on Python code from GitHub, on which we demonstrate the benefits of retrieve-and-edit.
78. **Scalable Laplacian K-modes** --*Imtiaz Ziko &middot; Ismail Ben Ayed &middot; Eric Granger*
 > We advocate Laplacian K-modes for joint clustering and density mode finding, and propose a concave-convex relaxation of the problem, which yields a parallel algorithm that scales up to large datasets and high dimensions. We optimize a tight bound (auxiliary function) of our relaxation, which, at each iteration, amounts to computing an independent update for each cluster-assignment variable, with guaranteed convergence. Therefore, our bound optimizer can be trivially distributed for large-scale data sets. Furthermore, we show that the density modes can be obtained as byproducts of the assignment variables via simple maximum-value operations whose additional computational cost is linear in the number of data points. Our formulation does not need storing a full affinity matrix and computing its eigenvalue decomposition, neither does it perform expensive projection steps and Lagrangian-dual inner iterates for the simplex constraints of each point. Furthermore, unlike mean-shift, our density-mode estimation does not require inner-loop gradient-ascent iterates. It has a complexity independent of feature-space dimension, yields modes that are valid data points in the input set and is applicable to discrete domains as well as arbitrary kernels. We report comprehensive experiments over various data sets, which show that our algorithm yields very competitive performances in term of optimization quality (i.e., the value of the discrete-variable objective at convergence) and clustering accuracy.
79. **Blind Deconvolutional Phase Retrieval via Convex Programming** --*Ali Ahmed &middot; Alireza Aghasi &middot; Paul Hand*
 > We consider the task of recovering two real or complex $m$-vectors from phaseless Fourier measurements of their circular convolution.  Our method is a novel convex relaxation that is based on a lifted matrix recovery formulation that allows a nontrivial convex relaxation of the bilinear measurements from convolution.    We prove that if  the two signals belong to known random subspaces of dimensions $k$ and $n$, then they can be recovered up to the inherent scaling ambiguity with $m  >> (k+n) \log^2 m$  phaseless measurements.  Our method provides the first theoretical recovery guarantee for this problem by a computationally efficient algorithm and does not require a solution estimate to be computed for initialization. Our proof is based Rademacher complexity estimates.  Additionally, we provide an ADMM implementation of the method and provide numerical experiments that verify the theory.
80. **Neural Voice Cloning with a Few Samples** --*Sercan Arik &middot; Jitong Chen &middot; Kainan Peng &middot; Wei Ping &middot; Yanqi Zhou*
 > Voice cloning is a highly desired feature for personalized speech interfaces. We introduce a neural voice cloning system that learns to synthesize a person's voice from only a few audio samples. We study two approaches: speaker adaptation and speaker encoding. Speaker adaptation is based on fine-tuning a multi-speaker  generative model. Speaker encoding is based on training a separate model to directly infer a new speaker embedding, which will be applied to a multi-speaker generative model. In terms of naturalness of the speech and similarity to the original speaker, both approaches can achieve good performance, even with a few cloning audios. While speaker adaptation can achieve slightly better naturalness and similarity, cloning time and required memory for the speaker encoding approach are significantly less, making it more favorable for low-resource deployment.
81. **Persistence Fisher Kernel: A Riemannian Manifold Kernel for Persistence Diagrams** --*Tam Le &middot; Makoto Yamada*
 > Algebraic topology methods have recently played an important role for statistical analysis with complicated geometric structured data such as shapes, linked twist maps, and material data. Among them, \textit{persistent homology} is a well-known tool to extract robust topological features, and outputs as \textit{persistence diagrams} (PDs). However, PDs are point multi-sets which can not be used in machine learning algorithms for vector data. To deal with it, an emerged approach is to use kernel methods, and an appropriate geometry for PDs is an important factor to measure the similarity of PDs. A popular geometry for PDs is the \textit{Wasserstein metric}. However, Wasserstein distance is not \textit{negative definite}. Thus, it is limited to build positive definite kernels upon the Wasserstein distance \textit{without approximation}. In this work, we rely upon the alternative \textit{Fisher information geometry} to propose a positive definite kernel for PDs \textit{without approximation}, namely the Persistence Fisher (PF) kernel. Then, we analyze eigensystem of the integral operator induced by the proposed kernel for kernel machines. Based on that, we derive generalization error bounds via covering numbers and Rademacher averages for kernel machines with the PF kernel. Additionally, we show some nice properties such as stability and infinite divisibility for the proposed kernel. Furthermore, we also propose a linear time complexity over the number of points in PDs for an approximation of our proposed kernel with a bounded error. Throughout experiments with many different tasks on various benchmark datasets, we illustrate that the PF kernel compares favorably with other baseline kernels for PDs.
82. **Memory Augmented Policy Optimization for Program Synthesis with Generalization** --*Chen Liang &middot; Mohammad Norouzi &middot; Jonathan Berant &middot; Quoc V Le &middot; Ni Lao*
 > This paper presents MAPO: a novel policy optimization formulation that incorporates a memory buffer of promising trajectories to reduce the variance of policy gradient estimates for deterministic environments with discrete actions. The formulation expresses the expected return objective as a weighted sum of two terms: an expectation over a memory of trajectories with high rewards, and a separate expectation over the trajectories outside the memory. We propose 3 techniques to make an efficient training algorithm for MAPO: (1) distributed sampling from inside and outside memory with an actor-learner architecture; (2) a marginal likelihood constraint over the memory to initiate training; (3) systematic exploration to discover new high reward trajectories. MAPO improves the sample efficiency and robustness of policy gradient, especially on tasks with a sparse reward. We evaluate MAPO on weakly supervised program synthesis from natural language with an emphasize on generalization. On the WikiTableQuestions benchmark we improve the state-of-the-art by 2.5%, achieving an accuracy of 46.2%, and on the WikiSQL benchmark, MAPO achieves an accuracy of 74.9% with only weak supervision, outperforming the state-of-the-art with full supervision. 
83. **Learning to Reason with Third Order Tensor Products** --*Imanol Schlag &middot; Jürgen Schmidhuber*
 > We combine Recurrent Neural Networks with Tensor Product Representations to learn “near-symbolic,” interpretable, combinatorial representations of sequential data.  The new architecture is trained end-to-end through gradient descent on a variety of natural language reasoning tasks, outperforming current state-of-the-art models in joint and single task settings. <br /> When training and test data exhibit systematic differences, it generalises more systematically than previous state-of-the-art methods.
84. **Post: Device Placement with Cross-Entropy Minimization and Proximal Policy Optimization** --*Yuanxiang Gao &middot; Li Chen &middot; Baochun Li*
 > Training deep neural networks requires an exorbitant amount of computation resources, including a heterogeneous mix of GPU and CPU devices. It is critical to place operations in a neural network on these devices in an optimal way, so that the training process can complete within the shortest amount of time. The state-of-the-art uses reinforcement learning to learn placement skills by repeatedly performing Monte-Carlo experiments. However, due to its equal treatment of placement samples, we argue that there remains ample room for significant improvements. In this paper, we propose a new joint learning algorithm, called Post, that integrates cross-entropy minimization and proximal policy optimization to achieve theoretically guaranteed optimal efficiency. In order to incorporate the cross-entropy method as a sampling technique, we propose to represent placements using discrete probability distributions, which allows us to estimate an optimal probability mass by maximal likelihood estimation, a powerful tool with the best possible efficiency. We have implemented Post in the Google Cloud platform, and our extensive experiments with several popular neural network benchmarks have demonstrated clear evidence of superior performance: with the same amount of learning time, it leads to placements that have training times up to 63.7% shorter over the state-of-the-art.
85. **Using Large Ensembles of Control Variates for Variational Inference** --*Tomas Geffner &middot; Justin Domke*
 > Variational inference is increasingly being addressed with stochastic optimization. While control variates are commonly used to reduce stochastic gradient variance, they are typically looked at in isolation. This paper clarifies the large number of control variates that are available by giving a systematic view of how they are derived. We give a Bayesian risk minimization framework in which the quality of a procedure for combining control variates is quantified by its effect on optimization convergence rates, which leads to a very simple combination rule. Results show that combining a large number of control variates this way significantly improves the speed and robustness of inference over using any single control variate in isolation.
86. **Non-delusional Q-learning and Value-iteration** --*Tyler Lu &middot; Craig Boutilier &middot; Dale Schuurmans*
 > We identify a fundamental source of error in Q-learning and other forms of dynamic programming with function approximation. Delusional bias arises when the approximation architecture limits the class of expressible greedy policies. Since standard Q-updates make globally uncoordinated action choices with respect to any policy class, inconsistent or even conflicting Q-value estimates can result, leading to pathological behaviour such as over/under-estimation and even divergence. To solve this problem, we introduce a new notion of policy consistency and define a local backup process that ensures global consistency through the use of information sets—sets that record constraints on policies consistent with backed-up Q-values. We prove that model-based and model-free algorithms using this backup fully resolve delusional bias, yielding the first known algorithms that can guarantee optimal results under general conditions. These algorithms only require polynomially many information sets (from a potentially exponential support). Finally, we suggest other heuristics for value-iteration and Q-learning that attempt to reduce this bias.
87. **Learning Invariances using the Marginal Likelihood** --*Mark van der Wilk &middot; Matthias Bauer &middot; ST John &middot; James Hensman*
 > In many supervised learning tasks, learning what changes do not affect the predic-tion target is as crucial to generalisation as learning what does. Data augmentationis a common way to enforce a model to exhibit an invariance: training data is modi-fied according to an invariance designed by a human and added to the training data.We argue that invariances should be incorporated the model structure, and learnedusing themarginal likelihood, which can correctly reward the reduced complexityof invariant models. We incorporate invariances in a Gaussian process, due to goodmarginal likelihood approximations being available for these models. Our maincontribution is a derivation for a variational inference scheme for invariant Gaussianprocesses where the invariance is described by a probability distribution that canbe sampled from, much like how data augmentation is implemented in practice
88. **Uplift Modeling from Separate Labels** --*Ikko Yamane &middot; Florian Yger &middot; Jamal Atif &middot; Masashi Sugiyama*
 > Uplift modeling is aimed at estimating the incremental impact of an action on an individual's behavior, which is useful in various application domains such as targeted marketing (advertisement campaigns) and personalized medicine (medical treatments). Conventional methods of uplift modeling require every instance to be jointly equipped with two types of labels: the taken action and its outcome. However, obtaining two labels for each instance at the same time is difficult or expensive in many real-world problems. In this paper, we propose a novel method of uplift modeling that is applicable to a more practical setting where only one type of labels is available for each instance. We provide a generalization error bound of the proposed method and demonstrate its effectiveness through experiments.
89. **Online Robust Policy Learning in the Presence of Unknown Adversaries** --*Aaron Havens &middot; Zhanhong Jiang &middot; Soumik Sarkar*
 > The growing prospect of deep reinforcement learning (DRL) being used in cyber-physical systems has raised concerns around safety and robustness of autonomous agents. Recent work on generating adversarial attacks have shown that it is computationally feasible for a bad actor to fool a DRL policy into behaving sub optimally. Although certain adversarial attacks with specific attack models have been addressed, most studies are only interested in off-line optimization in the data space (e.g., example fitting, distillation). This paper introduces a Meta-Learned Advantage Hierarchy (MLAH) framework that is attack model-agnostic and more suited to reinforcement learning, via handling the attacks in the decision space (as opposed to data space) and directly mitigating learned bias introduced by the adversary. In MLAH, we learn separate sub-policies (nominal and adversarial) in an online manner, as guided by a supervisory master agent that detects the presence of the adversary by leveraging the advantage function for the sub-policies. We demonstrate that the proposed algorithm enables policy learning with significantly lower bias as compared to the state-of-the-art policy learning approaches even in the presence of heavy state information attacks. We present algorithm analysis and simulation results using popular OpenAI Gym environments.
90. **Variance-Reduced Stochastic Gradient Descent on Streaming Data** --*Ellango Jothimurugesan &middot; Ashraf Tahmasbi &middot; Phillip Gibbons &middot; Srikanta Tirthapura*
 > We present an algorithm STRSAGA for efficiently maintaining a machine learning model over constantly arriving streaming data that can quickly update the model as new training data is observed. We present a competitive analysis comparing the sub optimality of the model maintained by STRSAGA with that of an offline algorithm that is given the entire data beforehand, and analyze the risk-competitiveness of STRSAGA under different arrival patterns. Our theoretical and experimental results show that the risk of STRSAGA is comparable to that of offline algorithms on a variety of input arrival patterns, and its experimental performance is significantly better than prior algorithms on streaming data, such as SSVRG.
91. **On Markov Chain Gradient Descent** --*Tao Sun &middot; Yuejiao Sun &middot; Wotao Yin*
 > Stochastic gradient methods are the workhorse (algorithms) of machine learning and other large-scale optimization. This paper studies Markov chain gradient descent, a method of stochastic gradient descent in which the random samples are taken according to a Markov chain. Existing results of this method assume convex objectives and a reversible Markov chain and thus have their limitations. By incorporating mixing times of varying mixing levels into a novel line of analysis, we establish non-ergodic convergence under a wider of step sizes, extending the convergence result to the nonconvex setting, and establishing the rates of convergence that are related to the second largest eigenvalue of the Markov chain transition matrix. Our results apply also to non-reversible finite-state Markov chains, which can be substantially faster at sampling.
92. **Maximizing acquisition functions for Bayesian optimization** --*James Wilson &middot; Frank Hutter &middot; Marc Deisenroth*
 > Bayesian optimization is a sample-efficient approach for global optimization and relies on acquisition functions to guide the search process. Maximizing these functions is inherently complicated, especially in the parallel setting, where acquisition functions are routinely non-convex, high-dimensional and intractable. We present two modern approaches for maximizing acquisition functions and show that 1) sample-path derivatives can be used to optimize acquisition functions and 2)  parallel formulations of many acquisition functions are submodular and can therefore be efficiently maximized in greedy fashion with guaranteed near-optimality.
93. **Life-Long Disentangled Representation Learning with Cross-Domain Latent Homologies** --*Alessandro Achille &middot; Tom Eccles &middot; Loic Matthey &middot; Chris Burgess &middot; Nicholas Watters &middot; Alexander Lerchner &middot; Irina Higgins*
 > Intelligent behaviour in the real-world requires the ability to acquire new knowledge from an ongoing sequence of experiences while preserving and reusing past knowledge. We propose a novel algorithm for unsupervised representation learning from piece-wise stationary visual data: Variational Autoencoder with Shared Embeddings (VASE). Based on the Minimum Description Length principle, VASE automatically detects shifts in the data distribution and allocates spare representational capacity to new knowledge, while simultaneously protecting previously learnt representations from catastrophic forgetting. Our approach encourages the learnt representations to be disentangled, which imparts a number of desirable properties: VASE can deal sensibly with ambiguous inputs, it can enhance its own representations through imagination-based exploration, and most importantly, it exhibits semantically meaningful sharing of latents between different datasets. Compared to baselines with entangled representations, our approach is able to reason beyond surface-level statistics and perform semantically meaningful cross-domain inference.
94. **Dynamic Network Model from Partial Observations** --*Elahe Ghalebi &middot; Baharan Mirzasoleiman &middot; Radu Grosu &middot; Jure Leskovec*
 > Can evolving networks be inferred and modeled without directly observing their nodes and edges? In many applications, the edges of a dynamic network might not be observed, but one can observe the dynamics of stochastic cascading processes (e.g., information diffusion, virus propagation) occurring over the unobserved network. While there have been efforts to infer networks based on such data, providing a generative probabilistic model that is able to identify the underlying time-varying network remains an open question. Here we consider the problem of inferring generative dynamic network models based on network cascade diffusion data. We propose a novel framework for providing a non-parametric dynamic network model---based on a mixture of coupled hierarchical Dirichlet processes---based on data capturing cascade node infection times. Our approach allows us to infer the evolving community structure in networks and to obtain an explicit predictive distribution over the edges of the underlying network---including those that were not involved in transmission of any cascade, or are likely to appear in the future. We show the effectiveness of our approach using extensive experiments on synthetic as well as real-world networks.
95. **ATOMO: Communication-efficient Learning via Atomic Sparsification** --*Zachary B Charles &middot; Hongyi Wang &middot; Scott Sievert &middot; Dimitris Papailiopoulos &middot; Stephen Wright*
 > Distributed model training suffers from communication overheads due to frequent gradient updates transmitted between compute nodes. To mitigate these overheads, several studies propose the use of sparsified stochastic gradients. We argue that these are facets of a general sparsification method that can operate on any possible atomic decomposition. Notable examples include element-wise, singular value, and Fourier decompositions. We present ATOMO, a general framework for atomic sparsification of stochastic gradients. Given a gradient, an atomic decomposition, and a sparsity budget, ATOMO gives a random unbiased sparsification of the atoms minimizing variance. We show that methods such as QSGD and TernGrad are special cases of ATOMO and show that sparsifiying gradients in their singular value decomposition (SVD), rather than the coordinate-wise one, can lead to significantly faster distributed training. 
96. **Reinforcement Learning for Solving the Vehicle Routing Problem** --*  &middot; Afshin Oroojlooy &middot; Lawrence Snyder &middot; Martin Takac*
 > We present an end-to-end framework for solving the Vehicle Routing Problem (VRP) using reinforcement learning. In this approach, we train a single model that finds near-optimal solutions for problem instances sampled from a given distribution, only by observing the reward signals and following feasibility rules. Our model represents a parameterized stochastic policy, and by applying a policy gradient algorithm to optimize its parameters, the trained model produces the solution as a sequence of consecutive actions in real time, without the need to re-train for every new problem instance. On capacitated VRP, our approach outperforms classical heuristics and Google's OR-Tools on medium-sized instances in solution quality with comparable computation time (after training). We demonstrate how our approach can handle problems with split delivery and explore the effect of such deliveries on the solution quality. Our proposed framework can be applied to other variants of the VRP such as the stochastic VRP, and has the potential to be applied more generally to combinatorial optimization problems. 
97. **Scalable End-to-End Autonomous Vehicle Testing via Rare-event Simulation** --*Matthew O'Kelly &middot; Aman Sinha &middot; Hongseok Namkoong &middot; Russ Tedrake &middot; John C Duchi*
 > While recent developments in autonomous vehicle (AV) technology highlight substantial progress, we lack the tools for rigorous, scalable testing that are so important for these safety-critical systems. Real-world testing, the \textit{de facto} evaluation environment, places the public in danger, and, due to the rare nature of accidents, will require billions of miles to validate empirically. We implement a simulation framework, \emph{pseudoreality}, which can put an entire autonomous driving system under test -- this includes deep-learning based perception and control algorithms, but also the underlying dynamics models and near-photo-realistic rendering engine required to complete the loop.  While complete systems of this complexity are currently intractable for formal verification, we demonstrate full-scale testing using a \emph{risk-based framework} where our goal is to evaluate the probability of an accident under a base distribution governing standard traffic behavior. Further, we address fundamental challenges in the sample complexity of risk evaluation through the use of adaptive importance-sampling methods. We demonstrate our framework on a highway scenario, showing that it is possible to accelerate system evaluation by $10$-$50 \mathsf{P}$ times that of real-world testing ($\mathsf{P}$ is the number of processors), and $1.5$-$5$ times that of naive Monte Carlo sampling methods.
99. **Object-Oriented Dynamics Predictor** --*Guangxiang Zhu &middot; Chongjie Zhang*
 > Generalization has been one of the major challenges for learning dynamics models in model-based reinforcement learning. However, previous work on action-conditioned dynamics prediction focuses on learning the pixel-level motion and thus does not generalize well to novel environments with different object layouts. In this paper, we present a novel object-oriented framework, called object-oriented dynamics predictor (OODP), which decomposes the environment into objects and predicts the dynamics of objects conditioned on both actions and object-to-object relations. It is an end-to-end neural network and can be trained in an unsupervised manner. To enable the generalization ability of dynamics learning, we design a novel CNN-based relation mechanism that is class-specific (rather than object-specific) and exploits the locality principle. Empirical results show that OODP significantly outperforms previous methods in terms of generalization over novel environments with various object layouts. OODP is able to learn from very few environments and accurately predict dynamics in a large number of unseen environments. In addition, OODP learns semantically and visually interpretable dynamics models.
100. **Adaptive Methods for Nonconvex Optimization** --*Manzil Zaheer &middot; Sashank Reddi &middot; Devendra Sachan &middot; Satyen Kale &middot; Sanjiv Kumar*
 > Adaptive gradient methods that rely on scaling gradients down by the square root of exponential moving averages of past squared gradients, such RMSProp, Adam, Adadelta have found wide application in optimizing the nonconvex problems that arise in deep learning. However, it has been recently demonstrated that such methods can fail to converge even in simple convex optimization settings. In this work, we provide a new analysis of such methods applied to nonconvex stochastic optimization problems, characterizing the effect of increasing minibatch size. Our analysis shows that under this scenario such methods do converge to stationarity up to the statistical limit of variance in the stochastic gradients (scaled by a constant factor). In particular, our result implies that increasing minibatch sizes enables convergence,  thus providing a way to circumvent the non-convergence issues. Furthermore, we provide a new adaptive optimization algorithm, Yogi, which controls the increase in effective learning rate,  leading to even better performance with similar theoretical guarantees on convergence. Extensive experiments show that Yogi with very little hyperparameter tuning outperforms methods such as Adam in several challenging machine learning tasks.
101. **Entropy Rate Estimation for Markov Chains with Large State Space** --*Yanjun Han &middot; Jiantao Jiao &middot; Chuan-Zheng Lee &middot; Tsachy Weissman &middot; Yihong Wu &middot; Tiancheng Yu*
 > Entropy estimation is one of the prototypical problems in distribution property testing. To consistently estimate the Shannon entropy of a distribution on $S$ elements with independent samples, the optimal sample complexity scales sublinearly with $S$ as $\Theta(\frac{S}{\log S})$ as shown by Valiant and Valiant \cite{Valiant--Valiant2011}. Extending the theory and algorithms for entropy estimation to dependent data, this paper considers the problem of estimating the entropy rate of a stationary reversible Markov chain with $S$ states from a sample path of $n$ observations. We show that \begin{itemize} 	\item Provided the Markov chain mixes not too slowly, \textit{i.e.}, the relaxation time is at most $O(\frac{S}{\ln^3 S})$, consistent estimation is achievable when $n \gg \frac{S^2}{\log S}$. 	\item Provided the Markov chain has some slight dependency, \textit{i.e.}, the relaxation time is at least $1+\Omega(\frac{\ln^2 S}{\sqrt{S}})$, consistent estimation is impossible when $n \lesssim \frac{S^2}{\log S}$. \end{itemize} Under both assumptions, the optimal estimation accuracy is shown to be $\Theta(\frac{S^2}{n \log S})$. In comparison, the empirical entropy rate requires at least $\Omega(S^2)$ samples to be consistent, even when the Markov chain is memoryless. In addition to synthetic experiments, we also apply the estimators that achieve the optimal sample complexity to estimate the entropy rate of the English language in the Penn Treebank and the Google One Billion Words corpora, which provides a natural benchmark for language modeling and relates it directly to the widely used perplexity measure.
102. **Large Scale computation of Means and Clusters for Persistence Diagrams using Optimal Transport** --*Theo Lacombe &middot; marco Cuturi &middot; Steve OUDOT*
 > Persistence diagrams (PDs) are now routinely used to summarize the underlying topology of sophisticated data encountered in challenging learning problems. Despite several appealing properties, integrating PDs in learning pipelines can be challenging because their natural geometry is not Hilbertian. In particular, algorithms to average a family of PDs have only been considered recently and are known to be computationally prohibitive. We propose in this article a tractable framework to carry out fundamental tasks on PDs, namely evaluating distances, computing barycenters and carrying out clustering. This framework builds upon a formulation of PD metrics as optimal transport (OT) problems, for which recent computational advances, in particular entropic regularization and its convolutional formulation on regular grids, can all be leveraged to provide efficient and (GPU) scalable computations. We demonstrate the efficiency of our approach by carrying out clustering on PDs at scales never seen before in the literature.
103. **Deep Anomaly Detection Using Geometric Transformations** --*Izhak Golan &middot; Ran El-Yaniv*
 > We consider the problem of anomaly detection in images, and  present a new detection technique. Given a sample of images, all known to belong to a ``normal'' class (e.g., dogs),  we show how to train a deep neural model that can detect  out-of-distribution images (i.e., non-dog objects). The main  idea behind our scheme is to train a multi-class model to discriminate between dozens of geometric transformations applied on all the given images. The auxiliary expertise learned by the model generates feature detectors that effectively identify, at test time, anomalous images based on the softmax activation statistics of the model when applied on transformed images. We present extensive experiments using the proposed detector, which indicate that our algorithm improves state-of-the-art methods by a wide margin.
104. **Generalization Bounds for Uniformly Stable Algorithms** --*Vitaly Feldman &middot; Jan Vondrak*
 >   Uniform stability of a learning algorithm is a classical notion of algorithmic stability introduced to derive high-probability bounds on the generalization error (Bousquet and Elisseeff, 2002).  Specifically, for a loss function with range bounded in $[0,1]$, the generalization error of $\gamma$-uniformly stable learning algorithm on $n$ samples is known to be at most $O((\gamma +1/n) \sqrt{n \log(1/\delta)})$ with probability at least $1-\delta$. Unfortunately, this bound does not lead to meaningful generalization bounds in many common settings where $\gamma \geq 1/\sqrt{n}$. At the same time the bound is known to be tight only when $\gamma = O(1/n)$.   Here we prove substantially stronger generalization bounds for uniformly stable algorithms without any additional assumptions. First, we show that the generalization error in this setting is at most $O(\sqrt{(\gamma + 1/n) \log(1/\delta)})$ with probability at least $1-\delta$. In addition, we prove a tight bound of $O(\gamma^2 + 1/n)$ on the second moment of the generalization error. The best previous bound on the second moment of the generalization error is $O(\gamma + 1/n)$. Our proofs are based on new analysis techniques and our results imply substantially stronger generalization guarantees for several well-studied algorithms.
106. **Towards Deep Conversational Recommendations** --*Raymond Li &middot; Samira Ebrahimi Kahou &middot; Hannes Schulz &middot; Vincent Michalski &middot; Laurent Charlin &middot; Chris Pal*
 > There has been growing interest in using neural networks and deep learning techniques to create dialogue systems. Conversational recommendation is an interesting setting for the scientific exploration of dialogue with natural language as the associated discourse involves goal-driven dialogue that often transforms naturally into more free-form chat. This paper provides two contributions. First, until now there has been no publicly available large-scale data set consisting of real-world dialogues centered around recommendations. To address this issue and to facilitate our exploration here, we have collected a data set consisting of over 10,000 conversations centered around the theme of providing movie recommendations. We intend to make this data available to the community for further research. Second, we use this dataset to explore multiple facets of  conversational recommendations. In particular we explore new neural architectures, mechanisms and methods suitable for composing conversational recommendation systems. Our dataset allows us to systematically probe model sub-components addressing different parts of the overall problem domain ranging from: sentiment analysis and cold-start recommendation generation to detailed aspects of how natural language is used in this setting in the real world. We combine such sub-components into a full-blown dialogue system and examine its behavior.
107. **Latent Alignment and Variational Attention** --*Yoon Kim &middot; Yuntian Deng &middot; Justin Chiu &middot; Demi Guo &middot; Alexander Rush*
 > Attention, a method for learning a soft alignment function embedded in a neural network, is central for many state-of-the-art models in natural language processing and related domains. Attention networks are easy to train and interpret; however, the standard (soft) attention approach is a fully feed-forward approach and does not marginalize over the latent alignment in a traditional sense. This property makes it difficult to compare attention to other alignment approaches, to compose it with probabilistic models, and to perform posterior inference conditioned on observed data. A popular latent variable approach, hard attention, fixes these issues, but is unfortunately generally less accurate and harder to train. In this work, we explore the space of modern variational inference approaches as alternatives for learning latent variable alignment models. Variational attention generalizes hard attention and can provide a tighter approximation bound. We further propose methods for reducing the variance of gradients to make these approaches computationally feasible. Experiments show that for machine translation and visual question answering, while hard attention performs worse than soft attention, exact latent variable models can outperform both. Furthermore variational attention retains almost all of this performance gain with training speed comparable to soft attention.
108. **Improving Explorability in Variational Inference with Annealed Variational Objectives** --*Chin-Wei Huang &middot; Shawn Tan &middot; Alexandre Lacoste &middot; Aaron C Courville*
 > Despite the advances in the representational capacity of approximate distributions for variational inference, the optimization process can still limit the density that is ultimately learned. We demonstrate the drawbacks of biasing the true posterior to be unimodal, and introduce Annealed Variational Objectives (AVO) into the training of hierarchical variational methods. Inspired by Annealed Importance Sampling, the proposed method facilitates learning by incorporating energy tempering into the optimization objective. In our experiments, we demonstrate our method's robustness to deterministic warm up, and the benefits of encouraging exploration in the latent space.
109. **Coupled Variational Bayes via Optimization Embedding** --*Bo Dai &middot; Hanjun Dai &middot; Niao He &middot; Weiyang Liu &middot; Zhen Liu &middot; Jianshu Chen &middot; Lin Xiao &middot; Le Song*
 > Variational inference plays a vital role in learning graphical models, especially on large-scale datasets. Much of its success depends on a proper choice of auxiliary distribution class for posterior approximation. However, how to pursue an auxiliary distribution class that achieves both good approximation ability and computation efficiency remains a core challenge. In this paper, we construct such a distribution class, termed optimization embedding, since it takes root in an optimization procedure. This flexible function class couples the variational distribution with the original parameters in the graphical models, allowing end-to-end learning of the graphical models by back-propagation through the variational distribution. Theoretically,  we establish an interesting connection to gradient flow and demonstrate the extremely flexibility of this implicit distribution family in the limit sense.  Practically,  the proposed technique allows to significantly accelerate the learning procedure, i.e., the proposed coupled variational Bayes, by reducing the searching space to a large extent. We further demonstrate the significant superiority of the proposed method on multiple graphical models with either continuous or discrete latent variables comparing to state-of-the-art methods.
110. **Theoretical guarantees for EM under misspecified Gaussian mixture models** --*Raaz Dwivedi &middot; nhật Hồ &middot; Koulik Khamaru &middot; Martin Wainwright &middot; Michael Jordan*
 > Recent years have witnessed substantial progress in understanding   the behavior of EM for mixture models that are correctly specified.   Given that model misspecification is common in practice, it is   important to understand EM in this more general setting.  We provide   non-asymptotic guarantees for population and sample-based EM for   parameter estimation under a few specific univariate settings of   misspecified Gaussian mixture models.  Due to misspecification, the   EM iterates no longer converge to the true model and instead   converge to the projection of the true model over the set of models   being searched over.  We provide two classes of theoretical   guarantees: first, we characterize the bias introduced due to the   misspecification; and second, we prove that population EM converges   at a geometric rate to the model projection under a suitable   initialization condition.  This geometric convergence rate for   population EM imply a statistical complexity of order $1/\sqrt{n}$   when running EM with $n$ samples. We validate our theoretical   findings in different cases via several numerical examples.
111. **Non-convex Optimization with Discretized Diffusions** --*Murat A Erdogdu &middot; Lester Mackey &middot; Ohad Shamir*
 > An Euler discretization of the Langevin diffusion is known to converge   to the global minimizers of certain convex and non-convex optimization problems. <br />   We show that this property holds for any suitably smooth diffusion and   that different diffusions are suitable for optimizing different classes of convex   and non-convex functions.   This allows us to design diffusions suitable for globally optimizing non-convex functions   not covered by the existing Langevin theory.   Our non-asymptotic analysis establishes explicit,   finite-time convergence rates to global minima,   and is based on a multidimensional version of Stein's method   with new explicit bounds on the solutions of Poisson equations.
